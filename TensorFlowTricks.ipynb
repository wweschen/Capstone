{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given:  tf.Tensor(\n",
      "[[[1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]]\n",
      "\n",
      " [[1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]]\n",
      "\n",
      " [[1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]]], shape=(3, 5, 4), dtype=int32)\n",
      "fetch indices:  tf.Tensor(\n",
      "[[0 1 2 3 3]\n",
      " [0 1 2 3 3]\n",
      " [0 1 2 3 3]], shape=(3, 5), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=int32, numpy=\n",
       "array([[1, 2, 3, 4, 4],\n",
       "       [1, 2, 3, 4, 4],\n",
       "       [1, 2, 3, 4, 4]], dtype=int32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def batch_fetch_element_per_group(data,idx):\n",
    "    #here data is of shape [?,m,n] ? is the data batch size, m -number of groups, n-number of candidates in each group\n",
    "    #idx is of shape [?,m] m - index to select a particular target from each group, so we have m of them.\n",
    "    # output would be [?,m], selected targets for all groups\n",
    "    \n",
    "    nRows = tf.shape(data)[0]  \n",
    "    #print(nRows)\n",
    "    \n",
    "    nCols = tf.constant(tf.shape(data)[1] , dtype=tf.int32) \n",
    "    #print(nCols)\n",
    "    \n",
    "    m1 = tf.reshape(tf.tile(tf.range(nCols), [nRows]),\n",
    "                                           shape=[nRows, nCols])\n",
    "    #print(m1)\n",
    "    m2 = tf.transpose(tf.reshape(tf.tile(tf.range(nRows), [nCols]),\n",
    "                                            shape=[nCols, nRows]))\n",
    "    #print(m2)\n",
    "    indices = tf.stack([m2, m1, idx], axis=-1)\n",
    "    # indices should be of shape [?, 5, 3] with indices[i,j]==[i,j,idx[i,j]]\n",
    "    #print(indices)\n",
    "    output = tf.gather_nd(data, indices=indices)\n",
    "    #print(output)\n",
    "    return output\n",
    "\n",
    "data = tf.constant([[[1,2,3,4],[1,2,3,4],[1,2,3,4],[1,2,3,4],[1,2,3,4]],\n",
    "                   [[1,2,3,4],[1,2,3,4],[1,2,3,4],[1,2,3,4],[1,2,3,4]],\n",
    "                   [[1,2,3,4],[1,2,3,4],[1,2,3,4],[1,2,3,4],[1,2,3,4]]])\n",
    "\n",
    "idx= tf.constant ([[0,1,2,3,3],[0,1,2,3,3],[0,1,2,3,3]])\n",
    "\n",
    " \n",
    "print('given: ',data)\n",
    "print('fetch indices: ',idx)\n",
    "batch_fetch_element_per_group(data,idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=int32, numpy=10>,\n",
       " <tf.Tensor: shape=(2048, 2), dtype=float32, numpy=\n",
       " array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        ...,\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32)>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to get the best span text given the logits of start and end points.\n",
    "i0 = tf.constant(0)\n",
    "m0 = tf.ones([2, 2])\n",
    "c = lambda i, m: i < 10\n",
    "b = lambda i, m: [i+1, tf.concat([m, m], axis=0)]\n",
    "tf.while_loop(\n",
    "    c, b, loop_vars=[i0, m0],\n",
    "    shape_invariants=[i0.get_shape(), tf.TensorShape([None, 2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 2]\n",
      "tf.Tensor(\n",
      "[[[0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]]], shape=(2, 3, 2), dtype=int32)\n",
      "shape is: [6 2]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "my_tensor = tf.constant(0, shape=[6 ,2]) # Tensor('Const:0' shape=(6, 2) dtype=int32)\n",
    "my_dynamic_shape = tf.shape(my_tensor) \n",
    "print(my_dynamic_shape.numpy())\n",
    "# -> Tensor('Shape:0' shape=(2,) dtype=int32)\n",
    "# The shape of the tensor \"Shape\" is (2,) because my_tensor is a 2-D tensor\n",
    "# so the dynamic shape is a 1-D tensor containing sizes of my_tensor dimensions\n",
    "# and in this case, we have 2 dimensions.\n",
    "\n",
    "my_reshaped_tensor = tf.reshape(my_tensor, [2, 3, 2]) \n",
    "print(my_reshaped_tensor)\n",
    "# -> Tensor('Reshape:0' shape=(2, 3, 2) dtype=int32)\n",
    "\n",
    "# To access a dynamic shape value, you need to run your graph and feed any placeholder that your tensor my depended upon:\n",
    "@tf.function\n",
    "def get_dynamic_shape(x):\n",
    "    return tf.shape(x)\n",
    "\n",
    "print('shape is:',get_dynamic_shape([[1., 2.], [1., 2.], [1., 2.], [1., 2.], [1., 2.], [1., 2.]]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_span_prediction(ids,start_logits, end_logits):\n",
    "    _, starts = tf.nn.top_k(start_logits, k=1)\n",
    "    _, ends = tf.nn.top_k(end_logits, k=1)\n",
    "    \n",
    "    batch_size = tf.shape(ids)[0]\n",
    "    str_len = tf.shape(ids)[1]\n",
    "    \n",
    "    span_array = []\n",
    "    mask_array = []\n",
    "\n",
    "    \n",
    "    def condition(id_str,start,end,i):\n",
    "        return tf.less(i,batch_size) && tf.less(j,str_len)\n",
    "        \n",
    "    \n",
    "    def body(id_str,start,end,i):\n",
    "       \n",
    "        span_array.append(tf.strided_slice(id_str, start, end + 1))\n",
    "        mask_array.append(tf.strided_slice(tf.fill([str_len], 1), start , end  + 1))\n",
    "        \n",
    "        def inside_body(i,j):\n",
    "            span_array[i] = tf.concat([span_array[i], [0]], axis=0)\n",
    "            mask_array[i] = tf.concat([mask_array[i], [0]], axis=0)\n",
    "            j=j+1\n",
    "        tf.while_loop(\n",
    "            cond = lambda i,j: tf.less(j,str_len-len(span_array[i])),\n",
    "            body=inside_body,\n",
    "            loop_vars=[i,j]\n",
    "        )\n",
    "        \n",
    "        i=i+1\n",
    "    \n",
    "    returned = tf.while_loop(\n",
    "        cond = condition,\n",
    "        body= body,\n",
    "        loop_vars=[ids,starts,ends,0]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[0.04177725, 0.7987331 , 0.52792335, 0.21513033],\n",
       "        [0.10943258, 1.3330783 , 0.6829629 , 0.65409565],\n",
       "        [0.91260433, 1.6601439 , 1.1433008 , 0.9245236 ]],\n",
       "\n",
       "       [[0.8501966 , 0.67991745, 0.7845633 , 0.66094744],\n",
       "        [1.4661397 , 1.6632185 , 0.7948631 , 0.992458  ],\n",
       "        [2.0233245 , 1.9321158 , 1.4580377 , 1.3229467 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 3\n",
    "feature_size = 4\n",
    "\n",
    "def rnn_step(inp, state):\n",
    "  return inp + state\n",
    "\n",
    "@tf.function\n",
    "def dynamic_rnn(rnn_step, input_data, initial_state):\n",
    "  # [batch, time, features] -> [time, batch, features]\n",
    "  input_data = tf.transpose(input_data, [1, 0, 2])\n",
    "  max_seq_len = input_data.shape[0]\n",
    "\n",
    "  states = tf.TensorArray(tf.float32, size=max_seq_len)\n",
    "  state = initial_state\n",
    "  for i in tf.range(max_seq_len):\n",
    "    state = rnn_step(input_data[i], state)\n",
    "    states = states.write(i, state)\n",
    "  return tf.transpose(states.stack(), [1, 0, 2])\n",
    "  \n",
    "dynamic_rnn(rnn_step,\n",
    "            tf.random.uniform([batch_size, seq_len, feature_size]),\n",
    "            tf.zeros([batch_size, feature_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_span_prediction(ids,start_logits, end_logits):\n",
    "    _, starts = tf.nn.top_k(start_logits, k=1)\n",
    "    _, ends = tf.nn.top_k(end_logits, k=1)\n",
    "    \n",
    "    batch_size = tf.shape(ids)[0]\n",
    "    str_len = tf.shape(ids)[1]\n",
    "    \n",
    "    span_array = []\n",
    "    mask_array = []\n",
    "    \n",
    "    dynamic_rnn(rnn_step, ids,starts,ends)\n",
    "    \n",
    "    def rnn_step(inp, state):\n",
    "    return inp + state\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def dynamic_rnn(rnn_step, input_data, starts,ends):\n",
    "      # [batch, time, features] -> [time, batch, features]\n",
    "      input_data = tf.transpose(input_data, [1, 0])\n",
    "      max_seq_len = input_data.shape[0]\n",
    "\n",
    "      spans = tf.TensorArray(tf.float32, size=max_seq_len)\n",
    "      masks = tf.TensorArray(tf.float32, size=max_seq_len)\n",
    "      start = starts[0]\n",
    "      end = ends[0]\n",
    "      for i in tf.range(max_seq_len):\n",
    "        state = rnn_step(input_data[i], state)\n",
    "        states = states.write(i, state)\n",
    "      return tf.transpose(states.stack(), [1, 0, 2])\n",
    "  \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Could not read index 0 twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-29cc3fded517>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mspans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mspans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mget_best_span_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-29cc3fded517>\u001b[0m in \u001b[0;36mget_best_span_prediction\u001b[0;34m(ids, starts, ends)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspan_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mspan_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, index, name)\u001b[0m\n\u001b[1;32m   1138\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mat\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \"\"\"\n\u001b[0;32m-> 1140\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_implementation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0;34m\"Could not read index %d twice because it was cleared after \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;34m\"a previous read (perhaps try setting clear_after_read = false?)\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m             index)\n\u001b[0m\u001b[1;32m    774\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Could not read index 0 twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?)"
     ]
    }
   ],
   "source": [
    "max_seq_length=400\n",
    "\n",
    "    # ids = tf.keras.layers.Input(\n",
    "    #       shape=(max_seq_length,), dtype=tf.int32, name='input_ids')\n",
    "    # starts = tf.keras.layers.Input(\n",
    "    #       shape=(1,), dtype=tf.int32, name='starts')\n",
    "\n",
    "    # ends = tf.keras.layers.Input(\n",
    "    #       shape=(1,), dtype=tf.int32, name='ends')\n",
    "\n",
    "ids = tf.constant([[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5]])\n",
    "starts = tf.constant([[0],[0],[1],[2],[3],[3]])\n",
    "ends = tf.constant([[3],[4],[4],[4],[4],[4]])\n",
    "\n",
    "#@tf.function\n",
    "def get_best_span_prediction(ids,starts, ends):\n",
    "    span_array = tf.TensorArray(dtype=tf.int32, size=0,dynamic_size=True)\n",
    "    mask_array =  tf.TensorArray(dtype=tf.int32, size=0,dynamic_size=True)\n",
    "\n",
    "\n",
    "    batch_size =tf.shape(ids)[0]\n",
    "    str_len = tf.shape(ids)[0]\n",
    "    i=0\n",
    "    while(i<batch_size):\n",
    "        span_array.write(i,tf.strided_slice(ids[i], starts[i], ends[i] + 1))\n",
    "        mask_array.write(i,tf.strided_slice(tf.fill([str_len], 1), starts[i], ends[i] + 1))\n",
    "        j=0\n",
    "        while j <(str_len - len(span_array.read(i))):\n",
    "            x=tf.concat([span_array.read(i), tf.constant([0])], axis=0)\n",
    "            span_array.write(i,x)\n",
    "            y=tf.concat([mask_array.read(i), tf.constant([0])], axis=0)\n",
    "            mask_array.write(i,y )\n",
    "            j=j+1\n",
    "        i=i+1\n",
    "        \n",
    "    spans =  span_array.stack()\n",
    "    masks =  mask_array.stack()\n",
    "\n",
    "    return (spans,masks)\n",
    "    \n",
    "spans,masks =get_best_span_prediction(ids,starts, ends)\n",
    "print(spans,masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((32,), (1,), (1,)), types: (tf.int64, tf.int64, tf.int64)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((32,), (1,), (1,)), types: (tf.int64, tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "ids = np.random.randint(30000, size=(1000,32))\n",
    "starts = np.random.randint(low=0,high=15,size=(1000,1))\n",
    "ends = np.random.randint(low=16,high=32,size=(1000,1))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((ids,starts,ends))\n",
    "print( dataset)  \n",
    "dataset.batch(10)\n",
    "dataset.repeat(100)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-b58ed8dcdcae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mspan_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmask_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    757\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \"\"\"\n\u001b[0;32m--> 759\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_bool_casting\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m       \u001b[0;31m# Default: V1-style Graph execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_in_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"using a `tf.Tensor` as a Python `bool`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_in_graph_mode\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    515\u001b[0m     raise errors.OperatorNotAllowedInGraphError(\n\u001b[1;32m    516\u001b[0m         \u001b[0;34m\"{} is not allowed in Graph execution. Use Eager execution or decorate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \" this function with @tf.function.\".format(task))\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function."
     ]
    }
   ],
   "source": [
    "ids = tf.keras.layers.Input(\n",
    "      shape=(max_seq_length,), dtype=tf.int32, name='input_ids')\n",
    "stt = tf.keras.layers.Input(\n",
    "      shape=(max_seq_length,), dtype=tf.int32, name='input_ids')\n",
    "\n",
    "ids = tf.keras.layers.Input(\n",
    "      shape=(max_seq_length,), dtype=tf.int32, name='input_ids')\n",
    "\n",
    "\n",
    "ids = tf.constant([[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5]])\n",
    "starts = tf.constant([[0],[0],[1],[2],[3],[3]])\n",
    "ends = tf.constant([[3],[4],[4],[4],[4],[4]])\n",
    "\n",
    "span_array = []\n",
    "mask_array = []\n",
    "\n",
    "\n",
    "batch_size =tf.shape(ids)[0]\n",
    "str_len = tf.shape(ids)[0]\n",
    "for i in tf.range(batch_size):\n",
    "    span_array.append(tf.strided_slice(ids[i], starts[i], ends[i] + 1))\n",
    "    mask_array.append(tf.strided_slice(tf.fill([str_len], 1), starts[i], ends[i] + 1))\n",
    "    for j in range(str_len - len(span_array[i])):\n",
    "        span_array[i] = tf.concat([span_array[i], [0]], axis=0)\n",
    "        mask_array[i] = tf.concat([mask_array[i], [0]], axis=0)\n",
    "\n",
    "spans = tf.stack(span_array, axis=0)\n",
    "masks = tf.stack(mask_array, axis=0)\n",
    "\n",
    "print(spans,masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32) tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32) tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)\n",
      "eager lstm: 0.009034960006829351\n",
      "function lstm: 0.004581001005135477\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "lstm_cell = tf.keras.layers.LSTMCell(10)\n",
    "\n",
    "@tf.function\n",
    "def lstm_fn(input, state):\n",
    "  return lstm_cell(input, state)\n",
    "\n",
    "input = tf.zeros([10, 10])\n",
    "state = [tf.zeros([10, 10])] * 2\n",
    "print(input,state[0],state[1])\n",
    "# warm up\n",
    "lstm_cell(input, state); lstm_fn(input, state)\n",
    "print(\"eager lstm:\", timeit.timeit(lambda: lstm_cell(input, state), number=10))\n",
    "print(\"function lstm:\", timeit.timeit(lambda: lstm_fn(input, state), number=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 1 1 1 1]\n",
      " [2 2 2 2 2]\n",
      " [3 3 3 3 3]\n",
      " [3 3 3 3 3]], shape=(6, 5), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [3]], shape=(6, 1), dtype=int32) tf.Tensor(\n",
      "[[0 0 1 2 3 3]\n",
      " [0 0 1 2 3 3]\n",
      " [0 0 1 2 3 3]\n",
      " [0 0 1 2 3 3]\n",
      " [0 0 1 2 3 3]], shape=(5, 6), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "ids = tf.constant([[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5]])\n",
    "starts = tf.constant([[0],[0],[1],[2],[3],[3]])\n",
    "ends = tf.constant([[3],[4],[4],[4],[4],[4]])\n",
    "\n",
    "starts_1= tf.tile(starts,[1,5])\n",
    "\n",
    "print(tf.reduce_max(starts_1[0]))\n",
    "print(starts_1)\n",
    "starts_t=tf.transpose(starts_1,[1,0])\n",
    "print(starts,starts_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-5 -4 -3 -2 -1  0  1  2  3  4], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def square_if_positive_vectorized(x):\n",
    "  return tf.where(x > 0, x ** 2, x)\n",
    "\n",
    "\n",
    "square_if_positive_vectorized(tf.range(-5, 5))\n",
    "\n",
    "print(tf.range(-5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tensor(\"loop_body/Roll:0\", shape=(5,), dtype=int32)\n"
     ]
    },
    {
     "ename": "StagingError",
     "evalue": "in converted code:\n    relative to /Users/wweschen/tf2/env/lib/python3.7/site-packages:\n\n    tensorflow_core/python/ops/parallel_for/control_flow_ops.py:183 f  *\n        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)\n    tensorflow_core/python/ops/parallel_for/control_flow_ops.py:256 _pfor_impl\n        outputs.append(converter.convert(loop_fn_output))\n    tensorflow_core/python/ops/parallel_for/pfor.py:1280 convert\n        output = self._convert_helper(y)\n    tensorflow_core/python/ops/parallel_for/pfor.py:1453 _convert_helper\n        if flags.FLAGS.op_conversion_fallback_to_while_loop:\n    tensorflow_core/python/platform/flags.py:84 __getattr__\n        wrapped(_sys.argv)\n    absl/flags/_flagvalues.py:633 __call__\n        name, value, suggestions=suggestions)\n\n    UnrecognizedFlagError: Unknown command line flag 'f'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7a99cbeedca5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m new_spans = tf.vectorized_map(\n\u001b[1;32m     40\u001b[0m     \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_roll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0melems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py\u001b[0m in \u001b[0;36mvectorized_map\u001b[0;34m(fn, elems)\u001b[0m\n\u001b[1;32m    392\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_elem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mpfor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py\u001b[0m in \u001b[0;36mpfor\u001b[0;34m(loop_fn, iters, parallel_iterations)\u001b[0m\n\u001b[1;32m    187\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_under_xla_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2336\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2337\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2338\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2339\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2672\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2673\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2674\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2675\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2561\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2562\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2563\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2564\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    956\u001b[0m                                           converted_func)\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    946\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStagingError\u001b[0m: in converted code:\n    relative to /Users/wweschen/tf2/env/lib/python3.7/site-packages:\n\n    tensorflow_core/python/ops/parallel_for/control_flow_ops.py:183 f  *\n        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)\n    tensorflow_core/python/ops/parallel_for/control_flow_ops.py:256 _pfor_impl\n        outputs.append(converter.convert(loop_fn_output))\n    tensorflow_core/python/ops/parallel_for/pfor.py:1280 convert\n        output = self._convert_helper(y)\n    tensorflow_core/python/ops/parallel_for/pfor.py:1453 _convert_helper\n        if flags.FLAGS.op_conversion_fallback_to_while_loop:\n    tensorflow_core/python/platform/flags.py:84 __getattr__\n        wrapped(_sys.argv)\n    absl/flags/_flagvalues.py:633 __call__\n        name, value, suggestions=suggestions)\n\n    UnrecognizedFlagError: Unknown command line flag 'f'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "starts = tf.constant([[0],[0],[1],[2],[3],[3]])\n",
    "ends = tf.constant([[3],[4],[4],[4],[4],[4]])\n",
    "ids = tf.constant([[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5]])\n",
    "max_len=5\n",
    "batch_size =6\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "print(tf.executing_eagerly())   \n",
    "\n",
    "s= tf.transpose(tf.tile(starts,[1,max_len]))\n",
    "e= tf.transpose(tf.tile(ends,[1,max_len]))\n",
    "\n",
    "ta=tf.TensorArray(dtype = tf.int32, size=5)\n",
    "#print(s,e)\n",
    "for i in tf.range(max_len):\n",
    "    x=tf.where(i>=s[i],1,0)\n",
    "    y=tf.where(i<e[i],1,0)\n",
    "    #tf.print(x,y)\n",
    "    ta.write(i,x*y)\n",
    "\n",
    "m=tf.transpose(ta.stack(),[1,0])\n",
    "spans=ids*m\n",
    " \n",
    "#for i in tf.range(max_len):\n",
    "    #new_spans=tf.roll(spans, shift=s[i], axis=[1])\n",
    "    \n",
    " \n",
    "\n",
    "def f_roll(arg):\n",
    "    x, s = arg\n",
    "    \n",
    "    #return tf.roll(x, shift=-1 * s, axis=[0])\n",
    "    z=tf.roll(x, shift= -1*s , axis=[0])\n",
    "    print(z)\n",
    "    return z\n",
    "    \n",
    "new_spans = tf.vectorized_map(\n",
    "    fn=f_roll,\n",
    "    elems=(spans, starts)\n",
    ")\n",
    " \n",
    "new_mask = tf.vectorized_map(\n",
    "    fn=f_roll,\n",
    "    elems=(m, starts)\n",
    ")\n",
    " \n",
    "print(new_spans,new_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 12, 10)\n"
     ]
    }
   ],
   "source": [
    " \n",
    "fw=tf.keras.layers.LSTM(5, return_sequences=True,return_state=True )\n",
    "bw=tf.keras.layers.LSTM(5, return_sequences=True,go_backwards=True,return_state=True )\n",
    "\n",
    " \n",
    "\n",
    "inputs = tf.ones([2, 12, 5])\n",
    "\n",
    "\n",
    "out=fw(inputs)\n",
    "out2 =bw(inputs)\n",
    " \n",
    "print(tf.concat([out[0],out2[0]],axis=2).shape)\n",
    "      \n",
    "#print(tf.split(s,2,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
      "array([[1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.]], dtype=float32)>, <tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
      "array([[1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.]], dtype=float32)>]\n",
      "tf.Tensor(\n",
      "[[0.00270986 0.5078718  0.2911771  0.5298484  0.08189317]\n",
      " [0.00270986 0.5078718  0.2911771  0.52984846 0.08189316]\n",
      " [0.00270986 0.5078718  0.29117706 0.52984846 0.08189316]], shape=(3, 5), dtype=float32) tf.Tensor(\n",
      "[[0.00270986 0.5078718  0.2911771  0.5298484  0.08189317]\n",
      " [0.00270986 0.5078718  0.2911771  0.52984846 0.08189316]\n",
      " [0.00270986 0.5078718  0.29117706 0.52984846 0.08189316]], shape=(3, 5), dtype=float32) tf.Tensor(\n",
      "[[0.00501275 1.1753801  0.9873215  1.044925   0.6098953 ]\n",
      " [0.00501275 1.1753801  0.9873215  1.044925   0.6098953 ]\n",
      " [0.00501275 1.1753801  0.9873214  1.044925   0.6098953 ]], shape=(3, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.20794933 -0.17963332  0.39797983 -0.03846632 -0.22294845]\n",
      " [-0.20794933 -0.17963338  0.3979799  -0.03846628 -0.22294846]\n",
      " [-0.20794934 -0.17963338  0.3979799  -0.03846627 -0.22294849]], shape=(3, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    " \n",
    "c=tf.keras.layers.LSTMCell(5) \n",
    "l  =  tf.keras.layers.Dense(5)\n",
    "#print(c.output_size)\n",
    "#print(c.state_size)\n",
    "\n",
    "inputs = tf.ones([3,5])\n",
    "state=[tf.ones([3,5]),tf.ones([3,5])]\n",
    "\n",
    "print(state)\n",
    "out=c(inputs,state)\n",
    "  \n",
    "out2=l(out[1][0])\n",
    "print(out[0],out[1][0],out[1][1])\n",
    "print(out2)\n",
    "      \n",
    "#print(tf.split(s,2,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "ename": "_SymbolicException",
     "evalue": "Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'input_ids_22:0' shape=(None, 5) dtype=int32>, <tf.Tensor 'starts_19:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'ends_19:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'starts_19:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'ends_19:0' shape=(None, 1) dtype=int32>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: An op outside of the function building code is being passed\na \"Graph\" tensor. It is possible to have Graph tensors\nleak out of the function building context by including a\ntf.init_scope in your function building code.\nFor example, the following function will fail:\n  @tf.function\n  def has_init_scope():\n    my_constant = tf.constant(1.)\n    with tf.init_scope():\n      added = my_constant * 2\nThe graph tensor has name: input_ids_22:0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31m_SymbolicException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-279-1eaf5f898980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mspans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mget_best_span_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    621\u001b[0m               *args, **kwds)\n\u001b[1;32m    622\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1554\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1555\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1556\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1635\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1637\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1638\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1639\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    498\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     73\u001b[0m       raise core._SymbolicException(\n\u001b[1;32m     74\u001b[0m           \u001b[0;34m\"Inputs to eager execution function cannot be Keras symbolic \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m           \"tensors, but found {}\".format(keras_symbolic_tensors))\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_SymbolicException\u001b[0m: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'input_ids_22:0' shape=(None, 5) dtype=int32>, <tf.Tensor 'starts_19:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'ends_19:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'starts_19:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'ends_19:0' shape=(None, 1) dtype=int32>]"
     ]
    }
   ],
   "source": [
    "max_len=5\n",
    "ids = tf.keras.layers.Input(\n",
    "      shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "starts = tf.keras.layers.Input(\n",
    "      shape=(1,), dtype=tf.int32, name='starts')\n",
    "\n",
    "ends = tf.keras.layers.Input(\n",
    "      shape=(1,), dtype=tf.int32, name='ends')\n",
    "# starts = tf.constant([[0],[0],[1],[2],[3],[3]])\n",
    "# ends = tf.constant([[3],[4],[4],[4],[4],[4]])\n",
    "# ids = tf.constant([[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5]])\n",
    "max_len=5\n",
    "\n",
    "@tf.function\n",
    "def get_best_span_prediction(ids,start_logits, end_logits):\n",
    "    #_, starts = tf.nn.top_k(start_logits, k=1)\n",
    "    #_, ends = tf.nn.top_k(end_logits, k=1)\n",
    "    \n",
    "    s= tf.transpose(tf.tile(starts,[1,max_len]))\n",
    "    e= tf.transpose(tf.tile(ends,[1,max_len]))\n",
    "\n",
    "    ta=tf.TensorArray(dtype = tf.int32, size=5)\n",
    "    #print(s,e)\n",
    "    for i in tf.range(max_len):\n",
    "        x=tf.where(i>=s[i],1,0)\n",
    "        y=tf.where(i<e[i],1,0)\n",
    "        #tf.print(x,y)\n",
    "        ta.write(i,x*y)\n",
    "\n",
    "    m=tf.transpose(ta.stack(),[1,0])\n",
    "    spans=ids*m\n",
    "    #print(spans,starts)\n",
    "\n",
    "    #for i in tf.range(max_len):\n",
    "        #new_spans=tf.roll(spans, shift=s[i], axis=[1])\n",
    "\n",
    "    return (spans,m)\n",
    "\n",
    "get_best_span_prediction(ids,starts,ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "_SymbolicException",
     "evalue": "Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'starts_17:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'ends_17:0' shape=(None, 1) dtype=int32>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: An op outside of the function building code is being passed\na \"Graph\" tensor. It is possible to have Graph tensors\nleak out of the function building context by including a\ntf.init_scope in your function building code.\nFor example, the following function will fail:\n  @tf.function\n  def has_init_scope():\n    my_constant = tf.constant(1.)\n    with tf.init_scope():\n      added = my_constant * 2\nThe graph tensor has name: starts_17:0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31m_SymbolicException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-690aab3c6a90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmake_a_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    621\u001b[0m               *args, **kwds)\n\u001b[1;32m    622\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1554\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1555\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1556\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1635\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1637\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1638\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1639\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    498\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     73\u001b[0m       raise core._SymbolicException(\n\u001b[1;32m     74\u001b[0m           \u001b[0;34m\"Inputs to eager execution function cannot be Keras symbolic \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m           \"tensors, but found {}\".format(keras_symbolic_tensors))\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_SymbolicException\u001b[0m: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'starts_17:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'ends_17:0' shape=(None, 1) dtype=int32>]"
     ]
    }
   ],
   "source": [
    "max_seq_length=400\n",
    "\n",
    "ids = tf.keras.layers.Input(\n",
    "       shape=(max_seq_length,), dtype=tf.int32, name='input_ids')\n",
    "starts = tf.keras.layers.Input(\n",
    "       shape=(1,), dtype=tf.int32, name='starts')\n",
    "\n",
    "ends = tf.keras.layers.Input(\n",
    "       shape=(1,), dtype=tf.int32, name='ends')\n",
    "\n",
    "m=[]\n",
    "\n",
    "@tf.function\n",
    "def make_a_mask(starts,ends):\n",
    "   \n",
    "    batch_size=tf.shape(starts)[0]\n",
    "\n",
    "    k=0\n",
    "    while(k<batch_size):\n",
    "\n",
    "        a =[]\n",
    "        for i in tf.range(max_seq_length):\n",
    "            if(i<starts[k] or i>=ends[k]):\n",
    "                a.append(0)\n",
    "            else: \n",
    "                a.append(1)\n",
    "\n",
    "        k=k+1 \n",
    "        m.append(a)\n",
    "    \n",
    "m= make_a_mask(starts,ends)\n",
    "\n",
    "tf.print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinearLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               output_size,\n",
    "               use_bias=False,\n",
    "               kernel_initializer=None,\n",
    "               bias_initializer=\"zeros\",\n",
    "               activation=None,\n",
    "               **kwargs):\n",
    "    super(LinearLayer, self).__init__(**kwargs)\n",
    "    self.output_size = output_size\n",
    "    self.kernel_initializer = kernel_initializer\n",
    "    self.bias_initializer = bias_initializer\n",
    "    self.activation = activation\n",
    "    self.use_bias = use_bias\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    \"\"\"Implements build() for the layer.\"\"\"\n",
    "\n",
    "    total_arg_size = 0\n",
    "    shapes = input_shape  \n",
    "    if type(shapes) is not list:\n",
    "        shapes=[shapes] \n",
    "        \n",
    "    shapes=list(itertools.chain(*shapes))\n",
    "     \n",
    "    for shape in shapes: \n",
    "       \n",
    "        if len(shape) != 2:\n",
    "            raise ValueError(\"Linear is expecting 2D arguments: %s\" % str(shapes))\n",
    "        if not shape[1]:\n",
    "            raise ValueError(\"Linear expects shape[1] of arguments: %s\" % str(shapes))\n",
    "        else:\n",
    "            total_arg_size += shape[1] \n",
    "             \n",
    "    self.kernel = self.add_weight(\n",
    "        \"kernel\",\n",
    "        shape=[total_arg_size, self.output_size],\n",
    "        initializer=self.kernel_initializer,\n",
    "        dtype=self.dtype,\n",
    "        trainable=True)\n",
    "    self.bias = self.add_weight(\n",
    "        \"bias\",\n",
    "        shape=[self.output_size],\n",
    "        initializer=self.bias_initializer,\n",
    "        dtype=self.dtype,\n",
    "        trainable=True)\n",
    "\n",
    "    super(LinearLayer, self).build(input_shape)\n",
    "\n",
    "  def call(self, inputs):\n",
    "     \n",
    "        \n",
    "      if type(inputs) is not list:\n",
    "        inputs=[inputs]  \n",
    "        \n",
    "      inputs=list(itertools.chain(*inputs))\n",
    "    \n",
    "      if len(inputs) == 1:\n",
    "          \n",
    "          res = tf.matmul(inputs[0], self.kernel)\n",
    "      else:\n",
    "          res = tf.matmul(tf.concat(axis=1, values=inputs), self.kernel)\n",
    "      \n",
    "      if not self.use_bias:\n",
    "            return res\n",
    "        \n",
    "      return res + self.bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape_list(tensor, expected_rank=None, name=None):\n",
    "  \"\"\"Returns a list of the shape of tensor, preferring static dimensions.\n",
    "\n",
    "  Args:\n",
    "    tensor: A tf.Tensor object to find the shape of.\n",
    "    expected_rank: (optional) int. The expected rank of `tensor`. If this is\n",
    "      specified and the `tensor` has a different rank, and exception will be\n",
    "      thrown.\n",
    "    name: Optional name of the tensor for the error message.\n",
    "\n",
    "  Returns:\n",
    "    A list of dimensions of the shape of tensor. All static dimensions will\n",
    "    be returned as python integers, and dynamic dimensions will be returned\n",
    "    as tf.Tensor scalars.\n",
    "  \"\"\"\n",
    "  if expected_rank is not None:\n",
    "    assert_rank(tensor, expected_rank, name)\n",
    "\n",
    "  shape = tensor.shape.as_list()\n",
    "\n",
    "  non_static_indexes = []\n",
    "  for (index, dim) in enumerate(shape):\n",
    "    if dim is None:\n",
    "      non_static_indexes.append(index)\n",
    "\n",
    "  if not non_static_indexes:\n",
    "    return shape\n",
    "\n",
    "  dyn_shape = tf.shape(tensor)\n",
    "  for index in non_static_indexes:\n",
    "    shape[index] = dyn_shape[index]\n",
    "  return shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import tf_utils\n",
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, vector_size,\n",
    "                 use_coverage,\n",
    "                 initializer=None,\n",
    "                 float_type=tf.float32,\n",
    "                 **kwargs):\n",
    "        super(AttentionLayer , self).__init__(**kwargs)\n",
    "        self.initializer = initializer\n",
    "        self.float_type = float_type\n",
    "        self.vector_size = vector_size\n",
    "        self.use_coverage=use_coverage\n",
    "\n",
    "        #self.w_h = self.add_weight(shape=[1, 1, self.attention_length, self.vector_size], name=\"W_h\")\n",
    "        self.v = self.add_weight(shape=[self.vector_size], name=\"v\")\n",
    "        #self.w_c = self.add_weight(shape=[1, 1, 1, self.vector_size], name=\"W_c\")\n",
    "\n",
    "    def build(self,  unused_input_shapes):\n",
    "\n",
    "\n",
    "        self.linear_layer =  LinearLayer(self.vector_size)\n",
    "            # shape (batch_size, attention_vec_size)\n",
    "\n",
    "        self.coverage_layer =  tf.keras.layers.Conv2D(self.vector_size,(1,1), padding= \"SAME\")\n",
    "        # c has shape (batch_size, attn_length, 1, attention_vec_size)\n",
    "\n",
    "        super(AttentionLayer, self).build(unused_input_shapes)\n",
    "\n",
    "    def __call__(self,\n",
    "                 decoder_state,\n",
    "                 encoder_features,\n",
    "                 input_mask,\n",
    "                 coverage=None,\n",
    "                 **kwargs):\n",
    "        inputs = (encoder_features,decoder_state, input_mask,coverage )\n",
    "        return super(AttentionLayer, self).__call__(inputs, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "         \n",
    "        encoder_features = inputs[0]\n",
    "        batch_size = tf_utils.get_shape_list(encoder_features)[0]\n",
    "\n",
    "        decoder_states=inputs[1]\n",
    "        input_mask=inputs[2] \n",
    "        coverage  =inputs[3]\n",
    " \n",
    "        decoder_features= self.linear_layer([decoder_states])\n",
    "        decoder_features = tf.expand_dims(tf.expand_dims(decoder_features, 1),1)\n",
    "          # reshape to (batch_size, 1, 1, attention_vec_size)\n",
    "\n",
    "\n",
    "        def masked_attention(e):\n",
    "            \"\"\"Take softmax of e then apply enc_padding_mask and re-normalize\"\"\"\n",
    "            attn_dist = tf.nn.softmax(e)  # take softmax. shape (batch_size, attn_length)\n",
    "            attn_dist *= input_mask  # apply mask\n",
    "            masked_sums = tf.reduce_sum(attn_dist, axis=1)  # shape (batch_size)\n",
    "            return attn_dist / tf.reshape(masked_sums, [-1, 1])  # re-normalize\n",
    "\n",
    "        if self.use_coverage and coverage is not None:  # non-first step of coverage\n",
    "            # Multiply coverage vector by w_c to get coverage_features.\n",
    "            coverage_features = self.coverage_layer(coverage )  # c has shape (batch_size, attn_length, 1, attention_vec_size)\n",
    "\n",
    "            # Calculate v^T tanh(W_h h_i + W_s s_t + w_c c_i^t + b_attn)\n",
    "            e = tf.reduce_sum(self.v * tf.tanh(encoder_features + decoder_features + coverage_features),\n",
    "                                    [2, 3])  # shape (batch_size,attn_length)\n",
    "\n",
    "            # Calculate attention distribution\n",
    "            attn_dist = masked_attention(e)\n",
    "\n",
    "            # Update coverage vector\n",
    "            coverage += tf.reshape(attn_dist, [batch_size, -1, 1, 1])\n",
    "        else:\n",
    "            # Calculate v^T tanh(W_h h_i + W_s s_t + b_attn)\n",
    "            e = tf.reduce_sum(self.v * tf.tanh(encoder_features + decoder_features), [2, 3])  # calculate e\n",
    "\n",
    "            # Calculate attention distribution\n",
    "            attn_dist = masked_attention(e)\n",
    "\n",
    "            if self.use_coverage:  # first step of training\n",
    "                coverage = tf.expand_dims(tf.expand_dims(attn_dist, 2), 2)  # initialize coverage\n",
    "\n",
    "        # Calculate the context vector from attn_dist and encoder_states\n",
    "        context_vector = tf.reduce_sum(tf.reshape(attn_dist, [batch_size, -1, 1, 1]) * encoder_features,\n",
    "                                             [1, 2])  # shape (batch_size, attn_size).\n",
    "       \n",
    "        context_vector = tf.reshape(context_vector, [-1, self.vector_size])\n",
    "       \n",
    "         \n",
    "        return context_vector, attn_dist, coverage\n",
    "\n",
    "    def compute_output_shape(self,inputShape):\n",
    "    \n",
    "        #calculate shapes from input shape\n",
    "        return [[None,self.vector_size],\n",
    "                [None,self.max_seq_length],\n",
    "                [None,self.max_seq_length,1,1]\n",
    "               ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder (tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                  hidden_dim,\n",
    "                 vector_size,\n",
    "                 attention_length,\n",
    "                 initial_state_attention=False,\n",
    "                 pointer_gen=True,\n",
    "                 use_coverage=False,\n",
    "                 initializer=None,\n",
    "                 float_type=tf.float32,\n",
    "                 **kwargs):\n",
    "        super(AttentionDecoder , self).__init__(**kwargs)\n",
    "        self.initializer = initializer\n",
    "        self.float_type = float_type\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.vector_size = vector_size\n",
    "        self.attention_length = attention_length\n",
    "        self.pointer_gen = pointer_gen\n",
    "        self.use_coverage = use_coverage\n",
    "        self.initial_state_attention=initial_state_attention\n",
    "\n",
    "    def build(self, unused_input_shapes):\n",
    "\n",
    "        self.lstm_layer = tf.keras.layers.LSTMCell(self.vector_size)\n",
    "\n",
    "        self.encoder_layer = tf.keras.layers.Conv2D(filters=self.vector_size, kernel_size=(1, 1), padding=\"SAME\")\n",
    "        # shape (batch_size,attn_length,1,attention_vec_size)\n",
    "        self.linear = LinearLayer(self.vector_size )\n",
    "        self.linear2 = LinearLayer(1)\n",
    "        self.attention_layer = AttentionLayer(self.vector_size,self.attention_length,True)\n",
    "\n",
    "\n",
    "\n",
    "    def __call__(self,\n",
    "                 decoder_inputs,\n",
    "                 dec_initial_state,\n",
    "                 encoder_states,\n",
    "                 enc_padding_mask,\n",
    "                 prev_coverage=None,\n",
    "                 **kwargs):\n",
    "        \n",
    "        inputs = (decoder_inputs,  \n",
    "                                       dec_initial_state,\n",
    "                                       encoder_states,\n",
    "                                       enc_padding_mask,\n",
    "                                       prev_coverage) \n",
    "        return super(AttentionDecoder, self).__call__(inputs, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #unpacked_inputs = tf_utils.unpack_inputs(inputs)\n",
    "\n",
    "        decoder_inputs = inputs[0]\n",
    "        initial_state = inputs[1]\n",
    "        encoder_states = inputs[2]\n",
    "        enc_padding_mask = inputs[3]\n",
    "        prev_coverage =  inputs[4]\n",
    "\n",
    "        outputs = []\n",
    "        attn_dists = []\n",
    "        p_gens = []\n",
    "  \n",
    "        encoder_states = tf.expand_dims(encoder_states, axis=2)  # now is shape (batch_size, attn_len, 1, attn_size)\n",
    "        \n",
    "        encoder_features = self.encoder_layer(encoder_states)  # shape (batch_size,attn_length,1,attention_vec_size)\n",
    "        state =initial_state # [initial_state,initial_state]\n",
    "        #state=[initial_state]*2\n",
    "        batch_size=tf_utils.get_shape_list(encoder_states)[0]\n",
    "\n",
    "        coverage = prev_coverage  # initialize coverage to None or whatever was passed in\n",
    "         \n",
    "        context_vector = tf.zeros([batch_size, self.vector_size])\n",
    "        context_vector.set_shape([None, self.vector_size])  # Ensure the second shape of attention vectors is set.\n",
    "        if self.initial_state_attention:  # true in decode mode\n",
    "            # Re-calculate the context vector from the previous step so that we can pass it through a linear layer\n",
    "            # with this step's input to get a modified version of the input\n",
    "            context_vector, _, coverage = self.attention_layer ( encoder_features=encoder_features,\n",
    "                                                                 decoder_state=state,\n",
    "                                                                 coverage =coverage,\n",
    "                                                                 input_mask=enc_padding_mask )\n",
    "             \n",
    "            # in decode mode, this is what updates the coverage vector\n",
    "\n",
    "        for i, inp in enumerate(decoder_inputs):\n",
    "\n",
    "            # Merge input and previous attentions into one vector x of the same size as inp\n",
    "            input_size = inp.get_shape().with_rank(2)[1]\n",
    "            \n",
    "            if input_size is None:\n",
    "                raise ValueError(\"Could not infer input size from input: %s\" % inp.name)\n",
    "            \n",
    "             \n",
    "            x = self.linear([[inp], [context_vector]])\n",
    "\n",
    "            # Run the decoder RNN cell. cell_output = decoder state\n",
    "            #print(i, x, state)\n",
    "            cell_output, state = self.lstm_layer(x,state)\n",
    "           \n",
    "            # Run the attention mechanism.\n",
    "            if i == 0 and self.initial_state_attention:  # always true in decode mode\n",
    "                context_vector, attn_dist, _ = self.attention_layer (encoder_features=encoder_features,\n",
    "                                                                     decoder_state=state,\n",
    "                                                                     coverage=coverage,\n",
    "                                                                     input_mask=enc_padding_mask)  # don't allow coverage to update\n",
    "            else:\n",
    "                context_vector, attn_dist, coverage = self.attention_layer(encoder_features=encoder_features,\n",
    "                                                                           decoder_state=state,\n",
    "                                                                           coverage=coverage,\n",
    "                                                                           input_mask=enc_padding_mask)\n",
    "            attn_dists.append(attn_dist)\n",
    "\n",
    "            # Calculate p_gen\n",
    "            if self.pointer_gen: \n",
    "                p_gen = self.linear2( [[context_vector],[state[0]], [state[1]], [x]])\n",
    "                # Tensor shape (batch_size, 1)\n",
    "                p_gen = tf.sigmoid(p_gen)\n",
    "                p_gens.append(p_gen)\n",
    "\n",
    "                # Concatenate the cell_output (= decoder state) and the context vector, and pass them through a linear layer\n",
    "                # This is V[s_t, h*_t] + b in the paper\n",
    "                output = self.linear( [[cell_output], [context_vector]])\n",
    "            outputs.append(output)\n",
    "\n",
    "        # If using coverage, reshape it\n",
    "        if coverage is not None:\n",
    "            coverage = tf.reshape(coverage, [batch_size, -1])\n",
    "\n",
    "        return outputs, state, attn_dists, p_gens, coverage\n",
    "    # def compute_output_shape(self,inputShape):\n",
    "    #      #calculate shapes from input shape\n",
    "    #      return [[None,self.max_seq_length,self.hidden_dim],\n",
    "    #              [None,self.hidden_dim],\n",
    "    #              [None, self.hidden_dim],\n",
    "    #              [None, self.hidden_dim],\n",
    "    #              [None, self.hidden_dim],\n",
    "    #              ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initializer(initializer_range=0.02):\n",
    "  \"\"\"Creates a `tf.initializers.truncated_normal` with the given range.\n",
    "\n",
    "  Args:\n",
    "    initializer_range: float, initializer range for stddev.\n",
    "\n",
    "  Returns:\n",
    "    TruncatedNormal initializer with stddev = `initializer_range`.\n",
    "  \"\"\"\n",
    "  return tf.keras.initializers.TruncatedNormal(stddev=initializer_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "seq_len=10\n",
    "feature_size = 12\n",
    "hidden_size=240\n",
    "max_dec_length = 8\n",
    "\n",
    "\n",
    "dec_features=[tf.random.uniform([batch_size,feature_size])]*max_dec_length\n",
    "\n",
    "dec_states=tf.random.uniform([batch_size,feature_size])\n",
    "dec_mask=tf.ones([batch_size,seq_len],tf.float32)\n",
    "enc_states=tf.random.uniform([batch_size, seq_len,feature_size])\n",
    " \n",
    "coverage = tf.random.uniform([batch_size, seq_len,1,1])\n",
    "\n",
    "\n",
    "decoder = AttentionDecoder(hidden_size, feature_size, \n",
    "                                        seq_len, get_initializer(),\n",
    "                                        name=\"attention_decoder\")\n",
    "\n",
    "out = decoder(\n",
    "            dec_features,\n",
    "            dec_states,\n",
    "            enc_states,\n",
    "            dec_mask,\n",
    "            coverage)\n",
    "    \n",
    "    \n",
    "#print(out)\n",
    "\n",
    " \n",
    "\n",
    "#print(get_shape_list(input))\n",
    "#input=tf.random.uniform([ seq_len])\n",
    "#zero_state=tf.zeros([batch_size, feature_size])\n",
    "\n",
    "#linear = LinearLayer(feature_size,False)\n",
    "\n",
    "# print(input)\n",
    "# out=linear(input)\n",
    "# encoder_layer = tf.keras.layers.Conv2D(filters=feature_size, kernel_size=(1, 1), padding=\"SAME\")\n",
    "\n",
    "# inputs = tf.expand_dims(inputs, axis=2)  # now is shape (batch_size, attn_len, 1, attn_size)\n",
    "\n",
    "# enc_feature= encoder_layer(inputs)     \n",
    "\n",
    "# atten=AttentionLayer(feature_size,seq_len,True)\n",
    "\n",
    "# out = atten(encoder_features=enc_feature, decoder_state=dec_states, coverage =coverage, input_mask=input_mask )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 10), dtype=float32, numpy=\n",
       "array([[1.4945861 , 1.6792537 , 1.085821  , 1.547793  , 1.6920732 ,\n",
       "        1.082137  , 1.0859984 , 0.47908726, 0.9617234 , 0.9767699 ],\n",
       "       [1.9037642 , 1.3531944 , 1.8471627 , 1.0240195 , 1.3833439 ,\n",
       "        1.4301822 , 0.77310556, 1.5611751 , 1.5469098 , 0.63561773],\n",
       "       [1.7449133 , 1.0637496 , 1.3419441 , 0.92907566, 1.6138995 ,\n",
       "        0.72120076, 1.827379  , 1.837569  , 0.7337004 , 1.6414684 ],\n",
       "       [1.7412142 , 1.7451642 , 1.1470199 , 1.9235015 , 1.3093983 ,\n",
       "        1.7299534 , 1.0788914 , 0.6208656 , 1.6557912 , 1.5660311 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EmbeddingLookup(tf.keras.layers.Layer):\n",
    "  \"\"\"Looks up words embeddings for id tensor.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               vocab_size,\n",
    "               embedding_size=768,\n",
    "               initializer_range=0.02,\n",
    "               **kwargs):\n",
    "    super(EmbeddingLookup, self).__init__(**kwargs)\n",
    "    self.vocab_size = vocab_size\n",
    "    self.embedding_size = embedding_size\n",
    "    self.initializer_range = initializer_range\n",
    "\n",
    "  def build(self, unused_input_shapes):\n",
    "    \"\"\"Implements build() for the layer.\"\"\"\n",
    "    self.embeddings = self.add_weight(\n",
    "        \"embeddings\",\n",
    "        shape=[self.vocab_size, self.embedding_size],\n",
    "        initializer=get_initializer(self.initializer_range),\n",
    "        dtype=self.dtype)\n",
    "    super(EmbeddingLookup, self).build(unused_input_shapes)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    \"\"\"Implements call() for the layer.\"\"\"\n",
    "\n",
    "    input_shape = tf_utils.get_shape_list(inputs)\n",
    "\n",
    "    flat_input = tf.reshape(inputs, [-1])\n",
    "    output = tf.gather(self.embeddings, flat_input)\n",
    "    output = tf.reshape(output, input_shape + [self.embedding_size])\n",
    "\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReduceStateLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 hidden_dim, **kwargs):\n",
    "        super(ReduceStateLayer, self).__init__(**kwargs)\n",
    "        self.hidden_dim=hidden_dim\n",
    "\n",
    "    def build(self, unused_input_shapes):\n",
    "        hidden_dim = self.hidden_dim\n",
    "        self.w_reduce_c = self.add_weight('w_reduce_c', [hidden_dim * 2, hidden_dim], dtype=tf.float32,\n",
    "                                     initializer=tf.keras.initializers.TruncatedNormal())\n",
    "        self.w_reduce_h = self.add_weight('w_reduce_h', [hidden_dim * 2, hidden_dim], dtype=tf.float32,\n",
    "                                     initializer=tf.keras.initializers.TruncatedNormal())\n",
    "        self.bias_reduce_c = self.add_weight('bias_reduce_c', [hidden_dim], dtype=tf.float32,\n",
    "                                        initializer=tf.keras.initializers.TruncatedNormal())\n",
    "        self.bias_reduce_h = self.add_weight('bias_reduce_h', [hidden_dim], dtype=tf.float32,\n",
    "                                        initializer=tf.keras.initializers.TruncatedNormal())\n",
    "        super(ReduceStateLayer, self).build(unused_input_shapes)\n",
    "\n",
    "    def __call__(self,\n",
    "                 fw_state_h,fw_state_c, bw_state_h,bw_state_c,\n",
    "                 **kwargs):\n",
    "        inputs =  (fw_state_h,fw_state_c, bw_state_h,bw_state_c)\n",
    "\n",
    "        return super(ReduceStateLayer, self).__call__(inputs, **kwargs)\n",
    "    def call(self, inputs):\n",
    "\n",
    "        fw_state_h = inputs[0]\n",
    "        fw_state_c = inputs[1]\n",
    "        bw_state_h = inputs[2]\n",
    "        bw_state_c = inputs[3]\n",
    "\n",
    "        # Apply linear layer\n",
    "        old_c = tf.concat(axis=1, values=[fw_state_c, bw_state_c])  # Concatenation of fw and bw cell\n",
    "        old_h = tf.concat(axis=1, values=[fw_state_h, bw_state_h])  # Concatenation of fw and bw state\n",
    "        new_c = tf.nn.relu(tf.matmul( old_c, self.w_reduce_c) + self.bias_reduce_c)  # Get new cell from old cell\n",
    "        new_h = tf.nn.relu(tf.matmul( old_h, self.w_reduce_h) + self.bias_reduce_h)  # Get new state from old state\n",
    "        \n",
    "        return [new_c, new_h]  # Return new cell and state\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder (tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 hidden_dim,max_seq_length,  **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.max_seq_length=max_seq_length\n",
    "\n",
    "    def build(self, unused_input_shapes):\n",
    "        lstm_layer_fw = tf.keras.layers.LSTM(self.hidden_dim, return_sequences=True, return_state=True)\n",
    "        lstm_layer_bw = tf.keras.layers.LSTM(self.hidden_dim, return_sequences=True, go_backwards=True,\n",
    "                                             return_state=True)\n",
    "        self.bidirection = tf.keras.layers.Bidirectional(lstm_layer_fw,backward_layer=lstm_layer_bw , merge_mode=\"concat\")\n",
    "\n",
    "        self.state_reducer = ReduceStateLayer(self.hidden_dim)\n",
    "\n",
    "        super(Encoder, self).build(unused_input_shapes)\n",
    "\n",
    "    def __call__(self,\n",
    "                 input_word_ids,\n",
    "                 input_mask=None ,\n",
    "                 **kwargs):\n",
    "        inputs = (input_word_ids, input_mask)\n",
    "        return super(Encoder, self).__call__(inputs, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #unpacked_inputs = tf_utils.unpack_inputs(inputs)\n",
    "        input_ids=inputs[0]\n",
    "        masks = inputs[1]\n",
    "        masks = tf.expand_dims(masks, axis=2)\n",
    "\n",
    "        outputs = self.bidirection(input_ids*masks)\n",
    " \n",
    "        encoder_outputs=outputs[0]\n",
    "\n",
    "        fw_state_h,fw_state_ch = outputs[1],outputs[2]\n",
    "        bw_state_h,bw_state_ch = outputs[3],outputs[4]\n",
    "\n",
    "        state = self.state_reducer(fw_state_h,fw_state_ch ,bw_state_h, bw_state_ch)\n",
    "\n",
    "        return encoder_outputs, state\n",
    "    def compute_output_shape(self,inputShape):\n",
    "        #calculate shapes from input shape\n",
    "        return [[None,self.max_seq_length,2*self.hidden_dim],\n",
    "                 [[None,self.hidden_dim],[None,self.hidden_dim]]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PGNetSummaryModel(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               config,\n",
    "               float_type=tf.float32,\n",
    "               **kwargs):\n",
    "    super(PGNetSummaryModel, self).__init__(**kwargs)\n",
    "\n",
    "    self.config = (\n",
    "        PGNetConfig.from_dict(config)\n",
    "        if isinstance(config, dict) else copy.deepcopy(config))\n",
    "\n",
    "    self.float_type = float_type\n",
    "\n",
    "\n",
    "\n",
    "  def build(self, unused_input_shapes):\n",
    "    \"\"\"Implements build() for the layer.\"\"\"\n",
    "    self.embedding_lookup = EmbeddingLookup(self.config.vocab_size,self.config.hidden_size)\n",
    "    self.encoder = Encoder(self.config.hidden_size,self.config.max_seq_length, dynamic=True)\n",
    "    self.decoder = AttentionDecoder(self.config.hidden_size,self.config.hidden_size,\n",
    "                                    self.config.max_seq_length,get_initializer())\n",
    "    self.output_projector = OutputProjectionLayer(self.config.hidden_size,self.config.vocab_size)\n",
    "    self.final_distribution = FinalDistributionLayer(self.config.hidden_size,self.config.vocab_size,self.config.max_oov_size)\n",
    "\n",
    "    super(PGNetSummaryModel, self).build(unused_input_shapes)\n",
    "\n",
    "  def __call__(self,\n",
    "               input_word_ids,\n",
    "               input_mask=None,\n",
    "               answer_ids=None,\n",
    "               answer_mask=None, \n",
    "               **kwargs):\n",
    "    inputs = (input_word_ids, input_mask, answer_ids,answer_mask)\n",
    "    return super(PGNetSummaryModel, self).__call__(inputs, **kwargs)\n",
    "\n",
    "  def call(self, inputs,mode=\"pgnet\"):\n",
    "\n",
    "      input_word_ids = inputs[0]\n",
    "      input_mask = inputs[1]\n",
    "      answer_ids= inputs[2]\n",
    "      answer_mask= inputs[3] \n",
    "\n",
    "      emb_enc_inputs = self.embedding_lookup(input_word_ids)  # tensor with shape (batch_size, max_seq_length, emb_size)\n",
    "      emb_dec_inputs = [self.embedding_lookup(x) for x in tf.unstack(answer_ids, axis=1)]  # list length max_dec_steps containing shape (batch_size, emb_size)\n",
    "\n",
    "      enc_outputs, enc_state = self.encoder(emb_enc_inputs,input_mask )\n",
    " \n",
    "      self._enc_states = enc_outputs\n",
    "\n",
    "      self._dec_in_state = enc_state\n",
    "\n",
    "      if mode==\"encoder\":\n",
    "         return (self._enc_states,self._dec_in_state )\n",
    "\n",
    "      prev_coverage =None # self.prev_coverage #if self.config.mode == \"decode\" and self.config.use_coverage  else None\n",
    "\n",
    "      decoder_outputs, self._dec_out_state, self.attn_dists, self.p_gens, self.coverage = self.decoder(\n",
    "                emb_dec_inputs,\n",
    "                 self._dec_in_state ,\n",
    "                 self._enc_states ,\n",
    "                 input_mask,\n",
    "                 prev_coverage=prev_coverage)\n",
    "      if mode == \"decoder\":\n",
    "           return (decoder_outputs, self._dec_out_state, self.attn_dists, self.p_gens, self.coverage)\n",
    "\n",
    "      vocab_dists=self.output_projector(decoder_outputs)\n",
    "\n",
    "      if self.config.use_pointer_gen:\n",
    "           final_dists = self.final_distribution(vocab_dists, self.attn_dists,self.p_gens, input_word_ids)\n",
    "      else:  # final distribution is just vocabulary distribution\n",
    "           final_dists = vocab_dists\n",
    "\n",
    "      return  final_dists,self.attn_dists\n",
    "\n",
    "  def get_config(self):\n",
    "    config = {\"config\": self.config.to_dict()}\n",
    "    base_config = super(PGNetSummaryModel, self).get_config()\n",
    "    return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputProjectionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 hidden_dim,\n",
    "                 vocab_size,\n",
    "                 **kwargs):\n",
    "        super(OutputProjectionLayer, self).__init__(**kwargs)\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.vocab_size =vocab_size\n",
    "\n",
    "\n",
    "    def build(self, unused_input_shapes):\n",
    "        self.w = self.add_weight('w', [self.hidden_dim, self.vocab_size], dtype=tf.float32, initializer=tf.keras.initializers.TruncatedNormal())\n",
    "        self.w_t = tf.transpose(self.w)\n",
    "        self.v = self.add_weight('v', [self.vocab_size], dtype=tf.float32, initializer=tf.keras.initializers.TruncatedNormal())\n",
    "      \n",
    "\n",
    "    def call(self, inputs):\n",
    "        decoder_outputs = inputs\n",
    "\n",
    "        vocab_scores = []  # vocab_scores is the vocabulary distribution before applying softmax. Each entry on the list corresponds to one decoder step\n",
    "        for i, output in enumerate(decoder_outputs):\n",
    "            vocab_scores.append(tf.matmul(output, self.w)+ self.v)  # apply the linear layer\n",
    "\n",
    "        vocab_dists = [tf.nn.softmax(s) for s in\n",
    "                       vocab_scores]\n",
    "        # The vocabulary distributions. List length max_dec_steps of (batch_size, vsize) arrays. The words are in the order they appear in the vocabulary file.\n",
    "\n",
    "        return vocab_dists\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FinalDistributionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 hidden_dim,\n",
    "                 vocab_size,\n",
    "                 max_oov_size,\n",
    "                 **kwargs):\n",
    "        super(FinalDistributionLayer, self).__init__(**kwargs)\n",
    "\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.vocab_size=vocab_size\n",
    "        self.max_oov_size=max_oov_size\n",
    "\n",
    "    #def build(self, unused_input_shapes):\n",
    "\n",
    "\n",
    "    def __call__(self,\n",
    "                 vocab_dists, attn_dists,p_gens,input_ids,\n",
    "                 **kwargs):\n",
    "        inputs = (vocab_dists, attn_dists,p_gens,input_ids)\n",
    "\n",
    "        return super(FinalDistributionLayer, self).__call__(inputs, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        vocab_dists=inputs[0]\n",
    "        attn_dists=inputs[1]\n",
    "        p_gens=inputs[2]\n",
    "        input_ids=inputs[3]\n",
    "        max_oov_size=self.max_oov_size\n",
    "\n",
    "        vocab_dists = [p_gen * dist for (p_gen, dist) in zip( p_gens, vocab_dists)]\n",
    "        attn_dists = [(1 - p_gen) * dist for (p_gen, dist) in zip( p_gens, attn_dists)]\n",
    " \n",
    "        batch_size = tf_utils.get_shape_list(vocab_dists[0])[0]\n",
    "        \n",
    "        # Concatenate some zeros to each vocabulary dist, to hold the probabilities for in-article OOV words\n",
    "        extended_vsize = self.vocab_size + max_oov_size  # the maximum (over the batch) size of the extended vocabulary\n",
    "        extra_zeros = tf.zeros(( batch_size,  max_oov_size))\n",
    "        vocab_dists_extended = [tf.concat(axis=1, values=[dist, extra_zeros]) for dist in\n",
    "                                vocab_dists]  # list length max_dec_steps of shape (batch_size, extended_vsize)\n",
    "\n",
    "        # Project the values in the attention distributions onto the appropriate entries in the final distributions\n",
    "        # This means that if a_i = 0.1 and the ith encoder word is w, and w has index 500 in the vocabulary, then we add 0.1 onto the 500th entry of the final distribution\n",
    "        # This is done for each decoder timestep.\n",
    "        # This is fiddly; we use tf.scatter_nd to do the projection\n",
    "        batch_nums = tf.range(0, limit= batch_size)  # shape (batch_size)\n",
    "        batch_nums = tf.expand_dims(batch_nums, 1)  # shape (batch_size, 1)\n",
    "        attn_len =  tf_utils.get_shape_list(input_ids)[1]  # number of states we attend over\n",
    "        batch_nums = tf.tile(batch_nums, [1, attn_len])  # shape (batch_size, attn_len)\n",
    "        indices = tf.stack((batch_nums,  input_ids), axis=2)  # shape (batch_size, enc_t, 2)\n",
    "        shape = [ batch_size, extended_vsize]\n",
    "        \n",
    "        attn_dists_projected = [tf.scatter_nd(indices, copy_dist, shape) for copy_dist in\n",
    "                                attn_dists]  # list length max_dec_steps (batch_size, extended_vsize)\n",
    "\n",
    "        # Add the vocab distributions and the copy distributions together to get the final distributions\n",
    "        # final_dists is a list length max_dec_steps; each entry is a tensor shape (batch_size, extended_vsize) giving the final distribution for that decoder timestep\n",
    "        # Note that for decoder timesteps and examples corresponding to a [PAD] token, this is junk - ignore.\n",
    "        final_dists = [vocab_dist + copy_dist for (vocab_dist, copy_dist) in\n",
    "                       zip(vocab_dists_extended, attn_dists_projected)]\n",
    "\n",
    "        return final_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_len: 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import bert.bert_modeling as bert_modeling\n",
    "import copy \n",
    "\n",
    "batch_size = 4\n",
    "seq_len=10\n",
    "feature_size = 12\n",
    "hidden_size=12\n",
    "max_dec_length = 8\n",
    "max_oov = 11\n",
    "vocab_size = 3000\n",
    "float_type=tf.float32\n",
    "\n",
    "bert_config = bert_modeling.BertConfig(vocab_size)\n",
    "\n",
    "bert_config.add_from_dict({\"hidden_size\":hidden_size, \n",
    "                           \"max_seq_length\":seq_len,\n",
    "                           \"use_pointer_gen\":True,\n",
    "                           \"max_oov_size\":max_oov})\n",
    "\n",
    "input_word_ids = np.random.randint(vocab_size, size=(batch_size,seq_len),dtype=np.int32)\n",
    "masks=tf.ones([batch_size,seq_len],tf.float32)\n",
    "\n",
    " \n",
    "#print(oov_ids)\n",
    "answer_ids=np.random.randint(vocab_size, size=(batch_size,max_dec_length))\n",
    "answer_mask=tf.ones([batch_size,max_dec_length],tf.float32)\n",
    "\n",
    "pgnet_model_layer =PGNetSummaryModel(config=bert_config ,\n",
    "                                                  float_type=float_type,\n",
    "                                                 name='pgnet_summary_model')\n",
    "\n",
    "\n",
    "final_dists, attn_dists = pgnet_model_layer(  input_word_ids,\n",
    "                                                masks,\n",
    "                                                answer_ids,\n",
    "                                                answer_mask \n",
    "                                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListWrapper([<tf.Tensor: shape=(4, 10), dtype=float32, numpy=\n",
       "array([[0.09971954, 0.09981675, 0.10018633, 0.10011055, 0.10031537,\n",
       "        0.10050201, 0.09985542, 0.0998798 , 0.09986451, 0.09974983],\n",
       "       [0.10005995, 0.10005333, 0.10025822, 0.09989783, 0.09962853,\n",
       "        0.09992645, 0.09980742, 0.09966271, 0.10031735, 0.10038821],\n",
       "       [0.09967137, 0.09958483, 0.09996431, 0.09994293, 0.09985147,\n",
       "        0.10009833, 0.10029086, 0.10019293, 0.10028132, 0.10012164],\n",
       "       [0.0999478 , 0.10043196, 0.10009155, 0.10033999, 0.10009501,\n",
       "        0.09973274, 0.09990396, 0.09998098, 0.09963658, 0.09983946]],\n",
       "      dtype=float32)>, <tf.Tensor: shape=(4, 10), dtype=float32, numpy=\n",
       "array([[0.09971951, 0.09981698, 0.10018635, 0.10011049, 0.10031542,\n",
       "        0.10050216, 0.09985526, 0.0998797 , 0.09986446, 0.09974967],\n",
       "       [0.10006024, 0.10005345, 0.10025822, 0.09989749, 0.09962828,\n",
       "        0.0999262 , 0.09980732, 0.09966278, 0.10031758, 0.10038846],\n",
       "       [0.09967156, 0.09958502, 0.09996435, 0.09994314, 0.09985174,\n",
       "        0.10009855, 0.10029089, 0.10019273, 0.10028093, 0.10012108],\n",
       "       [0.0999479 , 0.10043232, 0.10009164, 0.10034025, 0.10009529,\n",
       "        0.09973254, 0.09990419, 0.09998062, 0.09963607, 0.0998392 ]],\n",
       "      dtype=float32)>, <tf.Tensor: shape=(4, 10), dtype=float32, numpy=\n",
       "array([[0.0997107 , 0.09981111, 0.10019202, 0.1001153 , 0.10032561,\n",
       "        0.10051667, 0.09985144, 0.09987568, 0.09985936, 0.09974209],\n",
       "       [0.10006235, 0.10005635, 0.10026637, 0.09989482, 0.09961634,\n",
       "        0.0999242 , 0.09980202, 0.09965143, 0.10032656, 0.1003996 ],\n",
       "       [0.09966028, 0.0995715 , 0.09996342, 0.0999421 , 0.09984713,\n",
       "        0.10010148, 0.10029913, 0.10019957, 0.10029034, 0.10012512],\n",
       "       [0.09994609, 0.10044485, 0.10009446, 0.10035048, 0.10009752,\n",
       "        0.09972518, 0.09989939, 0.09998064, 0.0996258 , 0.09983551]],\n",
       "      dtype=float32)>, <tf.Tensor: shape=(4, 10), dtype=float32, numpy=\n",
       "array([[0.09970318, 0.09980629, 0.10019667, 0.10012047, 0.10033461,\n",
       "        0.10052844, 0.09984911, 0.0998717 , 0.09985394, 0.09973563],\n",
       "       [0.1000644 , 0.10005971, 0.10027341, 0.09989267, 0.09960567,\n",
       "        0.09992271, 0.09979806, 0.09964126, 0.10033377, 0.10040835],\n",
       "       [0.0996502 , 0.09955981, 0.09996285, 0.09994266, 0.09984443,\n",
       "        0.10010436, 0.10030568, 0.10020507, 0.10029753, 0.10012744],\n",
       "       [0.09994388, 0.10045531, 0.1000974 , 0.10035973, 0.10009935,\n",
       "        0.09971935, 0.09989346, 0.09998097, 0.09961742, 0.09983305]],\n",
       "      dtype=float32)>, <tf.Tensor: shape=(4, 10), dtype=float32, numpy=\n",
       "array([[0.09969703, 0.09980213, 0.10020032, 0.10012606, 0.10034224,\n",
       "        0.10053702, 0.09984791, 0.09986799, 0.09984862, 0.09973068],\n",
       "       [0.10006665, 0.10006355, 0.10027885, 0.09989137, 0.09959695,\n",
       "        0.09992194, 0.09979592, 0.09963285, 0.1003384 , 0.10041358],\n",
       "       [0.09964066, 0.09954911, 0.09996235, 0.09994358, 0.0998417 ,\n",
       "        0.10010627, 0.1003105 , 0.10021063, 0.10030483, 0.10013032],\n",
       "       [0.0999423 , 0.10046343, 0.10009997, 0.10036715, 0.10010055,\n",
       "        0.0997154 , 0.09988743, 0.09998123, 0.09961064, 0.09983188]],\n",
       "      dtype=float32)>, <tf.Tensor: shape=(4, 10), dtype=float32, numpy=\n",
       "array([[0.0996929 , 0.09979954, 0.10020258, 0.10013166, 0.100348  ,\n",
       "        0.10054206, 0.09984826, 0.09986457, 0.09984319, 0.09972719],\n",
       "       [0.10006882, 0.10006749, 0.10028261, 0.09989076, 0.0995903 ,\n",
       "        0.0999219 , 0.09979525, 0.09962639, 0.10034079, 0.10041573],\n",
       "       [0.09963324, 0.09954154, 0.09996253, 0.09994592, 0.09984087,\n",
       "        0.10010777, 0.10031295, 0.10021466, 0.10030942, 0.1001311 ],\n",
       "       [0.09994039, 0.10046849, 0.10010259, 0.10037271, 0.10010082,\n",
       "        0.09971355, 0.09988019, 0.09998202, 0.09960677, 0.09983243]],\n",
       "      dtype=float32)>, <tf.Tensor: shape=(4, 10), dtype=float32, numpy=\n",
       "array([[0.09969022, 0.09979784, 0.10020364, 0.10013743, 0.10035214,\n",
       "        0.10054369, 0.09985041, 0.09986147, 0.09983791, 0.09972522],\n",
       "       [0.10007031, 0.10007188, 0.10028493, 0.09989127, 0.09958566,\n",
       "        0.09992252, 0.09979645, 0.09962136, 0.10034068, 0.10041501],\n",
       "       [0.09962763, 0.09953643, 0.09996294, 0.09994917, 0.09984095,\n",
       "        0.10010849, 0.10031294, 0.10021777, 0.10031265, 0.10013106],\n",
       "       [0.09993844, 0.1004713 , 0.10010485, 0.10037747, 0.10010141,\n",
       "        0.09971319, 0.09987324, 0.09998281, 0.09960423, 0.09983309]],\n",
       "      dtype=float32)>, <tf.Tensor: shape=(4, 10), dtype=float32, numpy=\n",
       "array([[0.09968901, 0.09979641, 0.10020394, 0.10014334, 0.10035466,\n",
       "        0.10054252, 0.09985312, 0.09985865, 0.09983336, 0.09972508],\n",
       "       [0.10007136, 0.1000763 , 0.10028587, 0.09989226, 0.09958268,\n",
       "        0.09992348, 0.0997986 , 0.09961775, 0.10033888, 0.10041282],\n",
       "       [0.09962407, 0.09953409, 0.09996396, 0.09995406, 0.09984323,\n",
       "        0.10010916, 0.10031037, 0.10021896, 0.10031295, 0.10012914],\n",
       "       [0.0999379 , 0.10047047, 0.10010626, 0.10037822, 0.10009982,\n",
       "        0.09971572, 0.09986588, 0.09998378, 0.09960509, 0.09983685]],\n",
       "      dtype=float32)>])"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3002 3002 3001 3004 3003]\n",
      " [3001 3004 3004 3003 3001]\n",
      " [3004 3003 3004 3003 3004]\n",
      " [3004 3000 3000 3001 3004]\n",
      " [3000 3004 3002 3002 3002]]\n",
      "tf.Tensor(\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]], shape=(5, 30), dtype=int32)\n",
      "indices: tf.Tensor(\n",
      "[[[   0  991]\n",
      "  [   0 2577]\n",
      "  [   0  603]\n",
      "  [   0 1900]\n",
      "  [   0  343]\n",
      "  [   0 1173]\n",
      "  [   0  232]\n",
      "  [   0 1571]\n",
      "  [   0 1715]\n",
      "  [   0 1679]\n",
      "  [   0 1429]\n",
      "  [   0 2389]\n",
      "  [   0 1546]\n",
      "  [   0  540]\n",
      "  [   0 1864]\n",
      "  [   0 1541]\n",
      "  [   0  812]\n",
      "  [   0 1256]\n",
      "  [   0  965]\n",
      "  [   0 1988]\n",
      "  [   0 1171]\n",
      "  [   0  241]\n",
      "  [   0  204]\n",
      "  [   0 2577]\n",
      "  [   0 1058]\n",
      "  [   0 2442]\n",
      "  [   0 1463]\n",
      "  [   0   80]\n",
      "  [   0 2389]\n",
      "  [   0 1628]]\n",
      "\n",
      " [[   1 2905]\n",
      "  [   1  845]\n",
      "  [   1 1733]\n",
      "  [   1  575]\n",
      "  [   1 1027]\n",
      "  [   1 1995]\n",
      "  [   1  274]\n",
      "  [   1 2169]\n",
      "  [   1 1130]\n",
      "  [   1 2374]\n",
      "  [   1 2670]\n",
      "  [   1  651]\n",
      "  [   1  134]\n",
      "  [   1 2203]\n",
      "  [   1 1271]\n",
      "  [   1 1255]\n",
      "  [   1 1207]\n",
      "  [   1 2797]\n",
      "  [   1  555]\n",
      "  [   1  265]\n",
      "  [   1 2807]\n",
      "  [   1  340]\n",
      "  [   1  439]\n",
      "  [   1 2363]\n",
      "  [   1 2949]\n",
      "  [   1 1979]\n",
      "  [   1 2479]\n",
      "  [   1  467]\n",
      "  [   1 2368]\n",
      "  [   1 2651]]\n",
      "\n",
      " [[   2  150]\n",
      "  [   2 2352]\n",
      "  [   2 2367]\n",
      "  [   2  441]\n",
      "  [   2  187]\n",
      "  [   2 2702]\n",
      "  [   2 2626]\n",
      "  [   2 1024]\n",
      "  [   2 2375]\n",
      "  [   2 2646]\n",
      "  [   2 2043]\n",
      "  [   2 1905]\n",
      "  [   2 2674]\n",
      "  [   2 1959]\n",
      "  [   2 2477]\n",
      "  [   2  320]\n",
      "  [   2 2890]\n",
      "  [   2 2939]\n",
      "  [   2 2075]\n",
      "  [   2  284]\n",
      "  [   2 2459]\n",
      "  [   2 2356]\n",
      "  [   2  501]\n",
      "  [   2  805]\n",
      "  [   2 1725]\n",
      "  [   2   98]\n",
      "  [   2  735]\n",
      "  [   2 1099]\n",
      "  [   2 2519]\n",
      "  [   2 2416]]\n",
      "\n",
      " [[   3 2118]\n",
      "  [   3 2448]\n",
      "  [   3 1123]\n",
      "  [   3  503]\n",
      "  [   3  192]\n",
      "  [   3 1709]\n",
      "  [   3  446]\n",
      "  [   3 1039]\n",
      "  [   3   13]\n",
      "  [   3 1212]\n",
      "  [   3 2285]\n",
      "  [   3  595]\n",
      "  [   3  718]\n",
      "  [   3 1099]\n",
      "  [   3 1910]\n",
      "  [   3 2863]\n",
      "  [   3 2693]\n",
      "  [   3 2935]\n",
      "  [   3 1260]\n",
      "  [   3  796]\n",
      "  [   3 2847]\n",
      "  [   3 2761]\n",
      "  [   3 1276]\n",
      "  [   3 1738]\n",
      "  [   3 1817]\n",
      "  [   3 1105]\n",
      "  [   3  180]\n",
      "  [   3 1289]\n",
      "  [   3  193]\n",
      "  [   3  597]]\n",
      "\n",
      " [[   4 1205]\n",
      "  [   4  397]\n",
      "  [   4 1942]\n",
      "  [   4 1490]\n",
      "  [   4  606]\n",
      "  [   4  457]\n",
      "  [   4 1200]\n",
      "  [   4 1853]\n",
      "  [   4 2363]\n",
      "  [   4 1809]\n",
      "  [   4 1992]\n",
      "  [   4 2576]\n",
      "  [   4  316]\n",
      "  [   4 2746]\n",
      "  [   4  641]\n",
      "  [   4 1909]\n",
      "  [   4 1727]\n",
      "  [   4 2782]\n",
      "  [   4 2456]\n",
      "  [   4 2744]\n",
      "  [   4 1867]\n",
      "  [   4 1823]\n",
      "  [   4 2392]\n",
      "  [   4 2946]\n",
      "  [   4 1918]\n",
      "  [   4 1173]\n",
      "  [   4 1996]\n",
      "  [   4 2873]\n",
      "  [   4 2051]\n",
      "  [   4 1701]]], shape=(5, 30, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "batch_size=5\n",
    "max_oov_size=5\n",
    "vocab_size=3000\n",
    "seq_len=30\n",
    "extended_vsize = vocab_size + max_oov_size\n",
    "input_word_ids = np.random.randint(vocab_size, size=(batch_size,seq_len))\n",
    "oov_ids = np.random.randint(vocab_size,high=vocab_size+max_oov_size, size=[batch_size,max_oov_size],dtype=np.int64)\n",
    "print(oov_ids)\n",
    "\n",
    "batch_nums = tf.range(0, limit= batch_size)  # shape (batch_size)\n",
    "batch_nums = tf.expand_dims(batch_nums, 1)  # shape (batch_size, 1)\n",
    "attn_len = seq_len  # number of states we attend over\n",
    "batch_nums = tf.tile(batch_nums, [1, attn_len])  # shape (batch_size, attn_len)\n",
    "print (batch_nums)\n",
    "indices = tf.stack((batch_nums,  input_word_ids), axis=2)  # shape (batch_size, enc_t, 2)\n",
    "shape = [ batch_size, extended_vsize]\n",
    "print ('indices:',indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6]]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[1,2,3],[4,5,6]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
