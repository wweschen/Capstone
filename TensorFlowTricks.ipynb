{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given:  tf.Tensor(\n",
      "[[[1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]]\n",
      "\n",
      " [[1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]]\n",
      "\n",
      " [[1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]]], shape=(3, 5, 4), dtype=int32)\n",
      "fetch indices:  tf.Tensor(\n",
      "[[0 1 2 3 3]\n",
      " [0 1 2 3 3]\n",
      " [0 1 2 3 3]], shape=(3, 5), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=int32, numpy=\n",
       "array([[1, 2, 3, 4, 4],\n",
       "       [1, 2, 3, 4, 4],\n",
       "       [1, 2, 3, 4, 4]], dtype=int32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def batch_fetch_element_per_group(data,idx):\n",
    "    #here data is of shape [?,m,n] ? is the data batch size, m -number of groups, n-number of candidates in each group\n",
    "    #idx is of shape [?,m] m - index to select a particular target from each group, so we have m of them.\n",
    "    # output would be [?,m], selected targets for all groups\n",
    "    \n",
    "    nRows = tf.shape(data)[0]  \n",
    "    #print(nRows)\n",
    "    \n",
    "    nCols = tf.constant(tf.shape(data)[1] , dtype=tf.int32) \n",
    "    #print(nCols)\n",
    "    \n",
    "    m1 = tf.reshape(tf.tile(tf.range(nCols), [nRows]),\n",
    "                                           shape=[nRows, nCols])\n",
    "    #print(m1)\n",
    "    m2 = tf.transpose(tf.reshape(tf.tile(tf.range(nRows), [nCols]),\n",
    "                                            shape=[nCols, nRows]))\n",
    "    #print(m2)\n",
    "    indices = tf.stack([m2, m1, idx], axis=-1)\n",
    "    # indices should be of shape [?, 5, 3] with indices[i,j]==[i,j,idx[i,j]]\n",
    "    #print(indices)\n",
    "    output = tf.gather_nd(data, indices=indices)\n",
    "    #print(output)\n",
    "    return output\n",
    "\n",
    "data = tf.constant([[[1,2,3,4],[1,2,3,4],[1,2,3,4],[1,2,3,4],[1,2,3,4]],\n",
    "                   [[1,2,3,4],[1,2,3,4],[1,2,3,4],[1,2,3,4],[1,2,3,4]],\n",
    "                   [[1,2,3,4],[1,2,3,4],[1,2,3,4],[1,2,3,4],[1,2,3,4]]])\n",
    "\n",
    "idx= tf.constant ([[0,1,2,3,3],[0,1,2,3,3],[0,1,2,3,3]])\n",
    "\n",
    " \n",
    "print('given: ',data)\n",
    "print('fetch indices: ',idx)\n",
    "batch_fetch_element_per_group(data,idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=int32, numpy=10>,\n",
       " <tf.Tensor: shape=(2048, 2), dtype=float32, numpy=\n",
       " array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        ...,\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32)>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to get the best span text given the logits of start and end points.\n",
    "i0 = tf.constant(0)\n",
    "m0 = tf.ones([2, 2])\n",
    "c = lambda i, m: i < 10\n",
    "b = lambda i, m: [i+1, tf.concat([m, m], axis=0)]\n",
    "tf.while_loop(\n",
    "    c, b, loop_vars=[i0, m0],\n",
    "    shape_invariants=[i0.get_shape(), tf.TensorShape([None, 2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "dataset = tf.data.Dataset.from_tensor_slices([[1,1,1],[2,2,2]])\n",
    "# Create a dataset with data of [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    fruits = {\n",
    "        'apple':1,\n",
    "        'orange':2,\n",
    "        'banana':3\n",
    "    }\n",
    "    \n",
    "\t#if key 'apple' exists in fruits?\n",
    "    if 'applex'   in fruits:\n",
    "        print(fruits['apple'])\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAAAAAAAA\n",
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_marker_string(maker,len):\n",
    "    m=[]\n",
    "    for i in range(len):\n",
    "        m.append(maker)\n",
    "    return ''.join(m)\n",
    "\n",
    "\n",
    "marker= create_marker_string('A',10)\n",
    "print(marker)\n",
    "print(list(marker))\n",
    "len('asdf asdf asdfs'.split(' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When was the Vat formally opened?', 'what is the library for?']\n",
      "['It was formally established in 1475', 'research']\n"
     ]
    }
   ],
   "source": [
    "m=' QQQQQQAAAAAA QQQQQA'\n",
    "\n",
    "qa=' When was the Vat formally opened? It was formally established in 1475 what is the library for? research'\n",
    "\n",
    "def reverse_qa(qa_str, marker_str):\n",
    "    ques=[]\n",
    "    ans=[]\n",
    "    \n",
    "    qas=[] \n",
    "    k=0\n",
    "    marks = marker_str.split()\n",
    "    qas_str =qa_str.split()\n",
    "    for i in range(len(marks)):\n",
    "        l=len(marks[i]) \n",
    "        qas.append(qas_str[k:k+l])\n",
    "        k+=l  \n",
    "    \n",
    "    \n",
    "    for ms,qas in zip(marks,qas):\n",
    "        q=[]\n",
    "        a=[] \n",
    "        for m,qa in zip(ms,qas):\n",
    "            if m =='Q':\n",
    "               q.append(qa)\n",
    "            if m == 'A':\n",
    "               a.append(qa)\n",
    "        ques.append(' '.join(q))\n",
    "        ans.append(' '.join(a))\n",
    "    return ques,ans\n",
    "\n",
    "ques,ans=reverse_qa(qa,m)\n",
    "print(ques)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When was the Vat formally opened?'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when', 'was', 'the', 'va', '##t', 'formally', 'opened', '?', 'it', 'was', 'formally', 'established', 'in', '147', '##5', 'what', 'is', 'the', 'library', 'for', '?', 'research']\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from bert import tokenization\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "        vocab_file='/Users/wweschen/tf2/capstone/pretrained/uncased_L-12_H-768_A-12/vocab.txt', do_lower_case=True)\n",
    "def tokenize_qa_history(ques,ans):\n",
    "    qas_tokens=[]\n",
    "    q_type_ids=[]\n",
    "    ans_tokens=[]\n",
    "    qa_history_tokens=[]\n",
    "    qa_history_type_ids=[]\n",
    "\n",
    "    for q,a in zip(ques,ans): \n",
    "        qas_tokens.append(tokenizer.tokenize(''.join(q)))\n",
    "        ans_tokens.append(tokenizer.tokenize(''.join(a)))\n",
    "\n",
    "    for q, a in zip(qas_tokens,ans_tokens):\n",
    "        q_type_ids=[]\n",
    "        a_type_ids=[]\n",
    "        for i in range(len(q)):\n",
    "          q_type_ids.append(2)\n",
    "        qa_history_tokens.extend(q)\n",
    "        qa_history_type_ids.extend(q_type_ids)\n",
    "\n",
    "        for i in range(len(a)):\n",
    "          a_type_ids.append(3)\n",
    "        qa_history_tokens.extend(a)\n",
    "        qa_history_type_ids.extend(a_type_ids)\n",
    "\n",
    "    return  qa_history_tokens,qa_history_type_ids\n",
    "\n",
    "qas,qas_seq= tokenize_qa_history(ques,ans)\n",
    "print(qas)\n",
    "print(qas_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i',\n",
       "  't',\n",
       "  'w',\n",
       "  'a',\n",
       "  's',\n",
       "  'f',\n",
       "  'o',\n",
       "  'r',\n",
       "  'm',\n",
       "  'a',\n",
       "  'l',\n",
       "  'l',\n",
       "  'y',\n",
       "  'e',\n",
       "  's',\n",
       "  't',\n",
       "  'a',\n",
       "  'b',\n",
       "  'l',\n",
       "  'i',\n",
       "  's',\n",
       "  'h',\n",
       "  'e',\n",
       "  'd',\n",
       "  'i',\n",
       "  'n',\n",
       "  '1',\n",
       "  '4',\n",
       "  '7',\n",
       "  '5'],\n",
       " ['r', 'e', 's', 'e', 'a', 'r', 'c', 'h']]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qas_tokens\n",
    "ans_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n",
      "(3, 2, 4) (2, 3, 4) (2, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1,4,5,4],[1, 4,6,4]])\n",
    "print(x.shape)\n",
    "y = tf.constant([[1,3,5,4],[1, 7,6,5]])\n",
    "z = tf.constant([[1,5,5,6],[1, 8,6,8]])\n",
    "m=tf.stack([x, y, z])  # [[1, 4], [2, 5], [3, 6]] (Pack along first dim.)\n",
    "n=tf.stack([x, y, z], axis=1)  # [[1, 2, 3], [4, 5, 6]]\n",
    "p=tf.stack([x, y, z], axis=2)  \n",
    "print(m.shape,n.shape,p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 2]\n",
      "tf.Tensor(\n",
      "[[[0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]]], shape=(2, 3, 2), dtype=int32)\n",
      "shape is: [6 2]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "my_tensor = tf.constant(0, shape=[6 ,2]) # Tensor('Const:0' shape=(6, 2) dtype=int32)\n",
    "my_dynamic_shape = tf.shape(my_tensor) \n",
    "print(my_dynamic_shape.numpy())\n",
    "# -> Tensor('Shape:0' shape=(2,) dtype=int32)\n",
    "# The shape of the tensor \"Shape\" is (2,) because my_tensor is a 2-D tensor\n",
    "# so the dynamic shape is a 1-D tensor containing sizes of my_tensor dimensions\n",
    "# and in this case, we have 2 dimensions.\n",
    "\n",
    "my_reshaped_tensor = tf.reshape(my_tensor, [2, 3, 2]) \n",
    "print(my_reshaped_tensor)\n",
    "# -> Tensor('Reshape:0' shape=(2, 3, 2) dtype=int32)\n",
    "\n",
    "# To access a dynamic shape value, you need to run your graph and feed any placeholder that your tensor my depended upon:\n",
    "@tf.function\n",
    "def get_dynamic_shape(x):\n",
    "    return tf.shape(x)\n",
    "\n",
    "print('shape is:',get_dynamic_shape([[1., 2.], [1., 2.], [1., 2.], [1., 2.], [1., 2.], [1., 2.]]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_span_prediction(ids,start_logits, end_logits):\n",
    "    _, starts = tf.nn.top_k(start_logits, k=1)\n",
    "    _, ends = tf.nn.top_k(end_logits, k=1)\n",
    "    \n",
    "    batch_size = tf.shape(ids)[0]\n",
    "    str_len = tf.shape(ids)[1]\n",
    "    \n",
    "    span_array = []\n",
    "    mask_array = []\n",
    "\n",
    "    \n",
    "    def condition(id_str,start,end,i):\n",
    "        return tf.less(i,batch_size) && tf.less(j,str_len)\n",
    "        \n",
    "    \n",
    "    def body(id_str,start,end,i):\n",
    "       \n",
    "        span_array.append(tf.strided_slice(id_str, start, end + 1))\n",
    "        mask_array.append(tf.strided_slice(tf.fill([str_len], 1), start , end  + 1))\n",
    "        \n",
    "        def inside_body(i,j):\n",
    "            span_array[i] = tf.concat([span_array[i], [0]], axis=0)\n",
    "            mask_array[i] = tf.concat([mask_array[i], [0]], axis=0)\n",
    "            j=j+1\n",
    "        tf.while_loop(\n",
    "            cond = lambda i,j: tf.less(j,str_len-len(span_array[i])),\n",
    "            body=inside_body,\n",
    "            loop_vars=[i,j]\n",
    "        )\n",
    "        \n",
    "        i=i+1\n",
    "    \n",
    "    returned = tf.while_loop(\n",
    "        cond = condition,\n",
    "        body= body,\n",
    "        loop_vars=[ids,starts,ends,0]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[0.04177725, 0.7987331 , 0.52792335, 0.21513033],\n",
       "        [0.10943258, 1.3330783 , 0.6829629 , 0.65409565],\n",
       "        [0.91260433, 1.6601439 , 1.1433008 , 0.9245236 ]],\n",
       "\n",
       "       [[0.8501966 , 0.67991745, 0.7845633 , 0.66094744],\n",
       "        [1.4661397 , 1.6632185 , 0.7948631 , 0.992458  ],\n",
       "        [2.0233245 , 1.9321158 , 1.4580377 , 1.3229467 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 3\n",
    "feature_size = 4\n",
    "\n",
    "def rnn_step(inp, state):\n",
    "  return inp + state\n",
    "\n",
    "@tf.function\n",
    "def dynamic_rnn(rnn_step, input_data, initial_state):\n",
    "  # [batch, time, features] -> [time, batch, features]\n",
    "  input_data = tf.transpose(input_data, [1, 0, 2])\n",
    "  max_seq_len = input_data.shape[0]\n",
    "\n",
    "  states = tf.TensorArray(tf.float32, size=max_seq_len)\n",
    "  state = initial_state\n",
    "  for i in tf.range(max_seq_len):\n",
    "    state = rnn_step(input_data[i], state)\n",
    "    states = states.write(i, state)\n",
    "  return tf.transpose(states.stack(), [1, 0, 2])\n",
    "  \n",
    "dynamic_rnn(rnn_step,\n",
    "            tf.random.uniform([batch_size, seq_len, feature_size]),\n",
    "            tf.zeros([batch_size, feature_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_span_prediction(ids,start_logits, end_logits):\n",
    "    _, starts = tf.nn.top_k(start_logits, k=1)\n",
    "    _, ends = tf.nn.top_k(end_logits, k=1)\n",
    "    \n",
    "    batch_size = tf.shape(ids)[0]\n",
    "    str_len = tf.shape(ids)[1]\n",
    "    \n",
    "    span_array = []\n",
    "    mask_array = []\n",
    "    \n",
    "    dynamic_rnn(rnn_step, ids,starts,ends)\n",
    "    \n",
    "    def rnn_step(inp, state):\n",
    "    return inp + state\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def dynamic_rnn(rnn_step, input_data, starts,ends):\n",
    "      # [batch, time, features] -> [time, batch, features]\n",
    "      input_data = tf.transpose(input_data, [1, 0])\n",
    "      max_seq_len = input_data.shape[0]\n",
    "\n",
    "      spans = tf.TensorArray(tf.float32, size=max_seq_len)\n",
    "      masks = tf.TensorArray(tf.float32, size=max_seq_len)\n",
    "      start = starts[0]\n",
    "      end = ends[0]\n",
    "      for i in tf.range(max_seq_len):\n",
    "        state = rnn_step(input_data[i], state)\n",
    "        states = states.write(i, state)\n",
    "      return tf.transpose(states.stack(), [1, 0, 2])\n",
    "  \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Could not read index 0 twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-29cc3fded517>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mspans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mspans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mget_best_span_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-29cc3fded517>\u001b[0m in \u001b[0;36mget_best_span_prediction\u001b[0;34m(ids, starts, ends)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspan_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mspan_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, index, name)\u001b[0m\n\u001b[1;32m   1138\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mat\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \"\"\"\n\u001b[0;32m-> 1140\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_implementation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0;34m\"Could not read index %d twice because it was cleared after \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;34m\"a previous read (perhaps try setting clear_after_read = false?)\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m             index)\n\u001b[0m\u001b[1;32m    774\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Could not read index 0 twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?)"
     ]
    }
   ],
   "source": [
    "max_seq_length=400\n",
    "\n",
    "    # ids = tf.keras.layers.Input(\n",
    "    #       shape=(max_seq_length,), dtype=tf.int32, name='input_ids')\n",
    "    # starts = tf.keras.layers.Input(\n",
    "    #       shape=(1,), dtype=tf.int32, name='starts')\n",
    "\n",
    "    # ends = tf.keras.layers.Input(\n",
    "    #       shape=(1,), dtype=tf.int32, name='ends')\n",
    "\n",
    "ids = tf.constant([[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5]])\n",
    "starts = tf.constant([[0],[0],[1],[2],[3],[3]])\n",
    "ends = tf.constant([[3],[4],[4],[4],[4],[4]])\n",
    "\n",
    "#@tf.function\n",
    "def get_best_span_prediction(ids,starts, ends):\n",
    "    span_array = tf.TensorArray(dtype=tf.int32, size=0,dynamic_size=True)\n",
    "    mask_array =  tf.TensorArray(dtype=tf.int32, size=0,dynamic_size=True)\n",
    "\n",
    "\n",
    "    batch_size =tf.shape(ids)[0]\n",
    "    str_len = tf.shape(ids)[0]\n",
    "    i=0\n",
    "    while(i<batch_size):\n",
    "        span_array.write(i,tf.strided_slice(ids[i], starts[i], ends[i] + 1))\n",
    "        mask_array.write(i,tf.strided_slice(tf.fill([str_len], 1), starts[i], ends[i] + 1))\n",
    "        j=0\n",
    "        while j <(str_len - len(span_array.read(i))):\n",
    "            x=tf.concat([span_array.read(i), tf.constant([0])], axis=0)\n",
    "            span_array.write(i,x)\n",
    "            y=tf.concat([mask_array.read(i), tf.constant([0])], axis=0)\n",
    "            mask_array.write(i,y )\n",
    "            j=j+1\n",
    "        i=i+1\n",
    "        \n",
    "    spans =  span_array.stack()\n",
    "    masks =  mask_array.stack()\n",
    "\n",
    "    return (spans,masks)\n",
    "    \n",
    "spans,masks =get_best_span_prediction(ids,starts, ends)\n",
    "print(spans,masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((32,), (1,), (1,)), types: (tf.int64, tf.int64, tf.int64)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((32,), (1,), (1,)), types: (tf.int64, tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "ids = np.random.randint(30000, size=(1000,32))\n",
    "starts = np.random.randint(low=0,high=15,size=(1000,1))\n",
    "ends = np.random.randint(low=16,high=32,size=(1000,1))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((ids,starts,ends))\n",
    "print( dataset)  \n",
    "dataset.batch(10)\n",
    "dataset.repeat(100)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-b58ed8dcdcae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mspan_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmask_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    757\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \"\"\"\n\u001b[0;32m--> 759\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_bool_casting\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m       \u001b[0;31m# Default: V1-style Graph execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_in_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"using a `tf.Tensor` as a Python `bool`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_in_graph_mode\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    515\u001b[0m     raise errors.OperatorNotAllowedInGraphError(\n\u001b[1;32m    516\u001b[0m         \u001b[0;34m\"{} is not allowed in Graph execution. Use Eager execution or decorate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \" this function with @tf.function.\".format(task))\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function."
     ]
    }
   ],
   "source": [
    "ids = tf.keras.layers.Input(\n",
    "      shape=(max_seq_length,), dtype=tf.int32, name='input_ids')\n",
    "stt = tf.keras.layers.Input(\n",
    "      shape=(max_seq_length,), dtype=tf.int32, name='input_ids')\n",
    "\n",
    "ids = tf.keras.layers.Input(\n",
    "      shape=(max_seq_length,), dtype=tf.int32, name='input_ids')\n",
    "\n",
    "\n",
    "ids = tf.constant([[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5]])\n",
    "starts = tf.constant([[0],[0],[1],[2],[3],[3]])\n",
    "ends = tf.constant([[3],[4],[4],[4],[4],[4]])\n",
    "\n",
    "span_array = []\n",
    "mask_array = []\n",
    "\n",
    "\n",
    "batch_size =tf.shape(ids)[0]\n",
    "str_len = tf.shape(ids)[0]\n",
    "for i in tf.range(batch_size):\n",
    "    span_array.append(tf.strided_slice(ids[i], starts[i], ends[i] + 1))\n",
    "    mask_array.append(tf.strided_slice(tf.fill([str_len], 1), starts[i], ends[i] + 1))\n",
    "    for j in range(str_len - len(span_array[i])):\n",
    "        span_array[i] = tf.concat([span_array[i], [0]], axis=0)\n",
    "        mask_array[i] = tf.concat([mask_array[i], [0]], axis=0)\n",
    "\n",
    "spans = tf.stack(span_array, axis=0)\n",
    "masks = tf.stack(mask_array, axis=0)\n",
    "\n",
    "print(spans,masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32) tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32) tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)\n",
      "eager lstm: 0.009034960006829351\n",
      "function lstm: 0.004581001005135477\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "lstm_cell = tf.keras.layers.LSTMCell(10)\n",
    "\n",
    "@tf.function\n",
    "def lstm_fn(input, state):\n",
    "  return lstm_cell(input, state)\n",
    "\n",
    "input = tf.zeros([10, 10])\n",
    "state = [tf.zeros([10, 10])] * 2\n",
    "print(input,state[0],state[1])\n",
    "# warm up\n",
    "lstm_cell(input, state); lstm_fn(input, state)\n",
    "print(\"eager lstm:\", timeit.timeit(lambda: lstm_cell(input, state), number=10))\n",
    "print(\"function lstm:\", timeit.timeit(lambda: lstm_fn(input, state), number=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 1 1 1 1]\n",
      " [2 2 2 2 2]\n",
      " [3 3 3 3 3]\n",
      " [3 3 3 3 3]], shape=(6, 5), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [3]], shape=(6, 1), dtype=int32) tf.Tensor(\n",
      "[[0 0 1 2 3 3]\n",
      " [0 0 1 2 3 3]\n",
      " [0 0 1 2 3 3]\n",
      " [0 0 1 2 3 3]\n",
      " [0 0 1 2 3 3]], shape=(5, 6), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "ids = tf.constant([[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5]])\n",
    "starts = tf.constant([[0],[0],[1],[2],[3],[3]])\n",
    "ends = tf.constant([[3],[4],[4],[4],[4],[4]])\n",
    "\n",
    "starts_1= tf.tile(starts,[1,5])\n",
    "\n",
    "print(tf.reduce_max(starts_1[0]))\n",
    "print(starts_1)\n",
    "starts_t=tf.transpose(starts_1,[1,0])\n",
    "print(starts,starts_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-5 -4 -3 -2 -1  0  1  2  3  4], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def square_if_positive_vectorized(x):\n",
    "  return tf.where(x > 0, x ** 2, x)\n",
    "\n",
    "\n",
    "square_if_positive_vectorized(tf.range(-5, 5))\n",
    "\n",
    "print(tf.range(-5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tensor(\"loop_body/Roll:0\", shape=(5,), dtype=int32)\n"
     ]
    },
    {
     "ename": "StagingError",
     "evalue": "in converted code:\n    relative to /Users/wweschen/tf2/env/lib/python3.7/site-packages:\n\n    tensorflow_core/python/ops/parallel_for/control_flow_ops.py:183 f  *\n        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)\n    tensorflow_core/python/ops/parallel_for/control_flow_ops.py:256 _pfor_impl\n        outputs.append(converter.convert(loop_fn_output))\n    tensorflow_core/python/ops/parallel_for/pfor.py:1280 convert\n        output = self._convert_helper(y)\n    tensorflow_core/python/ops/parallel_for/pfor.py:1453 _convert_helper\n        if flags.FLAGS.op_conversion_fallback_to_while_loop:\n    tensorflow_core/python/platform/flags.py:84 __getattr__\n        wrapped(_sys.argv)\n    absl/flags/_flagvalues.py:633 __call__\n        name, value, suggestions=suggestions)\n\n    UnrecognizedFlagError: Unknown command line flag 'f'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7a99cbeedca5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m new_spans = tf.vectorized_map(\n\u001b[1;32m     40\u001b[0m     \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_roll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0melems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py\u001b[0m in \u001b[0;36mvectorized_map\u001b[0;34m(fn, elems)\u001b[0m\n\u001b[1;32m    392\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_elem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mpfor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py\u001b[0m in \u001b[0;36mpfor\u001b[0;34m(loop_fn, iters, parallel_iterations)\u001b[0m\n\u001b[1;32m    187\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_under_xla_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2336\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2337\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2338\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2339\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2672\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2673\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2674\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2675\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2561\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2562\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2563\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2564\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    956\u001b[0m                                           converted_func)\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    946\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStagingError\u001b[0m: in converted code:\n    relative to /Users/wweschen/tf2/env/lib/python3.7/site-packages:\n\n    tensorflow_core/python/ops/parallel_for/control_flow_ops.py:183 f  *\n        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)\n    tensorflow_core/python/ops/parallel_for/control_flow_ops.py:256 _pfor_impl\n        outputs.append(converter.convert(loop_fn_output))\n    tensorflow_core/python/ops/parallel_for/pfor.py:1280 convert\n        output = self._convert_helper(y)\n    tensorflow_core/python/ops/parallel_for/pfor.py:1453 _convert_helper\n        if flags.FLAGS.op_conversion_fallback_to_while_loop:\n    tensorflow_core/python/platform/flags.py:84 __getattr__\n        wrapped(_sys.argv)\n    absl/flags/_flagvalues.py:633 __call__\n        name, value, suggestions=suggestions)\n\n    UnrecognizedFlagError: Unknown command line flag 'f'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "starts = tf.constant([[0],[0],[1],[2],[3],[3]])\n",
    "ends = tf.constant([[3],[4],[4],[4],[4],[4]])\n",
    "ids = tf.constant([[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5]])\n",
    "max_len=5\n",
    "batch_size =6\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "print(tf.executing_eagerly())   \n",
    "\n",
    "s= tf.transpose(tf.tile(starts,[1,max_len]))\n",
    "e= tf.transpose(tf.tile(ends,[1,max_len]))\n",
    "\n",
    "ta=tf.TensorArray(dtype = tf.int32, size=5)\n",
    "#print(s,e)\n",
    "for i in tf.range(max_len):\n",
    "    x=tf.where(i>=s[i],1,0)\n",
    "    y=tf.where(i<e[i],1,0)\n",
    "    #tf.print(x,y)\n",
    "    ta.write(i,x*y)\n",
    "\n",
    "m=tf.transpose(ta.stack(),[1,0])\n",
    "spans=ids*m\n",
    " \n",
    "#for i in tf.range(max_len):\n",
    "    #new_spans=tf.roll(spans, shift=s[i], axis=[1])\n",
    "    \n",
    " \n",
    "\n",
    "def f_roll(arg):\n",
    "    x, s = arg\n",
    "    \n",
    "    #return tf.roll(x, shift=-1 * s, axis=[0])\n",
    "    z=tf.roll(x, shift= -1*s , axis=[0])\n",
    "    print(z)\n",
    "    return z\n",
    "    \n",
    "new_spans = tf.vectorized_map(\n",
    "    fn=f_roll,\n",
    "    elems=(spans, starts)\n",
    ")\n",
    " \n",
    "new_mask = tf.vectorized_map(\n",
    "    fn=f_roll,\n",
    "    elems=(m, starts)\n",
    ")\n",
    " \n",
    "print(new_spans,new_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 12, 10)\n"
     ]
    }
   ],
   "source": [
    " \n",
    "fw=tf.keras.layers.LSTM(5, return_sequences=True,return_state=True )\n",
    "bw=tf.keras.layers.LSTM(5, return_sequences=True,go_backwards=True,return_state=True )\n",
    "\n",
    " \n",
    "\n",
    "inputs = tf.ones([2, 12, 5])\n",
    "\n",
    "\n",
    "out=fw(inputs)\n",
    "out2 =bw(inputs)\n",
    " \n",
    "print(tf.concat([out[0],out2[0]],axis=2).shape)\n",
    "      \n",
    "#print(tf.split(s,2,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
      "array([[1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.]], dtype=float32)>, <tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
      "array([[1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1.]], dtype=float32)>]\n",
      "tf.Tensor(\n",
      "[[0.00270986 0.5078718  0.2911771  0.5298484  0.08189317]\n",
      " [0.00270986 0.5078718  0.2911771  0.52984846 0.08189316]\n",
      " [0.00270986 0.5078718  0.29117706 0.52984846 0.08189316]], shape=(3, 5), dtype=float32) tf.Tensor(\n",
      "[[0.00270986 0.5078718  0.2911771  0.5298484  0.08189317]\n",
      " [0.00270986 0.5078718  0.2911771  0.52984846 0.08189316]\n",
      " [0.00270986 0.5078718  0.29117706 0.52984846 0.08189316]], shape=(3, 5), dtype=float32) tf.Tensor(\n",
      "[[0.00501275 1.1753801  0.9873215  1.044925   0.6098953 ]\n",
      " [0.00501275 1.1753801  0.9873215  1.044925   0.6098953 ]\n",
      " [0.00501275 1.1753801  0.9873214  1.044925   0.6098953 ]], shape=(3, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.20794933 -0.17963332  0.39797983 -0.03846632 -0.22294845]\n",
      " [-0.20794933 -0.17963338  0.3979799  -0.03846628 -0.22294846]\n",
      " [-0.20794934 -0.17963338  0.3979799  -0.03846627 -0.22294849]], shape=(3, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    " \n",
    "c=tf.keras.layers.LSTMCell(5) \n",
    "l  =  tf.keras.layers.Dense(5)\n",
    "#print(c.output_size)\n",
    "#print(c.state_size)\n",
    "\n",
    "inputs = tf.ones([3,5])\n",
    "state=[tf.ones([3,5]),tf.ones([3,5])]\n",
    "\n",
    "print(state)\n",
    "out=c(inputs,state)\n",
    "  \n",
    "out2=l(out[1][0])\n",
    "print(out[0],out[1][0],out[1][1])\n",
    "print(out2)\n",
    "      \n",
    "#print(tf.split(s,2,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "ename": "_SymbolicException",
     "evalue": "Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'input_ids_22:0' shape=(None, 5) dtype=int32>, <tf.Tensor 'starts_19:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'ends_19:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'starts_19:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'ends_19:0' shape=(None, 1) dtype=int32>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: An op outside of the function building code is being passed\na \"Graph\" tensor. It is possible to have Graph tensors\nleak out of the function building context by including a\ntf.init_scope in your function building code.\nFor example, the following function will fail:\n  @tf.function\n  def has_init_scope():\n    my_constant = tf.constant(1.)\n    with tf.init_scope():\n      added = my_constant * 2\nThe graph tensor has name: input_ids_22:0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31m_SymbolicException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-279-1eaf5f898980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mspans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mget_best_span_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    621\u001b[0m               *args, **kwds)\n\u001b[1;32m    622\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1554\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1555\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1556\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1635\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1637\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1638\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1639\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    498\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     73\u001b[0m       raise core._SymbolicException(\n\u001b[1;32m     74\u001b[0m           \u001b[0;34m\"Inputs to eager execution function cannot be Keras symbolic \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m           \"tensors, but found {}\".format(keras_symbolic_tensors))\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_SymbolicException\u001b[0m: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'input_ids_22:0' shape=(None, 5) dtype=int32>, <tf.Tensor 'starts_19:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'ends_19:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'starts_19:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'ends_19:0' shape=(None, 1) dtype=int32>]"
     ]
    }
   ],
   "source": [
    "max_len=5\n",
    "ids = tf.keras.layers.Input(\n",
    "      shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "starts = tf.keras.layers.Input(\n",
    "      shape=(1,), dtype=tf.int32, name='starts')\n",
    "\n",
    "ends = tf.keras.layers.Input(\n",
    "      shape=(1,), dtype=tf.int32, name='ends')\n",
    "# starts = tf.constant([[0],[0],[1],[2],[3],[3]])\n",
    "# ends = tf.constant([[3],[4],[4],[4],[4],[4]])\n",
    "# ids = tf.constant([[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5]])\n",
    "max_len=5\n",
    "\n",
    "@tf.function\n",
    "def get_best_span_prediction(ids,start_logits, end_logits):\n",
    "    #_, starts = tf.nn.top_k(start_logits, k=1)\n",
    "    #_, ends = tf.nn.top_k(end_logits, k=1)\n",
    "    \n",
    "    s= tf.transpose(tf.tile(starts,[1,max_len]))\n",
    "    e= tf.transpose(tf.tile(ends,[1,max_len]))\n",
    "\n",
    "    ta=tf.TensorArray(dtype = tf.int32, size=5)\n",
    "    #print(s,e)\n",
    "    for i in tf.range(max_len):\n",
    "        x=tf.where(i>=s[i],1,0)\n",
    "        y=tf.where(i<e[i],1,0)\n",
    "        #tf.print(x,y)\n",
    "        ta.write(i,x*y)\n",
    "\n",
    "    m=tf.transpose(ta.stack(),[1,0])\n",
    "    spans=ids*m\n",
    "    #print(spans,starts)\n",
    "\n",
    "    #for i in tf.range(max_len):\n",
    "        #new_spans=tf.roll(spans, shift=s[i], axis=[1])\n",
    "\n",
    "    return (spans,m)\n",
    "\n",
    "get_best_span_prediction(ids,starts,ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "_SymbolicException",
     "evalue": "Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'starts_17:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'ends_17:0' shape=(None, 1) dtype=int32>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: An op outside of the function building code is being passed\na \"Graph\" tensor. It is possible to have Graph tensors\nleak out of the function building context by including a\ntf.init_scope in your function building code.\nFor example, the following function will fail:\n  @tf.function\n  def has_init_scope():\n    my_constant = tf.constant(1.)\n    with tf.init_scope():\n      added = my_constant * 2\nThe graph tensor has name: starts_17:0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31m_SymbolicException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-690aab3c6a90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmake_a_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    621\u001b[0m               *args, **kwds)\n\u001b[1;32m    622\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1554\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1555\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1556\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1635\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1637\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1638\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1639\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    498\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     73\u001b[0m       raise core._SymbolicException(\n\u001b[1;32m     74\u001b[0m           \u001b[0;34m\"Inputs to eager execution function cannot be Keras symbolic \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m           \"tensors, but found {}\".format(keras_symbolic_tensors))\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_SymbolicException\u001b[0m: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'starts_17:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'ends_17:0' shape=(None, 1) dtype=int32>]"
     ]
    }
   ],
   "source": [
    "max_seq_length=400\n",
    "\n",
    "ids = tf.keras.layers.Input(\n",
    "       shape=(max_seq_length,), dtype=tf.int32, name='input_ids')\n",
    "starts = tf.keras.layers.Input(\n",
    "       shape=(1,), dtype=tf.int32, name='starts')\n",
    "\n",
    "ends = tf.keras.layers.Input(\n",
    "       shape=(1,), dtype=tf.int32, name='ends')\n",
    "\n",
    "m=[]\n",
    "\n",
    "@tf.function\n",
    "def make_a_mask(starts,ends):\n",
    "   \n",
    "    batch_size=tf.shape(starts)[0]\n",
    "\n",
    "    k=0\n",
    "    while(k<batch_size):\n",
    "\n",
    "        a =[]\n",
    "        for i in tf.range(max_seq_length):\n",
    "            if(i<starts[k] or i>=ends[k]):\n",
    "                a.append(0)\n",
    "            else: \n",
    "                a.append(1)\n",
    "\n",
    "        k=k+1 \n",
    "        m.append(a)\n",
    "    \n",
    "m= make_a_mask(starts,ends)\n",
    "\n",
    "tf.print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "class LinearLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               output_size,\n",
    "               use_bias=False,\n",
    "               kernel_initializer=None,\n",
    "               bias_initializer=\"zeros\",\n",
    "               activation=None,\n",
    "               **kwargs):\n",
    "    super(LinearLayer, self).__init__(**kwargs)\n",
    "    self.output_size = output_size\n",
    "    self.kernel_initializer = kernel_initializer\n",
    "    self.bias_initializer = bias_initializer\n",
    "    self.activation = activation\n",
    "    self.use_bias = use_bias\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    \"\"\"Implements build() for the layer.\"\"\"\n",
    "\n",
    "    total_arg_size = 0\n",
    "    shapes = input_shape  \n",
    "    if type(shapes) is not list:\n",
    "        shapes=[shapes] \n",
    "        \n",
    "    shapes=list(itertools.chain(*shapes))\n",
    "     \n",
    "    for shape in shapes: \n",
    "       \n",
    "        if len(shape) != 2:\n",
    "            raise ValueError(\"Linear is expecting 2D arguments: %s\" % str(shapes))\n",
    "        if not shape[1]:\n",
    "            raise ValueError(\"Linear expects shape[1] of arguments: %s\" % str(shapes))\n",
    "        else:\n",
    "            total_arg_size += shape[1] \n",
    "             \n",
    "    self.kernel = self.add_weight(\n",
    "        \"kernel\",\n",
    "        shape=[total_arg_size, self.output_size],\n",
    "        initializer=self.kernel_initializer,\n",
    "        dtype=self.dtype,\n",
    "        trainable=True)\n",
    "    self.bias = self.add_weight(\n",
    "        \"bias\",\n",
    "        shape=[self.output_size],\n",
    "        initializer=self.bias_initializer,\n",
    "        dtype=self.dtype,\n",
    "        trainable=True)\n",
    "\n",
    "    super(LinearLayer, self).build(input_shape)\n",
    "\n",
    "  def call(self, inputs):\n",
    "     \n",
    "        \n",
    "      if type(inputs) is not list:\n",
    "        inputs=[inputs]  \n",
    "        \n",
    "      inputs=list(itertools.chain(*inputs))\n",
    "    \n",
    "      if len(inputs) == 1:\n",
    "          \n",
    "          res = tf.matmul(inputs[0], self.kernel)\n",
    "      else:\n",
    "          res = tf.matmul(tf.concat(axis=1, values=inputs), self.kernel)\n",
    "      \n",
    "      if not self.use_bias:\n",
    "            return res\n",
    "        \n",
    "      return res + self.bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape_list(tensor, expected_rank=None, name=None):\n",
    "  \"\"\"Returns a list of the shape of tensor, preferring static dimensions.\n",
    "\n",
    "  Args:\n",
    "    tensor: A tf.Tensor object to find the shape of.\n",
    "    expected_rank: (optional) int. The expected rank of `tensor`. If this is\n",
    "      specified and the `tensor` has a different rank, and exception will be\n",
    "      thrown.\n",
    "    name: Optional name of the tensor for the error message.\n",
    "\n",
    "  Returns:\n",
    "    A list of dimensions of the shape of tensor. All static dimensions will\n",
    "    be returned as python integers, and dynamic dimensions will be returned\n",
    "    as tf.Tensor scalars.\n",
    "  \"\"\"\n",
    "  if expected_rank is not None:\n",
    "    assert_rank(tensor, expected_rank, name)\n",
    "\n",
    "  shape = tensor.shape.as_list()\n",
    "\n",
    "  non_static_indexes = []\n",
    "  for (index, dim) in enumerate(shape):\n",
    "    if dim is None:\n",
    "      non_static_indexes.append(index)\n",
    "\n",
    "  if not non_static_indexes:\n",
    "    return shape\n",
    "\n",
    "  dyn_shape = tf.shape(tensor)\n",
    "  for index in non_static_indexes:\n",
    "    shape[index] = dyn_shape[index]\n",
    "  return shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import tf_utils\n",
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, vector_size,\n",
    "                 use_coverage,\n",
    "                 initializer=None,\n",
    "                 float_type=tf.float32,\n",
    "                 **kwargs):\n",
    "        super(AttentionLayer , self).__init__(**kwargs)\n",
    "        self.initializer = initializer\n",
    "        self.float_type = float_type\n",
    "        self.vector_size = vector_size\n",
    "        self.use_coverage=use_coverage\n",
    "\n",
    "        #self.w_h = self.add_weight(shape=[1, 1, self.attention_length, self.vector_size], name=\"W_h\")\n",
    "        self.v = self.add_weight(shape=[self.vector_size], name=\"v\")\n",
    "        #self.w_c = self.add_weight(shape=[1, 1, 1, self.vector_size], name=\"W_c\")\n",
    "\n",
    "    def build(self,  unused_input_shapes):\n",
    "\n",
    "\n",
    "        self.linear_layer =  LinearLayer(self.vector_size)\n",
    "            # shape (batch_size, attention_vec_size)\n",
    "\n",
    "        self.coverage_layer =  tf.keras.layers.Conv2D(self.vector_size,(1,1), padding= \"SAME\")\n",
    "        # c has shape (batch_size, attn_length, 1, attention_vec_size)\n",
    "\n",
    "        super(AttentionLayer, self).build(unused_input_shapes)\n",
    "\n",
    "    def __call__(self,\n",
    "                 decoder_state,\n",
    "                 encoder_features,\n",
    "                 input_mask,\n",
    "                 coverage=None,\n",
    "                 **kwargs):\n",
    "        inputs = (encoder_features,decoder_state, input_mask,coverage )\n",
    "        return super(AttentionLayer, self).__call__(inputs, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "         \n",
    "        encoder_features = inputs[0]\n",
    "        batch_size = tf_utils.get_shape_list(encoder_features)[0]\n",
    "\n",
    "        decoder_states=inputs[1]\n",
    "        input_mask=inputs[2] \n",
    "        coverage  =inputs[3]\n",
    " \n",
    "        decoder_features= self.linear_layer([decoder_states])\n",
    "        decoder_features = tf.expand_dims(tf.expand_dims(decoder_features, 1),1)\n",
    "          # reshape to (batch_size, 1, 1, attention_vec_size)\n",
    "\n",
    "\n",
    "        def masked_attention(e):\n",
    "            \"\"\"Take softmax of e then apply enc_padding_mask and re-normalize\"\"\"\n",
    "            attn_dist = tf.nn.softmax(e)  # take softmax. shape (batch_size, attn_length)\n",
    "            attn_dist *= input_mask  # apply mask\n",
    "            masked_sums = tf.reduce_sum(attn_dist, axis=1)  # shape (batch_size)\n",
    "            return attn_dist / tf.reshape(masked_sums, [-1, 1])  # re-normalize\n",
    "\n",
    "        if self.use_coverage and coverage is not None:  # non-first step of coverage\n",
    "            # Multiply coverage vector by w_c to get coverage_features.\n",
    "            coverage_features = self.coverage_layer(coverage )  # c has shape (batch_size, attn_length, 1, attention_vec_size)\n",
    "\n",
    "            # Calculate v^T tanh(W_h h_i + W_s s_t + w_c c_i^t + b_attn)\n",
    "            e = tf.reduce_sum(self.v * tf.tanh(encoder_features + decoder_features + coverage_features),\n",
    "                                    [2, 3])  # shape (batch_size,attn_length)\n",
    "\n",
    "            # Calculate attention distribution\n",
    "            attn_dist = masked_attention(e)\n",
    "\n",
    "            # Update coverage vector\n",
    "            coverage += tf.reshape(attn_dist, [batch_size, -1, 1, 1])\n",
    "        else:\n",
    "            # Calculate v^T tanh(W_h h_i + W_s s_t + b_attn)\n",
    "            e = tf.reduce_sum(self.v * tf.tanh(encoder_features + decoder_features), [2, 3])  # calculate e\n",
    "\n",
    "            # Calculate attention distribution\n",
    "            attn_dist = masked_attention(e)\n",
    "\n",
    "            if self.use_coverage:  # first step of training\n",
    "                coverage = tf.expand_dims(tf.expand_dims(attn_dist, 2), 2)  # initialize coverage\n",
    "\n",
    "        # Calculate the context vector from attn_dist and encoder_states\n",
    "        context_vector = tf.reduce_sum(tf.reshape(attn_dist, [batch_size, -1, 1, 1]) * encoder_features,\n",
    "                                             [1, 2])  # shape (batch_size, attn_size).\n",
    "       \n",
    "        context_vector = tf.reshape(context_vector, [-1, self.vector_size])\n",
    "       \n",
    "         \n",
    "        return context_vector, attn_dist, coverage\n",
    "\n",
    "    def compute_output_shape(self,inputShape):\n",
    "    \n",
    "        #calculate shapes from input shape\n",
    "        return [[None,self.vector_size],\n",
    "                [None,self.max_seq_length],\n",
    "                [None,self.max_seq_length,1,1]\n",
    "               ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder (tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                  hidden_dim,\n",
    "                 vector_size,\n",
    "                 attention_length,\n",
    "                 initial_state_attention=False,\n",
    "                 pointer_gen=True,\n",
    "                 use_coverage=False,\n",
    "                 initializer=None,\n",
    "                 float_type=tf.float32,\n",
    "                 **kwargs):\n",
    "        super(AttentionDecoder , self).__init__(**kwargs)\n",
    "        self.initializer = initializer\n",
    "        self.float_type = float_type\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.vector_size = vector_size\n",
    "        self.attention_length = attention_length\n",
    "        self.pointer_gen = pointer_gen\n",
    "        self.use_coverage = use_coverage\n",
    "        self.initial_state_attention=initial_state_attention\n",
    "\n",
    "    def build(self, unused_input_shapes):\n",
    "\n",
    "        self.lstm_layer = tf.keras.layers.LSTMCell(self.vector_size)\n",
    "\n",
    "        self.encoder_layer = tf.keras.layers.Conv2D(filters=self.vector_size, kernel_size=(1, 1), padding=\"SAME\")\n",
    "        # shape (batch_size,attn_length,1,attention_vec_size)\n",
    "        self.linear = LinearLayer(self.vector_size )\n",
    "        self.linear2 = LinearLayer(1)\n",
    "        self.attention_layer = AttentionLayer(self.vector_size,self.attention_length,True)\n",
    "\n",
    "\n",
    "\n",
    "    def __call__(self,\n",
    "                 decoder_inputs,\n",
    "                 dec_initial_state,\n",
    "                 encoder_states,\n",
    "                 enc_padding_mask,\n",
    "                 prev_coverage=None,\n",
    "                 **kwargs):\n",
    "        \n",
    "        inputs = (decoder_inputs,  \n",
    "                                       dec_initial_state,\n",
    "                                       encoder_states,\n",
    "                                       enc_padding_mask,\n",
    "                                       prev_coverage) \n",
    "        return super(AttentionDecoder, self).__call__(inputs, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #unpacked_inputs = tf_utils.unpack_inputs(inputs)\n",
    "\n",
    "        decoder_inputs = inputs[0]\n",
    "        initial_state = inputs[1]\n",
    "        encoder_states = inputs[2]\n",
    "        enc_padding_mask = inputs[3]\n",
    "        prev_coverage =  inputs[4]\n",
    "\n",
    "        outputs = []\n",
    "        attn_dists = []\n",
    "        p_gens = []\n",
    "  \n",
    "        encoder_states = tf.expand_dims(encoder_states, axis=2)  # now is shape (batch_size, attn_len, 1, attn_size)\n",
    "        \n",
    "        encoder_features = self.encoder_layer(encoder_states)  # shape (batch_size,attn_length,1,attention_vec_size)\n",
    "        state =initial_state # [initial_state,initial_state]\n",
    "        #state=[initial_state]*2\n",
    "        batch_size=tf_utils.get_shape_list(encoder_states)[0]\n",
    "\n",
    "        coverage = prev_coverage  # initialize coverage to None or whatever was passed in\n",
    "         \n",
    "        context_vector = tf.zeros([batch_size, self.vector_size])\n",
    "        context_vector.set_shape([None, self.vector_size])  # Ensure the second shape of attention vectors is set.\n",
    "        if self.initial_state_attention:  # true in decode mode\n",
    "            # Re-calculate the context vector from the previous step so that we can pass it through a linear layer\n",
    "            # with this step's input to get a modified version of the input\n",
    "            context_vector, _, coverage = self.attention_layer ( encoder_features=encoder_features,\n",
    "                                                                 decoder_state=state,\n",
    "                                                                 coverage =coverage,\n",
    "                                                                 input_mask=enc_padding_mask )\n",
    "             \n",
    "            # in decode mode, this is what updates the coverage vector\n",
    "\n",
    "        for i, inp in enumerate(decoder_inputs):\n",
    "\n",
    "            # Merge input and previous attentions into one vector x of the same size as inp\n",
    "            input_size = inp.get_shape().with_rank(2)[1]\n",
    "            \n",
    "            if input_size is None:\n",
    "                raise ValueError(\"Could not infer input size from input: %s\" % inp.name)\n",
    "            \n",
    "             \n",
    "            x = self.linear([[inp], [context_vector]])\n",
    "\n",
    "            # Run the decoder RNN cell. cell_output = decoder state\n",
    "            #print(i, x, state)\n",
    "            cell_output, state = self.lstm_layer(x,state)\n",
    "           \n",
    "            # Run the attention mechanism.\n",
    "            if i == 0 and self.initial_state_attention:  # always true in decode mode\n",
    "                context_vector, attn_dist, _ = self.attention_layer (encoder_features=encoder_features,\n",
    "                                                                     decoder_state=state,\n",
    "                                                                     coverage=coverage,\n",
    "                                                                     input_mask=enc_padding_mask)  # don't allow coverage to update\n",
    "            else:\n",
    "                context_vector, attn_dist, coverage = self.attention_layer(encoder_features=encoder_features,\n",
    "                                                                           decoder_state=state,\n",
    "                                                                           coverage=coverage,\n",
    "                                                                           input_mask=enc_padding_mask)\n",
    "            attn_dists.append(attn_dist)\n",
    "\n",
    "            # Calculate p_gen\n",
    "            if self.pointer_gen: \n",
    "                p_gen = self.linear2( [[context_vector],[state[0]], [state[1]], [x]])\n",
    "                # Tensor shape (batch_size, 1)\n",
    "                p_gen = tf.sigmoid(p_gen)\n",
    "                p_gens.append(p_gen)\n",
    "\n",
    "                # Concatenate the cell_output (= decoder state) and the context vector, and pass them through a linear layer\n",
    "                # This is V[s_t, h*_t] + b in the paper\n",
    "                output = self.linear( [[cell_output], [context_vector]])\n",
    "            outputs.append(output)\n",
    "\n",
    "        # If using coverage, reshape it\n",
    "        if coverage is not None:\n",
    "            coverage = tf.reshape(coverage, [batch_size, -1])\n",
    "\n",
    "        return outputs, state, attn_dists, p_gens, coverage\n",
    "    # def compute_output_shape(self,inputShape):\n",
    "    #      #calculate shapes from input shape\n",
    "    #      return [[None,self.max_seq_length,self.hidden_dim],\n",
    "    #              [None,self.hidden_dim],\n",
    "    #              [None, self.hidden_dim],\n",
    "    #              [None, self.hidden_dim],\n",
    "    #              [None, self.hidden_dim],\n",
    "    #              ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initializer(initializer_range=0.02):\n",
    "  \"\"\"Creates a `tf.initializers.truncated_normal` with the given range.\n",
    "\n",
    "  Args:\n",
    "    initializer_range: float, initializer range for stddev.\n",
    "\n",
    "  Returns:\n",
    "    TruncatedNormal initializer with stddev = `initializer_range`.\n",
    "  \"\"\"\n",
    "  return tf.keras.initializers.TruncatedNormal(stddev=initializer_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "seq_len=10\n",
    "feature_size = 12\n",
    "hidden_size=240\n",
    "max_dec_length = 8\n",
    "\n",
    "\n",
    "dec_features=[tf.random.uniform([batch_size,feature_size])]*max_dec_length\n",
    "\n",
    "dec_states=tf.random.uniform([batch_size,feature_size])\n",
    "dec_mask=tf.ones([batch_size,seq_len],tf.float32)\n",
    "enc_states=tf.random.uniform([batch_size, seq_len,feature_size])\n",
    " \n",
    "coverage = tf.random.uniform([batch_size, seq_len,1,1])\n",
    "\n",
    "\n",
    "decoder = AttentionDecoder(hidden_size, feature_size, \n",
    "                                        seq_len, get_initializer(),\n",
    "                                        name=\"attention_decoder\")\n",
    "\n",
    "out = decoder(\n",
    "            dec_features,\n",
    "            dec_states,\n",
    "            enc_states,\n",
    "            dec_mask,\n",
    "            coverage)\n",
    "    \n",
    "    \n",
    "#print(out)\n",
    "\n",
    " \n",
    "\n",
    "#print(get_shape_list(input))\n",
    "#input=tf.random.uniform([ seq_len])\n",
    "#zero_state=tf.zeros([batch_size, feature_size])\n",
    "\n",
    "#linear = LinearLayer(feature_size,False)\n",
    "\n",
    "# print(input)\n",
    "# out=linear(input)\n",
    "# encoder_layer = tf.keras.layers.Conv2D(filters=feature_size, kernel_size=(1, 1), padding=\"SAME\")\n",
    "\n",
    "# inputs = tf.expand_dims(inputs, axis=2)  # now is shape (batch_size, attn_len, 1, attn_size)\n",
    "\n",
    "# enc_feature= encoder_layer(inputs)     \n",
    "\n",
    "# atten=AttentionLayer(feature_size,seq_len,True)\n",
    "\n",
    "# out = atten(encoder_features=enc_feature, decoder_state=dec_states, coverage =coverage, input_mask=input_mask )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 10), dtype=float32, numpy=\n",
       "array([[1.4945861 , 1.6792537 , 1.085821  , 1.547793  , 1.6920732 ,\n",
       "        1.082137  , 1.0859984 , 0.47908726, 0.9617234 , 0.9767699 ],\n",
       "       [1.9037642 , 1.3531944 , 1.8471627 , 1.0240195 , 1.3833439 ,\n",
       "        1.4301822 , 0.77310556, 1.5611751 , 1.5469098 , 0.63561773],\n",
       "       [1.7449133 , 1.0637496 , 1.3419441 , 0.92907566, 1.6138995 ,\n",
       "        0.72120076, 1.827379  , 1.837569  , 0.7337004 , 1.6414684 ],\n",
       "       [1.7412142 , 1.7451642 , 1.1470199 , 1.9235015 , 1.3093983 ,\n",
       "        1.7299534 , 1.0788914 , 0.6208656 , 1.6557912 , 1.5660311 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EmbeddingLookup(tf.keras.layers.Layer):\n",
    "  \"\"\"Looks up words embeddings for id tensor.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               vocab_size,\n",
    "               embedding_size=768,\n",
    "               initializer_range=0.02,\n",
    "               **kwargs):\n",
    "    super(EmbeddingLookup, self).__init__(**kwargs)\n",
    "    self.vocab_size = vocab_size\n",
    "    self.embedding_size = embedding_size\n",
    "    self.initializer_range = initializer_range\n",
    "\n",
    "  def build(self, unused_input_shapes):\n",
    "    \"\"\"Implements build() for the layer.\"\"\"\n",
    "    self.embeddings = self.add_weight(\n",
    "        \"embeddings\",\n",
    "        shape=[self.vocab_size, self.embedding_size],\n",
    "        initializer=get_initializer(self.initializer_range),\n",
    "        dtype=self.dtype)\n",
    "    super(EmbeddingLookup, self).build(unused_input_shapes)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    \"\"\"Implements call() for the layer.\"\"\"\n",
    "\n",
    "    input_shape = tf_utils.get_shape_list(inputs)\n",
    "\n",
    "    flat_input = tf.reshape(inputs, [-1])\n",
    "    output = tf.gather(self.embeddings, flat_input)\n",
    "    output = tf.reshape(output, input_shape + [self.embedding_size])\n",
    "\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReduceStateLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 hidden_dim, **kwargs):\n",
    "        super(ReduceStateLayer, self).__init__(**kwargs)\n",
    "        self.hidden_dim=hidden_dim\n",
    "\n",
    "    def build(self, unused_input_shapes):\n",
    "        hidden_dim = self.hidden_dim\n",
    "        self.w_reduce_c = self.add_weight('w_reduce_c', [hidden_dim * 2, hidden_dim], dtype=tf.float32,\n",
    "                                     initializer=tf.keras.initializers.TruncatedNormal())\n",
    "        self.w_reduce_h = self.add_weight('w_reduce_h', [hidden_dim * 2, hidden_dim], dtype=tf.float32,\n",
    "                                     initializer=tf.keras.initializers.TruncatedNormal())\n",
    "        self.bias_reduce_c = self.add_weight('bias_reduce_c', [hidden_dim], dtype=tf.float32,\n",
    "                                        initializer=tf.keras.initializers.TruncatedNormal())\n",
    "        self.bias_reduce_h = self.add_weight('bias_reduce_h', [hidden_dim], dtype=tf.float32,\n",
    "                                        initializer=tf.keras.initializers.TruncatedNormal())\n",
    "        super(ReduceStateLayer, self).build(unused_input_shapes)\n",
    "\n",
    "    def __call__(self,\n",
    "                 fw_state_h,fw_state_c, bw_state_h,bw_state_c,\n",
    "                 **kwargs):\n",
    "        inputs =  (fw_state_h,fw_state_c, bw_state_h,bw_state_c)\n",
    "\n",
    "        return super(ReduceStateLayer, self).__call__(inputs, **kwargs)\n",
    "    def call(self, inputs):\n",
    "\n",
    "        fw_state_h = inputs[0]\n",
    "        fw_state_c = inputs[1]\n",
    "        bw_state_h = inputs[2]\n",
    "        bw_state_c = inputs[3]\n",
    "\n",
    "        # Apply linear layer\n",
    "        old_c = tf.concat(axis=1, values=[fw_state_c, bw_state_c])  # Concatenation of fw and bw cell\n",
    "        old_h = tf.concat(axis=1, values=[fw_state_h, bw_state_h])  # Concatenation of fw and bw state\n",
    "        new_c = tf.nn.relu(tf.matmul( old_c, self.w_reduce_c) + self.bias_reduce_c)  # Get new cell from old cell\n",
    "        new_h = tf.nn.relu(tf.matmul( old_h, self.w_reduce_h) + self.bias_reduce_h)  # Get new state from old state\n",
    "        \n",
    "        return [new_c, new_h]  # Return new cell and state\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder (tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 hidden_dim,max_seq_length,  **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.max_seq_length=max_seq_length\n",
    "\n",
    "    def build(self, unused_input_shapes):\n",
    "        lstm_layer_fw = tf.keras.layers.LSTM(self.hidden_dim, return_sequences=True, return_state=True)\n",
    "        lstm_layer_bw = tf.keras.layers.LSTM(self.hidden_dim, return_sequences=True, go_backwards=True,\n",
    "                                             return_state=True)\n",
    "        self.bidirection = tf.keras.layers.Bidirectional(lstm_layer_fw,backward_layer=lstm_layer_bw , merge_mode=\"concat\")\n",
    "\n",
    "        self.state_reducer = ReduceStateLayer(self.hidden_dim)\n",
    "\n",
    "        super(Encoder, self).build(unused_input_shapes)\n",
    "\n",
    "    def __call__(self,\n",
    "                 input_word_ids,\n",
    "                 input_mask=None ,\n",
    "                 **kwargs):\n",
    "        inputs = (input_word_ids, input_mask)\n",
    "        return super(Encoder, self).__call__(inputs, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #unpacked_inputs = tf_utils.unpack_inputs(inputs)\n",
    "        input_ids=inputs[0]\n",
    "        masks = inputs[1]\n",
    "         \n",
    "        masks = tf.expand_dims(masks, axis=2)\n",
    "\n",
    "        outputs = self.bidirection(input_ids*masks)\n",
    "        print('outputs:',outputs)\n",
    "        encoder_outputs=outputs[0]\n",
    "\n",
    "        fw_state_h,fw_state_ch = outputs[1],outputs[2]\n",
    "        bw_state_h,bw_state_ch = outputs[3],outputs[4]\n",
    "\n",
    "        state = self.state_reducer(fw_state_h,fw_state_ch ,bw_state_h, bw_state_ch)\n",
    "\n",
    "        return encoder_outputs, state\n",
    "    def compute_output_shape(self,inputShape):\n",
    "        #calculate shapes from input shape\n",
    "        return [[None,self.max_seq_length,2*self.hidden_dim],\n",
    "                 [[None,self.hidden_dim],[None,self.hidden_dim]]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PGNetSummaryModel(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               config,\n",
    "               float_type=tf.float32,\n",
    "               **kwargs):\n",
    "    super(PGNetSummaryModel, self).__init__(**kwargs)\n",
    "\n",
    "    self.config = (\n",
    "        PGNetConfig.from_dict(config)\n",
    "        if isinstance(config, dict) else copy.deepcopy(config))\n",
    "\n",
    "    self.float_type = float_type\n",
    "\n",
    "\n",
    "\n",
    "  def build(self, unused_input_shapes):\n",
    "    \"\"\"Implements build() for the layer.\"\"\"\n",
    "    self.embedding_lookup = EmbeddingLookup(self.config.vocab_size,self.config.hidden_size)\n",
    "    self.encoder = Encoder(self.config.hidden_size,self.config.max_seq_length, dynamic=True)\n",
    "    self.decoder = AttentionDecoder(self.config.hidden_size,self.config.hidden_size,\n",
    "                                    self.config.max_seq_length,get_initializer())\n",
    "    self.output_projector = OutputProjectionLayer(self.config.hidden_size,self.config.vocab_size)\n",
    "    self.final_distribution = FinalDistributionLayer(self.config.hidden_size,self.config.vocab_size,self.config.max_oov_size)\n",
    "\n",
    "    super(PGNetSummaryModel, self).build(unused_input_shapes)\n",
    "\n",
    "  def __call__(self,\n",
    "               input_word_ids,\n",
    "               input_mask=None,\n",
    "               answer_ids=None,\n",
    "               answer_mask=None, \n",
    "               **kwargs):\n",
    "    inputs = (input_word_ids, input_mask, answer_ids,answer_mask)\n",
    "    return super(PGNetSummaryModel, self).__call__(inputs, **kwargs)\n",
    "\n",
    "  def call(self, inputs,mode=\"pgnet\"):\n",
    "\n",
    "      input_word_ids = inputs[0]\n",
    "      input_mask = inputs[1]\n",
    "      answer_ids= inputs[2]\n",
    "      answer_mask= inputs[3] \n",
    "\n",
    "      emb_enc_inputs = self.embedding_lookup(input_word_ids)  # tensor with shape (batch_size, max_seq_length, emb_size)\n",
    "      emb_dec_inputs = [self.embedding_lookup(x) for x in tf.unstack(answer_ids, axis=1)]  # list length max_dec_steps containing shape (batch_size, emb_size)\n",
    "\n",
    "      enc_outputs, enc_state = self.encoder(emb_enc_inputs,input_mask )\n",
    "      print('enc_outputs:',enc_outputs)\n",
    "      self._enc_states = enc_outputs\n",
    "\n",
    "      self._dec_in_state = enc_state\n",
    "\n",
    "      if mode==\"encoder\":\n",
    "         return (self._enc_states,self._dec_in_state )\n",
    "\n",
    "      prev_coverage =None # self.prev_coverage #if self.config.mode == \"decode\" and self.config.use_coverage  else None\n",
    "\n",
    "      decoder_outputs, self._dec_out_state, self.attn_dists, self.p_gens, self.coverage = self.decoder(\n",
    "                emb_dec_inputs,\n",
    "                 self._dec_in_state ,\n",
    "                 self._enc_states ,\n",
    "                 input_mask,\n",
    "                 prev_coverage=prev_coverage)\n",
    "      if mode == \"decoder\":\n",
    "           return (decoder_outputs, self._dec_out_state, self.attn_dists, self.p_gens, self.coverage)\n",
    "\n",
    "      vocab_dists=self.output_projector(decoder_outputs)\n",
    "\n",
    "      if self.config.use_pointer_gen:\n",
    "           final_dists = self.final_distribution(vocab_dists, self.attn_dists,self.p_gens, input_word_ids)\n",
    "      else:  # final distribution is just vocabulary distribution\n",
    "           final_dists = vocab_dists\n",
    "\n",
    "      return  final_dists,self.attn_dists\n",
    "\n",
    "  def get_config(self):\n",
    "    config = {\"config\": self.config.to_dict()}\n",
    "    base_config = super(PGNetSummaryModel, self).get_config()\n",
    "    return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputProjectionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 hidden_dim,\n",
    "                 vocab_size,\n",
    "                 **kwargs):\n",
    "        super(OutputProjectionLayer, self).__init__(**kwargs)\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.vocab_size =vocab_size\n",
    "\n",
    "\n",
    "    def build(self, unused_input_shapes):\n",
    "        self.w = self.add_weight('w', [self.hidden_dim, self.vocab_size], dtype=tf.float32, initializer=tf.keras.initializers.TruncatedNormal())\n",
    "        self.w_t = tf.transpose(self.w)\n",
    "        self.v = self.add_weight('v', [self.vocab_size], dtype=tf.float32, initializer=tf.keras.initializers.TruncatedNormal())\n",
    "      \n",
    "\n",
    "    def call(self, inputs):\n",
    "        decoder_outputs = inputs\n",
    "\n",
    "        vocab_scores = []  # vocab_scores is the vocabulary distribution before applying softmax. Each entry on the list corresponds to one decoder step\n",
    "        for i, output in enumerate(decoder_outputs):\n",
    "            vocab_scores.append(tf.matmul(output, self.w)+ self.v)  # apply the linear layer\n",
    "\n",
    "        vocab_dists = [tf.nn.softmax(s) for s in\n",
    "                       vocab_scores]\n",
    "        # The vocabulary distributions. List length max_dec_steps of (batch_size, vsize) arrays. The words are in the order they appear in the vocabulary file.\n",
    "\n",
    "        return vocab_dists\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FinalDistributionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 hidden_dim,\n",
    "                 vocab_size,\n",
    "                 max_oov_size,\n",
    "                 **kwargs):\n",
    "        super(FinalDistributionLayer, self).__init__(**kwargs)\n",
    "\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.vocab_size=vocab_size\n",
    "        self.max_oov_size=max_oov_size\n",
    "\n",
    "    #def build(self, unused_input_shapes):\n",
    "\n",
    "\n",
    "    def __call__(self,\n",
    "                 vocab_dists, attn_dists,p_gens,input_ids,\n",
    "                 **kwargs):\n",
    "        inputs = (vocab_dists, attn_dists,p_gens,input_ids)\n",
    "\n",
    "        return super(FinalDistributionLayer, self).__call__(inputs, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        vocab_dists=inputs[0]\n",
    "        attn_dists=inputs[1]\n",
    "        p_gens=inputs[2]\n",
    "        input_ids=inputs[3]\n",
    "        max_oov_size=self.max_oov_size\n",
    "\n",
    "        vocab_dists = [p_gen * dist for (p_gen, dist) in zip( p_gens, vocab_dists)]\n",
    "        attn_dists = [(1 - p_gen) * dist for (p_gen, dist) in zip( p_gens, attn_dists)]\n",
    " \n",
    "        batch_size = tf_utils.get_shape_list(vocab_dists[0])[0]\n",
    "        \n",
    "        # Concatenate some zeros to each vocabulary dist, to hold the probabilities for in-article OOV words\n",
    "        extended_vsize = self.vocab_size + max_oov_size  # the maximum (over the batch) size of the extended vocabulary\n",
    "        extra_zeros = tf.zeros(( batch_size,  max_oov_size))\n",
    "        vocab_dists_extended = [tf.concat(axis=1, values=[dist, extra_zeros]) for dist in\n",
    "                                vocab_dists]  # list length max_dec_steps of shape (batch_size, extended_vsize)\n",
    "\n",
    "        # Project the values in the attention distributions onto the appropriate entries in the final distributions\n",
    "        # This means that if a_i = 0.1 and the ith encoder word is w, and w has index 500 in the vocabulary, then we add 0.1 onto the 500th entry of the final distribution\n",
    "        # This is done for each decoder timestep.\n",
    "        # This is fiddly; we use tf.scatter_nd to do the projection\n",
    "        batch_nums = tf.range(0, limit= batch_size)  # shape (batch_size)\n",
    "        batch_nums = tf.expand_dims(batch_nums, 1)  # shape (batch_size, 1)\n",
    "        attn_len =  tf_utils.get_shape_list(input_ids)[1]  # number of states we attend over\n",
    "        batch_nums = tf.tile(batch_nums, [1, attn_len])  # shape (batch_size, attn_len)\n",
    "        indices = tf.stack((batch_nums,  input_ids), axis=2)  # shape (batch_size, enc_t, 2)\n",
    "        shape = [ batch_size, extended_vsize]\n",
    "        \n",
    "        attn_dists_projected = [tf.scatter_nd(indices, copy_dist, shape) for copy_dist in\n",
    "                                attn_dists]  # list length max_dec_steps (batch_size, extended_vsize)\n",
    "\n",
    "        # Add the vocab distributions and the copy distributions together to get the final distributions\n",
    "        # final_dists is a list length max_dec_steps; each entry is a tensor shape (batch_size, extended_vsize) giving the final distribution for that decoder timestep\n",
    "        # Note that for decoder timesteps and examples corresponding to a [PAD] token, this is junk - ignore.\n",
    "        final_dists = [vocab_dist + copy_dist for (vocab_dist, copy_dist) in\n",
    "                       zip(vocab_dists_extended, attn_dists_projected)]\n",
    "\n",
    "        return final_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: [<tf.Tensor: shape=(4, 10, 24), dtype=float32, numpy=\n",
      "array([[[ 3.58280609e-03, -2.77756760e-03, -1.94900855e-03,\n",
      "          1.75909034e-03,  3.87027278e-04,  1.01619912e-03,\n",
      "         -3.10345367e-03, -1.59479538e-03,  3.01030255e-03,\n",
      "         -2.82257004e-03,  5.34832943e-04, -8.80464446e-04,\n",
      "         -2.40700925e-03, -2.65070214e-03, -3.27312620e-04,\n",
      "          7.76522234e-03,  6.27826713e-03, -5.71529474e-03,\n",
      "         -3.10296379e-03,  5.82676948e-05, -9.70482733e-03,\n",
      "          3.23103101e-04, -7.07714004e-04,  1.63233664e-03],\n",
      "        [ 2.49302224e-03,  4.88758367e-03,  5.66031924e-03,\n",
      "          2.18685344e-03, -1.40863319e-03, -4.50846087e-03,\n",
      "         -2.86793220e-03,  3.58036341e-04, -1.97534706e-03,\n",
      "         -2.76866183e-03,  5.99751074e-04, -4.24135197e-03,\n",
      "         -5.14633721e-03, -6.17821177e-04, -2.11976795e-03,\n",
      "          9.05728806e-03,  8.30808934e-03, -2.70160264e-03,\n",
      "         -4.05476755e-03, -4.73688170e-03, -7.71968672e-03,\n",
      "          3.04814428e-03,  2.81281956e-03, -4.38857503e-04],\n",
      "        [ 6.99989917e-03,  7.10550137e-03,  5.08632697e-03,\n",
      "          7.03637488e-05, -2.32466380e-03, -4.24066465e-03,\n",
      "         -1.21051434e-03, -3.42844112e-04, -1.88605476e-03,\n",
      "         -2.74786772e-03,  4.77175042e-03, -3.25892563e-03,\n",
      "         -9.46808024e-04, -2.29838653e-03,  1.34550233e-03,\n",
      "          8.19583703e-03,  2.99985823e-03, -1.82673556e-03,\n",
      "         -5.21777850e-03, -5.16294967e-04, -6.00401964e-03,\n",
      "          3.76146217e-03, -1.04124821e-03,  2.61611096e-03],\n",
      "        [ 4.19341587e-03,  6.14448870e-03,  6.18888345e-03,\n",
      "         -1.27181713e-03,  3.80567880e-03,  6.52288727e-04,\n",
      "         -2.99588079e-03, -4.85470169e-04, -4.66118974e-04,\n",
      "         -1.44541753e-03,  3.00211576e-03, -2.74948357e-03,\n",
      "         -2.04695668e-03, -8.24803661e-04,  2.87915044e-03,\n",
      "          6.63590059e-03,  4.95133968e-03,  3.18135880e-03,\n",
      "         -6.40356448e-03, -1.23388215e-03,  1.23470218e-03,\n",
      "          1.48162059e-03,  8.16360116e-04,  7.45223195e-04],\n",
      "        [-1.13424659e-03,  6.21440960e-03,  4.91579203e-03,\n",
      "          9.40591272e-04,  5.74464072e-03, -1.10000477e-03,\n",
      "         -6.85977191e-03, -8.09311896e-05, -2.57598865e-03,\n",
      "         -3.00930557e-03,  4.51023271e-03, -8.03641789e-03,\n",
      "          5.50158089e-03,  2.13911943e-03,  7.28904677e-04,\n",
      "          6.88684126e-03, -1.01850438e-03,  9.53735376e-04,\n",
      "         -5.93701284e-03, -4.24588937e-03, -7.64529163e-04,\n",
      "          3.77666950e-03,  1.96793606e-03,  6.21211343e-03],\n",
      "        [-1.73668406e-04,  6.45449711e-03, -6.37668767e-04,\n",
      "         -1.93506887e-03,  6.40251348e-03,  8.54265585e-04,\n",
      "         -1.49640813e-03, -3.46396089e-04,  1.93763850e-03,\n",
      "         -9.68891662e-04,  2.80006323e-03, -2.43882276e-03,\n",
      "          1.73987227e-03,  4.76575969e-03,  4.62461030e-03,\n",
      "          6.78399159e-03, -4.07201657e-03, -2.79460032e-03,\n",
      "         -4.30145883e-04, -3.33023863e-03,  1.39932567e-03,\n",
      "          5.27853286e-03, -5.52365463e-03,  4.86750063e-03],\n",
      "        [-4.54845186e-03,  1.54248410e-04, -9.06044559e-04,\n",
      "          8.28761375e-04,  2.23133340e-03, -1.35301217e-03,\n",
      "          2.05337931e-03, -3.42476508e-03,  8.92869849e-03,\n",
      "         -1.70469005e-03,  2.43144808e-03, -6.40798244e-04,\n",
      "          1.48227706e-03,  6.04586862e-03,  1.11598754e-03,\n",
      "          6.55180356e-03, -9.36585711e-04, -2.72103562e-03,\n",
      "         -1.41141194e-04, -2.60238280e-03,  1.27604115e-03,\n",
      "          3.67188640e-03, -3.41553311e-03,  5.46074845e-03],\n",
      "        [-7.41290569e-04,  7.54420273e-03,  2.29949874e-04,\n",
      "          2.07306212e-03, -1.35527481e-03, -5.46101993e-03,\n",
      "          2.42424221e-03, -5.80882595e-04,  5.45511534e-03,\n",
      "         -3.04260687e-03,  2.30934145e-03, -1.38671976e-03,\n",
      "         -1.14156515e-03,  2.42187292e-03,  1.70355884e-03,\n",
      "          5.77286584e-03,  2.19334965e-03, -4.87430766e-03,\n",
      "          1.60333246e-03, -2.99742469e-03, -2.34901207e-03,\n",
      "          8.83411092e-04, -1.25613087e-03,  2.04123775e-04],\n",
      "        [-2.15950399e-03,  5.35545684e-03, -2.89025088e-03,\n",
      "          1.56089326e-03,  6.04334520e-04, -4.60798247e-03,\n",
      "          4.28268267e-03, -6.31816976e-04,  6.99597411e-03,\n",
      "         -1.85230665e-03,  1.29837310e-04, -7.29667954e-04,\n",
      "         -1.22170569e-03,  3.47670796e-03,  3.59010929e-03,\n",
      "          3.08965147e-03, -2.09008595e-05, -3.86304874e-03,\n",
      "          4.84580436e-04, -1.95071381e-03,  3.27013526e-03,\n",
      "          2.02705705e-04, -2.96254992e-03, -6.66132022e-04],\n",
      "        [-2.75678816e-04,  3.15991580e-03,  2.18823156e-03,\n",
      "          1.95492571e-03, -1.39250827e-03, -6.15092879e-03,\n",
      "          1.06973690e-03, -2.66930461e-03,  9.93111078e-03,\n",
      "         -4.18335060e-03, -2.38985545e-03, -4.87176265e-04,\n",
      "         -3.62173724e-03,  2.82371743e-03, -9.39416583e-04,\n",
      "         -3.58753838e-04,  7.51893851e-04, -1.75333023e-03,\n",
      "          1.85608771e-03, -8.54500628e-04, -2.76953913e-04,\n",
      "          2.09728512e-03, -4.59167501e-03, -3.41672497e-03]],\n",
      "\n",
      "       [[-5.69531322e-03,  1.46171683e-03,  3.78182414e-03,\n",
      "         -1.13680575e-03,  4.24085744e-03, -2.39906274e-03,\n",
      "          4.04144230e-04, -3.08782794e-03, -1.67893106e-03,\n",
      "         -2.39869370e-03,  4.40772111e-03, -7.05026137e-03,\n",
      "          7.08960276e-03,  4.11731843e-03, -4.86129615e-03,\n",
      "          1.05370944e-02,  4.04119631e-03, -2.75794417e-03,\n",
      "         -1.42193167e-02, -3.10938619e-03, -5.70091512e-03,\n",
      "         -4.09833388e-03,  9.52572841e-03,  8.09456687e-03],\n",
      "        [ 1.67277956e-03,  4.89391014e-03,  2.95354985e-03,\n",
      "         -2.61627510e-03,  1.78165711e-03, -3.21532413e-03,\n",
      "          1.46396132e-03, -3.07000941e-03, -1.59134145e-03,\n",
      "         -2.99357972e-03,  6.89586485e-03, -5.15427254e-03,\n",
      "          7.12608499e-03,  2.10551941e-03, -2.10629241e-03,\n",
      "          7.24970782e-03, -1.98916925e-04, -4.72520618e-03,\n",
      "         -8.79753288e-03, -3.69718159e-03, -5.25626494e-03,\n",
      "         -2.37010210e-03,  4.70024161e-03,  6.06346643e-03],\n",
      "        [-2.97070411e-03,  2.97995540e-03, -1.23779359e-03,\n",
      "         -1.48976012e-03,  4.71672835e-03, -3.20251868e-03,\n",
      "          3.08349682e-03, -6.30477071e-03,  2.32598337e-04,\n",
      "         -1.17959338e-03,  6.61398936e-03, -6.55137654e-03,\n",
      "          7.96471909e-03,  4.78848163e-03, -8.27416254e-04,\n",
      "          4.25527990e-03, -4.73876462e-05, -2.71336001e-04,\n",
      "         -9.56608076e-03, -5.40720345e-03,  1.62911310e-03,\n",
      "         -5.49544906e-03,  8.63169692e-03,  5.73333446e-03],\n",
      "        [-3.80968070e-03,  6.23745087e-04, -2.69431411e-03,\n",
      "         -2.73314677e-03,  4.32547834e-03, -4.69685765e-03,\n",
      "          5.65268390e-04, -7.94101879e-03,  4.63874283e-04,\n",
      "         -4.18354175e-04,  2.85637914e-03, -5.17200632e-03,\n",
      "          8.26179236e-03,  3.48810316e-03, -1.91491924e-03,\n",
      "          1.16661315e-04, -4.00506984e-03,  5.78876898e-05,\n",
      "         -4.50431695e-03, -1.28274057e-02, -6.82345475e-04,\n",
      "          2.51659803e-04,  5.61391702e-03,  2.77800905e-03],\n",
      "        [-5.16499020e-03,  9.65344138e-04, -1.52369007e-03,\n",
      "         -9.45223554e-04,  2.57628248e-03, -5.68846567e-03,\n",
      "         -2.38329079e-03, -2.61992938e-03,  5.22826856e-04,\n",
      "         -2.24657543e-03, -1.64934748e-03, -2.01845402e-03,\n",
      "          6.93774503e-03,  4.84934164e-04,  6.58138830e-04,\n",
      "          4.01553139e-03, -6.47355220e-04, -1.90987473e-03,\n",
      "         -8.71522527e-04, -1.34543143e-02, -1.43508159e-03,\n",
      "         -1.16271432e-03,  5.18501597e-03,  3.97875160e-03],\n",
      "        [-6.49508368e-03,  1.73752813e-03,  3.36141884e-03,\n",
      "          3.48808360e-03,  2.48478638e-04, -9.57498327e-03,\n",
      "         -7.37091480e-03,  7.11456232e-04, -2.51249387e-03,\n",
      "         -7.45576527e-03, -5.52217802e-03, -3.76641075e-03,\n",
      "          5.95531706e-03,  1.07834442e-03,  1.33907399e-03,\n",
      "          6.50746515e-03,  9.79727367e-04, -6.22590911e-03,\n",
      "         -3.32509610e-03, -1.03354845e-02, -3.80480150e-03,\n",
      "         -3.15315556e-03,  5.01566753e-03,  3.94349173e-03],\n",
      "        [-4.69865324e-03,  7.23967241e-05,  1.73199293e-03,\n",
      "          4.14947141e-03,  1.77902437e-03, -8.80161673e-03,\n",
      "         -7.02068303e-03,  1.64121925e-03,  4.39502823e-04,\n",
      "         -6.11299695e-03, -5.73607301e-03, -4.24017850e-03,\n",
      "          4.04138770e-03,  3.41810659e-03,  1.48106052e-03,\n",
      "          6.41707750e-03, -3.22353700e-03, -6.95198169e-03,\n",
      "         -7.29951216e-03, -1.08775105e-02, -3.91217764e-04,\n",
      "          3.19135329e-03, -2.02226613e-04, -1.53439643e-03],\n",
      "        [-1.55571313e-03, -2.85767415e-03,  6.09408971e-03,\n",
      "         -2.83485628e-03,  3.08127259e-03, -6.05200185e-03,\n",
      "         -5.79130789e-03, -7.43444660e-04, -6.37749385e-04,\n",
      "         -5.96878305e-03, -5.71657810e-03, -1.81123638e-03,\n",
      "          1.56171899e-03,  3.11228423e-03, -1.41048396e-03,\n",
      "          3.24220676e-03, -2.99627939e-03, -3.29907145e-03,\n",
      "         -5.64796990e-03, -6.50685281e-03, -4.98673087e-03,\n",
      "          4.31227498e-03, -1.88320701e-03, -1.70906261e-03],\n",
      "        [-1.06527645e-03,  2.94308853e-03,  6.71228068e-03,\n",
      "          1.74282026e-03,  2.03666580e-03, -9.09614097e-03,\n",
      "         -5.34088816e-03,  4.84144810e-04,  2.07669777e-03,\n",
      "         -7.29425717e-03, -3.02904635e-03, -2.89825769e-03,\n",
      "          2.80050957e-03,  3.34057119e-03, -4.83833160e-03,\n",
      "          6.96449354e-03,  6.91872847e-04,  1.72747881e-03,\n",
      "         -6.73647784e-03, -4.31124261e-03, -2.99812644e-03,\n",
      "          3.67997074e-03, -5.20061119e-04, -1.59814896e-03],\n",
      "        [-1.91590248e-03,  4.02741320e-03,  5.47716813e-03,\n",
      "          4.56047535e-04,  3.25095584e-03, -8.59794021e-03,\n",
      "         -5.64622227e-03, -3.90832685e-03,  2.57031852e-03,\n",
      "         -6.61897380e-03,  1.07745838e-03, -5.54302661e-03,\n",
      "          1.74627057e-03,  2.53617251e-03, -3.74363316e-03,\n",
      "          9.32357041e-04, -3.97581578e-04,  1.69916009e-03,\n",
      "         -4.85049281e-03,  1.93978113e-03, -3.42243770e-03,\n",
      "          7.10552791e-04,  4.18002135e-04, -7.39000243e-05]],\n",
      "\n",
      "       [[ 2.43666698e-03,  3.47954244e-03,  1.10141562e-04,\n",
      "          3.89999896e-03, -2.96596368e-03, -6.07845234e-03,\n",
      "          1.86627090e-04, -1.38304231e-03,  1.52783154e-03,\n",
      "          3.80474812e-04, -2.05500424e-03, -5.88539173e-04,\n",
      "         -2.80263415e-03,  4.25484031e-03,  4.46109660e-03,\n",
      "         -5.36049157e-03, -3.69298691e-03, -6.44852174e-03,\n",
      "         -6.44720218e-04, -1.97991217e-03,  6.64757239e-03,\n",
      "         -7.50900770e-04, -2.51113903e-04, -7.32868304e-03],\n",
      "        [ 4.21748217e-03, -3.65078275e-04,  7.82052739e-05,\n",
      "          8.92664597e-04, -3.79832159e-03, -4.63890936e-03,\n",
      "         -5.12484985e-04, -1.23810369e-05, -1.22558337e-03,\n",
      "          3.77814984e-04, -1.97321712e-03, -9.93730966e-04,\n",
      "         -4.42242250e-03, -8.43097572e-04,  8.68635438e-03,\n",
      "         -1.03923175e-02, -3.35983885e-03, -5.38254529e-03,\n",
      "          1.29142625e-03,  4.83559258e-03,  6.95069088e-03,\n",
      "         -5.01516322e-03,  2.57732160e-03, -4.52809967e-03],\n",
      "        [ 1.55402231e-03, -4.55096504e-03, -4.53423447e-04,\n",
      "         -1.56605477e-03,  1.76153565e-03,  1.60635728e-03,\n",
      "         -2.37538177e-03, -1.26218551e-03, -4.47158841e-03,\n",
      "          5.21411793e-03, -3.30609176e-03,  2.24602292e-04,\n",
      "         -7.13639287e-03,  5.41532354e-04,  8.70989449e-03,\n",
      "         -1.12469485e-02, -2.45448342e-03,  3.65040312e-03,\n",
      "         -4.73827496e-03,  4.03449824e-03,  9.46827978e-03,\n",
      "         -2.37691123e-03,  7.74712302e-04, -8.26028921e-03],\n",
      "        [-9.15979675e-04, -1.26434835e-02, -3.61224939e-03,\n",
      "         -6.95944065e-03,  5.45598846e-03,  8.07265006e-03,\n",
      "          3.81474383e-03, -3.56174470e-03, -3.01088952e-03,\n",
      "          8.52980092e-03, -1.27382472e-03,  3.32405185e-03,\n",
      "         -4.69917571e-03,  1.94727618e-03,  8.75597261e-03,\n",
      "         -8.63289833e-03, -4.33726935e-03, -1.60974334e-03,\n",
      "         -2.26784428e-03,  1.21928402e-03,  5.49898902e-03,\n",
      "         -1.05190999e-03,  1.98922222e-04, -4.27303649e-03],\n",
      "        [-3.81106441e-03, -9.55551583e-03,  4.41668468e-04,\n",
      "         -7.31550762e-03,  7.16067106e-03,  5.05638914e-03,\n",
      "          4.00853902e-03, -7.02171912e-03, -4.95733041e-03,\n",
      "          5.27721969e-03, -2.17611855e-03,  1.64649345e-03,\n",
      "         -6.46752026e-03,  1.80175505e-03,  4.16345056e-03,\n",
      "         -6.52234582e-03,  2.30473728e-04,  2.35313826e-04,\n",
      "         -9.46375367e-04, -3.40038585e-03, -9.30925715e-04,\n",
      "          1.69004285e-04,  1.99730188e-04, -7.80000305e-03],\n",
      "        [ 2.49200524e-03, -8.50101840e-03,  2.85871164e-03,\n",
      "         -7.21057644e-03,  7.03093968e-03,  3.82319838e-03,\n",
      "          2.77882675e-03, -7.96259474e-03, -2.85504269e-03,\n",
      "          1.86193734e-04, -3.05018038e-03,  3.76324193e-03,\n",
      "         -4.93477983e-03, -2.06902390e-03,  6.16305554e-03,\n",
      "         -2.76751933e-03, -7.09207379e-04, -3.50344670e-03,\n",
      "          9.78456112e-04, -7.71057326e-03,  7.41282420e-04,\n",
      "          3.33088427e-03, -3.13105527e-03, -7.48298597e-03],\n",
      "        [ 3.39330756e-03, -4.58637485e-03,  5.02466038e-03,\n",
      "         -8.20348505e-03,  8.15432239e-03,  4.83670970e-03,\n",
      "          3.23042879e-03, -3.87870730e-03, -3.52549576e-03,\n",
      "          1.58770999e-03, -5.75074600e-03,  5.81337465e-03,\n",
      "         -5.00733778e-03, -2.53270194e-03,  3.50574637e-03,\n",
      "         -1.10317266e-03,  2.38270336e-03,  7.44598161e-04,\n",
      "          1.09365105e-03, -9.71995108e-03,  6.37318101e-03,\n",
      "          3.34810861e-03,  9.71890870e-04, -7.56283989e-03],\n",
      "        [ 6.93057382e-06, -2.97075463e-03,  2.44092662e-03,\n",
      "         -1.74158462e-03,  5.84476395e-03,  1.68530899e-03,\n",
      "         -3.24566965e-04, -2.77691684e-03, -2.24045850e-03,\n",
      "          5.71835553e-04, -2.89828307e-03,  1.04470807e-03,\n",
      "          2.79707531e-03, -2.42841686e-03, -6.57955767e-04,\n",
      "          2.16082833e-03,  6.49692316e-04,  2.33518193e-03,\n",
      "         -8.91193748e-04, -6.37207553e-03,  2.55625276e-03,\n",
      "          3.18015786e-03,  2.16913805e-03,  1.48963256e-04],\n",
      "        [ 1.00152940e-03, -8.82217355e-05,  4.19375114e-03,\n",
      "          2.52214842e-03,  4.28971462e-03,  1.64736202e-03,\n",
      "         -2.80340970e-03,  2.76159006e-03,  3.78735771e-04,\n",
      "         -2.04958278e-03, -2.08896375e-03,  1.12263800e-03,\n",
      "          1.82583171e-03, -4.04429855e-03,  3.21633671e-03,\n",
      "          3.81388469e-03, -9.43471736e-04, -2.64738715e-04,\n",
      "          1.90961326e-03, -6.34308811e-03,  1.05146260e-03,\n",
      "          4.22508875e-03, -1.39825616e-03,  1.64992246e-03],\n",
      "        [ 1.13192793e-04, -4.07269603e-04,  2.56955391e-03,\n",
      "         -3.15113552e-03,  5.46101714e-03,  4.50190296e-03,\n",
      "          2.22863350e-03,  4.70036222e-03,  2.32189472e-04,\n",
      "         -2.80183577e-03,  4.23866732e-06,  3.05675552e-03,\n",
      "          3.69632849e-03, -1.79762964e-03,  4.10756562e-03,\n",
      "          1.46525574e-03, -4.59256582e-03, -2.80557922e-03,\n",
      "          1.49190938e-03, -3.20623815e-03, -1.79505107e-04,\n",
      "          1.83421152e-03,  2.93974212e-04,  4.74787503e-03]],\n",
      "\n",
      "       [[ 6.83734706e-03, -3.99794400e-04,  1.81352161e-03,\n",
      "          2.12685624e-03, -3.60272289e-03,  1.76677469e-03,\n",
      "         -2.87977979e-03,  4.29457938e-03,  7.49245228e-04,\n",
      "          8.80263746e-04,  2.90807523e-03, -5.61150722e-04,\n",
      "         -4.33520926e-03, -1.09368819e-03,  3.73977469e-03,\n",
      "          1.73501414e-03,  2.49286997e-03, -4.71250433e-03,\n",
      "          1.09424873e-03, -2.08093808e-03,  4.53014206e-03,\n",
      "          5.65575343e-03, -3.39351082e-03, -3.32745817e-03],\n",
      "        [ 6.27455628e-03, -6.56493474e-04, -5.87639748e-04,\n",
      "          3.83738521e-03, -3.03057744e-03,  2.90536846e-04,\n",
      "         -3.35958437e-03,  1.01287547e-03,  1.44255371e-03,\n",
      "          8.02734809e-04,  9.08852613e-04, -3.95853975e-04,\n",
      "         -1.59544218e-03,  4.49710386e-03,  5.33042289e-03,\n",
      "          1.80741737e-03, -3.05904086e-06, -5.51939942e-04,\n",
      "         -5.46405965e-04, -1.49108155e-03,  6.75603794e-03,\n",
      "          1.24698866e-03, -1.58342312e-03,  3.72338429e-04],\n",
      "        [ 6.17287646e-04,  4.04077535e-03, -2.98248162e-03,\n",
      "          6.15748484e-03, -3.78987379e-03, -2.65360903e-03,\n",
      "         -5.78437757e-05,  4.42949450e-03,  1.37225864e-03,\n",
      "          2.75881425e-03,  1.16451492e-03, -2.58894241e-03,\n",
      "         -3.66974599e-03,  5.01547428e-03,  5.94996242e-03,\n",
      "          2.35343468e-03,  1.33928400e-03,  1.55774396e-04,\n",
      "          2.59474479e-03, -2.79972143e-03,  1.04433214e-02,\n",
      "          1.58727367e-03, -8.62519897e-04,  5.11529041e-04],\n",
      "        [ 2.59268843e-03,  6.79988822e-04,  7.59343908e-04,\n",
      "          4.78510838e-03, -2.93351291e-03, -5.92634315e-04,\n",
      "          1.55352626e-03,  1.67805178e-03,  4.80404263e-03,\n",
      "          2.85058771e-03, -2.20828597e-03,  2.36290507e-03,\n",
      "         -4.77730948e-03,  4.72914847e-03,  7.43797328e-03,\n",
      "         -6.49751164e-04, -2.16404488e-03,  2.87002738e-04,\n",
      "          2.57050479e-03, -9.03201639e-04,  8.20605271e-03,\n",
      "          3.20406398e-03, -8.57262313e-03,  3.47859401e-04],\n",
      "        [ 1.14147515e-04,  4.54612629e-04,  5.35074505e-04,\n",
      "          2.44882354e-03, -3.01207113e-03, -3.28399963e-03,\n",
      "          2.51730345e-03, -8.10452446e-04,  2.61735846e-03,\n",
      "          4.54019429e-03, -4.08370188e-03,  1.91893114e-03,\n",
      "         -7.54557186e-05,  4.36036615e-03,  4.75006737e-03,\n",
      "         -1.75988022e-03, -3.36253271e-03,  1.29481821e-04,\n",
      "          3.86184733e-03, -1.82728283e-03,  8.42943229e-03,\n",
      "          1.11283280e-03, -2.51418655e-03,  3.99540737e-03],\n",
      "        [-3.12309200e-03,  3.31272953e-03,  2.46167625e-03,\n",
      "          5.06224902e-03, -2.22679926e-03, -6.50675269e-03,\n",
      "         -1.26230530e-04,  3.63916508e-04,  2.61788187e-03,\n",
      "         -1.40084268e-03, -3.56652471e-03, -4.07333777e-04,\n",
      "         -6.02238986e-04, -1.13048672e-03,  8.05909187e-03,\n",
      "          1.09170424e-03, -3.17831320e-04, -1.87049096e-04,\n",
      "          7.19158910e-03,  4.49110568e-03,  7.17213377e-03,\n",
      "         -2.39638332e-03, -3.51814879e-03,  8.20740405e-03],\n",
      "        [-6.25513261e-04, -9.10569448e-04, -2.24258355e-03,\n",
      "          1.52162323e-03, -2.97167571e-03,  1.00779254e-03,\n",
      "          4.70322976e-03,  3.80084291e-03,  3.65104876e-03,\n",
      "          3.18470784e-03, -1.73532940e-03,  4.91622230e-03,\n",
      "         -4.24530078e-03, -4.13480401e-03,  1.22485636e-02,\n",
      "         -1.55841908e-03, -1.34958897e-03, -3.40583944e-03,\n",
      "          7.84327276e-03,  8.77292641e-03,  1.13827437e-02,\n",
      "         -3.02553270e-03, -5.20788692e-03,  7.02411076e-03],\n",
      "        [-6.41986821e-03, -1.08597111e-02, -1.08137855e-03,\n",
      "         -1.82433554e-03, -1.88171631e-04,  7.17274239e-03,\n",
      "          6.80613099e-03,  2.21064384e-03,  5.94809512e-03,\n",
      "          2.85210065e-03, -4.38201893e-03,  8.28648824e-03,\n",
      "         -3.16043408e-03, -2.15636916e-03,  8.70051142e-03,\n",
      "         -1.91177253e-03, -3.90019850e-04, -1.47252611e-03,\n",
      "          3.14609520e-03,  7.26996642e-03,  8.31675995e-03,\n",
      "         -3.72800068e-03, -2.73742829e-03,  5.59260696e-03],\n",
      "        [ 1.15534943e-03, -5.77710941e-03, -4.95337590e-04,\n",
      "         -3.95124126e-03,  1.86361535e-03,  9.72273480e-03,\n",
      "          7.19585456e-03,  4.23015701e-03,  1.00527029e-03,\n",
      "          7.78422633e-04,  1.56091130e-03,  5.07158227e-03,\n",
      "         -8.84269481e-04, -3.10420035e-03,  4.14202549e-03,\n",
      "          1.91459653e-03,  1.08917500e-03, -5.21956943e-03,\n",
      "         -1.46197726e-03,  4.06571198e-03,  1.12931523e-03,\n",
      "         -1.61315443e-03, -2.17445267e-04,  1.74327195e-03],\n",
      "        [-1.33385672e-03, -1.01680495e-02, -5.10115176e-03,\n",
      "         -2.48728227e-03, -2.87220697e-04,  8.97445343e-03,\n",
      "          1.01233404e-02,  6.63338637e-04,  2.55411305e-03,\n",
      "          4.59366292e-03,  4.10546141e-04,  5.05729998e-03,\n",
      "          1.27353836e-04,  2.48948950e-03,  1.45857618e-03,\n",
      "         -1.36924069e-03, -1.56305579e-03, -1.05930213e-03,\n",
      "         -7.61824311e-04,  2.10711919e-03,  6.68406766e-03,\n",
      "         -1.49865437e-03,  3.88268905e-04,  1.67534093e-03]]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(4, 12), dtype=float32, numpy=\n",
      "array([[-2.75678816e-04,  3.15991580e-03,  2.18823156e-03,\n",
      "         1.95492571e-03, -1.39250827e-03, -6.15092879e-03,\n",
      "         1.06973690e-03, -2.66930461e-03,  9.93111078e-03,\n",
      "        -4.18335060e-03, -2.38985545e-03, -4.87176265e-04],\n",
      "       [-1.91590248e-03,  4.02741320e-03,  5.47716813e-03,\n",
      "         4.56047535e-04,  3.25095584e-03, -8.59794021e-03,\n",
      "        -5.64622227e-03, -3.90832685e-03,  2.57031852e-03,\n",
      "        -6.61897380e-03,  1.07745838e-03, -5.54302661e-03],\n",
      "       [ 1.13192793e-04, -4.07269603e-04,  2.56955391e-03,\n",
      "        -3.15113552e-03,  5.46101714e-03,  4.50190296e-03,\n",
      "         2.22863350e-03,  4.70036222e-03,  2.32189472e-04,\n",
      "        -2.80183577e-03,  4.23866732e-06,  3.05675552e-03],\n",
      "       [-1.33385672e-03, -1.01680495e-02, -5.10115176e-03,\n",
      "        -2.48728227e-03, -2.87220697e-04,  8.97445343e-03,\n",
      "         1.01233404e-02,  6.63338637e-04,  2.55411305e-03,\n",
      "         4.59366292e-03,  4.10546141e-04,  5.05729998e-03]], dtype=float32)>, <tf.Tensor: shape=(4, 12), dtype=float32, numpy=\n",
      "array([[-5.5667176e-04,  6.3488302e-03,  4.3458375e-03,  3.9200513e-03,\n",
      "        -2.7917726e-03, -1.2413918e-02,  2.1396531e-03, -5.2634929e-03,\n",
      "         1.9883389e-02, -8.3260313e-03, -4.8105884e-03, -9.7815099e-04],\n",
      "       [-3.8577849e-03,  8.0370018e-03,  1.0971859e-02,  9.1428368e-04,\n",
      "         6.5170494e-03, -1.7067458e-02, -1.1368049e-02, -7.8599220e-03,\n",
      "         5.1754927e-03, -1.3140845e-02,  2.1625403e-03, -1.1041679e-02],\n",
      "       [ 2.2404711e-04, -8.1603293e-04,  5.1592351e-03, -6.2589119e-03,\n",
      "         1.0847373e-02,  8.9632580e-03,  4.4714222e-03,  9.4272671e-03,\n",
      "         4.6206545e-04, -5.5979965e-03,  8.4177591e-06,  6.1039482e-03],\n",
      "       [-2.6763319e-03, -2.0217612e-02, -1.0248018e-02, -4.9593961e-03,\n",
      "        -5.7819346e-04,  1.7848436e-02,  2.0339414e-02,  1.3185693e-03,\n",
      "         5.1174541e-03,  9.1872439e-03,  8.1952207e-04,  1.0213087e-02]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(4, 12), dtype=float32, numpy=\n",
      "array([[-2.4070092e-03, -2.6507021e-03, -3.2731262e-04,  7.7652223e-03,\n",
      "         6.2782671e-03, -5.7152947e-03, -3.1029638e-03,  5.8267695e-05,\n",
      "        -9.7048273e-03,  3.2310310e-04, -7.0771400e-04,  1.6323366e-03],\n",
      "       [ 7.0896028e-03,  4.1173184e-03, -4.8612962e-03,  1.0537094e-02,\n",
      "         4.0411963e-03, -2.7579442e-03, -1.4219317e-02, -3.1093862e-03,\n",
      "        -5.7009151e-03, -4.0983339e-03,  9.5257284e-03,  8.0945669e-03],\n",
      "       [-2.8026341e-03,  4.2548403e-03,  4.4610966e-03, -5.3604916e-03,\n",
      "        -3.6929869e-03, -6.4485217e-03, -6.4472022e-04, -1.9799122e-03,\n",
      "         6.6475724e-03, -7.5090077e-04, -2.5111390e-04, -7.3286830e-03],\n",
      "       [-4.3352093e-03, -1.0936882e-03,  3.7397747e-03,  1.7350141e-03,\n",
      "         2.4928700e-03, -4.7125043e-03,  1.0942487e-03, -2.0809381e-03,\n",
      "         4.5301421e-03,  5.6557534e-03, -3.3935108e-03, -3.3274582e-03]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(4, 12), dtype=float32, numpy=\n",
      "array([[-0.0048533 , -0.00531517, -0.00065284,  0.0157036 ,  0.01254567,\n",
      "        -0.01147134, -0.00616637,  0.00011613, -0.01941625,  0.00064612,\n",
      "        -0.00141215,  0.0032662 ],\n",
      "       [ 0.01423055,  0.00828637, -0.00969348,  0.02113231,  0.00812279,\n",
      "        -0.0055414 , -0.02817767, -0.00617176, -0.01133542, -0.00818491,\n",
      "         0.01889618,  0.01612761],\n",
      "       [-0.00560701,  0.00850784,  0.00887663, -0.01065107, -0.00746953,\n",
      "        -0.01289382, -0.00129895, -0.00395446,  0.01328981, -0.00149702,\n",
      "        -0.00050374, -0.014677  ],\n",
      "       [-0.00878754, -0.00218126,  0.00752881,  0.00350061,  0.00500308,\n",
      "        -0.00951086,  0.0021941 , -0.00418826,  0.00920105,  0.01127453,\n",
      "        -0.00688559, -0.0066798 ]], dtype=float32)>]\n",
      "enc_outputs: tf.Tensor(\n",
      "[[[ 3.58280609e-03 -2.77756760e-03 -1.94900855e-03  1.75909034e-03\n",
      "    3.87027278e-04  1.01619912e-03 -3.10345367e-03 -1.59479538e-03\n",
      "    3.01030255e-03 -2.82257004e-03  5.34832943e-04 -8.80464446e-04\n",
      "   -2.40700925e-03 -2.65070214e-03 -3.27312620e-04  7.76522234e-03\n",
      "    6.27826713e-03 -5.71529474e-03 -3.10296379e-03  5.82676948e-05\n",
      "   -9.70482733e-03  3.23103101e-04 -7.07714004e-04  1.63233664e-03]\n",
      "  [ 2.49302224e-03  4.88758367e-03  5.66031924e-03  2.18685344e-03\n",
      "   -1.40863319e-03 -4.50846087e-03 -2.86793220e-03  3.58036341e-04\n",
      "   -1.97534706e-03 -2.76866183e-03  5.99751074e-04 -4.24135197e-03\n",
      "   -5.14633721e-03 -6.17821177e-04 -2.11976795e-03  9.05728806e-03\n",
      "    8.30808934e-03 -2.70160264e-03 -4.05476755e-03 -4.73688170e-03\n",
      "   -7.71968672e-03  3.04814428e-03  2.81281956e-03 -4.38857503e-04]\n",
      "  [ 6.99989917e-03  7.10550137e-03  5.08632697e-03  7.03637488e-05\n",
      "   -2.32466380e-03 -4.24066465e-03 -1.21051434e-03 -3.42844112e-04\n",
      "   -1.88605476e-03 -2.74786772e-03  4.77175042e-03 -3.25892563e-03\n",
      "   -9.46808024e-04 -2.29838653e-03  1.34550233e-03  8.19583703e-03\n",
      "    2.99985823e-03 -1.82673556e-03 -5.21777850e-03 -5.16294967e-04\n",
      "   -6.00401964e-03  3.76146217e-03 -1.04124821e-03  2.61611096e-03]\n",
      "  [ 4.19341587e-03  6.14448870e-03  6.18888345e-03 -1.27181713e-03\n",
      "    3.80567880e-03  6.52288727e-04 -2.99588079e-03 -4.85470169e-04\n",
      "   -4.66118974e-04 -1.44541753e-03  3.00211576e-03 -2.74948357e-03\n",
      "   -2.04695668e-03 -8.24803661e-04  2.87915044e-03  6.63590059e-03\n",
      "    4.95133968e-03  3.18135880e-03 -6.40356448e-03 -1.23388215e-03\n",
      "    1.23470218e-03  1.48162059e-03  8.16360116e-04  7.45223195e-04]\n",
      "  [-1.13424659e-03  6.21440960e-03  4.91579203e-03  9.40591272e-04\n",
      "    5.74464072e-03 -1.10000477e-03 -6.85977191e-03 -8.09311896e-05\n",
      "   -2.57598865e-03 -3.00930557e-03  4.51023271e-03 -8.03641789e-03\n",
      "    5.50158089e-03  2.13911943e-03  7.28904677e-04  6.88684126e-03\n",
      "   -1.01850438e-03  9.53735376e-04 -5.93701284e-03 -4.24588937e-03\n",
      "   -7.64529163e-04  3.77666950e-03  1.96793606e-03  6.21211343e-03]\n",
      "  [-1.73668406e-04  6.45449711e-03 -6.37668767e-04 -1.93506887e-03\n",
      "    6.40251348e-03  8.54265585e-04 -1.49640813e-03 -3.46396089e-04\n",
      "    1.93763850e-03 -9.68891662e-04  2.80006323e-03 -2.43882276e-03\n",
      "    1.73987227e-03  4.76575969e-03  4.62461030e-03  6.78399159e-03\n",
      "   -4.07201657e-03 -2.79460032e-03 -4.30145883e-04 -3.33023863e-03\n",
      "    1.39932567e-03  5.27853286e-03 -5.52365463e-03  4.86750063e-03]\n",
      "  [-4.54845186e-03  1.54248410e-04 -9.06044559e-04  8.28761375e-04\n",
      "    2.23133340e-03 -1.35301217e-03  2.05337931e-03 -3.42476508e-03\n",
      "    8.92869849e-03 -1.70469005e-03  2.43144808e-03 -6.40798244e-04\n",
      "    1.48227706e-03  6.04586862e-03  1.11598754e-03  6.55180356e-03\n",
      "   -9.36585711e-04 -2.72103562e-03 -1.41141194e-04 -2.60238280e-03\n",
      "    1.27604115e-03  3.67188640e-03 -3.41553311e-03  5.46074845e-03]\n",
      "  [-7.41290569e-04  7.54420273e-03  2.29949874e-04  2.07306212e-03\n",
      "   -1.35527481e-03 -5.46101993e-03  2.42424221e-03 -5.80882595e-04\n",
      "    5.45511534e-03 -3.04260687e-03  2.30934145e-03 -1.38671976e-03\n",
      "   -1.14156515e-03  2.42187292e-03  1.70355884e-03  5.77286584e-03\n",
      "    2.19334965e-03 -4.87430766e-03  1.60333246e-03 -2.99742469e-03\n",
      "   -2.34901207e-03  8.83411092e-04 -1.25613087e-03  2.04123775e-04]\n",
      "  [-2.15950399e-03  5.35545684e-03 -2.89025088e-03  1.56089326e-03\n",
      "    6.04334520e-04 -4.60798247e-03  4.28268267e-03 -6.31816976e-04\n",
      "    6.99597411e-03 -1.85230665e-03  1.29837310e-04 -7.29667954e-04\n",
      "   -1.22170569e-03  3.47670796e-03  3.59010929e-03  3.08965147e-03\n",
      "   -2.09008595e-05 -3.86304874e-03  4.84580436e-04 -1.95071381e-03\n",
      "    3.27013526e-03  2.02705705e-04 -2.96254992e-03 -6.66132022e-04]\n",
      "  [-2.75678816e-04  3.15991580e-03  2.18823156e-03  1.95492571e-03\n",
      "   -1.39250827e-03 -6.15092879e-03  1.06973690e-03 -2.66930461e-03\n",
      "    9.93111078e-03 -4.18335060e-03 -2.38985545e-03 -4.87176265e-04\n",
      "   -3.62173724e-03  2.82371743e-03 -9.39416583e-04 -3.58753838e-04\n",
      "    7.51893851e-04 -1.75333023e-03  1.85608771e-03 -8.54500628e-04\n",
      "   -2.76953913e-04  2.09728512e-03 -4.59167501e-03 -3.41672497e-03]]\n",
      "\n",
      " [[-5.69531322e-03  1.46171683e-03  3.78182414e-03 -1.13680575e-03\n",
      "    4.24085744e-03 -2.39906274e-03  4.04144230e-04 -3.08782794e-03\n",
      "   -1.67893106e-03 -2.39869370e-03  4.40772111e-03 -7.05026137e-03\n",
      "    7.08960276e-03  4.11731843e-03 -4.86129615e-03  1.05370944e-02\n",
      "    4.04119631e-03 -2.75794417e-03 -1.42193167e-02 -3.10938619e-03\n",
      "   -5.70091512e-03 -4.09833388e-03  9.52572841e-03  8.09456687e-03]\n",
      "  [ 1.67277956e-03  4.89391014e-03  2.95354985e-03 -2.61627510e-03\n",
      "    1.78165711e-03 -3.21532413e-03  1.46396132e-03 -3.07000941e-03\n",
      "   -1.59134145e-03 -2.99357972e-03  6.89586485e-03 -5.15427254e-03\n",
      "    7.12608499e-03  2.10551941e-03 -2.10629241e-03  7.24970782e-03\n",
      "   -1.98916925e-04 -4.72520618e-03 -8.79753288e-03 -3.69718159e-03\n",
      "   -5.25626494e-03 -2.37010210e-03  4.70024161e-03  6.06346643e-03]\n",
      "  [-2.97070411e-03  2.97995540e-03 -1.23779359e-03 -1.48976012e-03\n",
      "    4.71672835e-03 -3.20251868e-03  3.08349682e-03 -6.30477071e-03\n",
      "    2.32598337e-04 -1.17959338e-03  6.61398936e-03 -6.55137654e-03\n",
      "    7.96471909e-03  4.78848163e-03 -8.27416254e-04  4.25527990e-03\n",
      "   -4.73876462e-05 -2.71336001e-04 -9.56608076e-03 -5.40720345e-03\n",
      "    1.62911310e-03 -5.49544906e-03  8.63169692e-03  5.73333446e-03]\n",
      "  [-3.80968070e-03  6.23745087e-04 -2.69431411e-03 -2.73314677e-03\n",
      "    4.32547834e-03 -4.69685765e-03  5.65268390e-04 -7.94101879e-03\n",
      "    4.63874283e-04 -4.18354175e-04  2.85637914e-03 -5.17200632e-03\n",
      "    8.26179236e-03  3.48810316e-03 -1.91491924e-03  1.16661315e-04\n",
      "   -4.00506984e-03  5.78876898e-05 -4.50431695e-03 -1.28274057e-02\n",
      "   -6.82345475e-04  2.51659803e-04  5.61391702e-03  2.77800905e-03]\n",
      "  [-5.16499020e-03  9.65344138e-04 -1.52369007e-03 -9.45223554e-04\n",
      "    2.57628248e-03 -5.68846567e-03 -2.38329079e-03 -2.61992938e-03\n",
      "    5.22826856e-04 -2.24657543e-03 -1.64934748e-03 -2.01845402e-03\n",
      "    6.93774503e-03  4.84934164e-04  6.58138830e-04  4.01553139e-03\n",
      "   -6.47355220e-04 -1.90987473e-03 -8.71522527e-04 -1.34543143e-02\n",
      "   -1.43508159e-03 -1.16271432e-03  5.18501597e-03  3.97875160e-03]\n",
      "  [-6.49508368e-03  1.73752813e-03  3.36141884e-03  3.48808360e-03\n",
      "    2.48478638e-04 -9.57498327e-03 -7.37091480e-03  7.11456232e-04\n",
      "   -2.51249387e-03 -7.45576527e-03 -5.52217802e-03 -3.76641075e-03\n",
      "    5.95531706e-03  1.07834442e-03  1.33907399e-03  6.50746515e-03\n",
      "    9.79727367e-04 -6.22590911e-03 -3.32509610e-03 -1.03354845e-02\n",
      "   -3.80480150e-03 -3.15315556e-03  5.01566753e-03  3.94349173e-03]\n",
      "  [-4.69865324e-03  7.23967241e-05  1.73199293e-03  4.14947141e-03\n",
      "    1.77902437e-03 -8.80161673e-03 -7.02068303e-03  1.64121925e-03\n",
      "    4.39502823e-04 -6.11299695e-03 -5.73607301e-03 -4.24017850e-03\n",
      "    4.04138770e-03  3.41810659e-03  1.48106052e-03  6.41707750e-03\n",
      "   -3.22353700e-03 -6.95198169e-03 -7.29951216e-03 -1.08775105e-02\n",
      "   -3.91217764e-04  3.19135329e-03 -2.02226613e-04 -1.53439643e-03]\n",
      "  [-1.55571313e-03 -2.85767415e-03  6.09408971e-03 -2.83485628e-03\n",
      "    3.08127259e-03 -6.05200185e-03 -5.79130789e-03 -7.43444660e-04\n",
      "   -6.37749385e-04 -5.96878305e-03 -5.71657810e-03 -1.81123638e-03\n",
      "    1.56171899e-03  3.11228423e-03 -1.41048396e-03  3.24220676e-03\n",
      "   -2.99627939e-03 -3.29907145e-03 -5.64796990e-03 -6.50685281e-03\n",
      "   -4.98673087e-03  4.31227498e-03 -1.88320701e-03 -1.70906261e-03]\n",
      "  [-1.06527645e-03  2.94308853e-03  6.71228068e-03  1.74282026e-03\n",
      "    2.03666580e-03 -9.09614097e-03 -5.34088816e-03  4.84144810e-04\n",
      "    2.07669777e-03 -7.29425717e-03 -3.02904635e-03 -2.89825769e-03\n",
      "    2.80050957e-03  3.34057119e-03 -4.83833160e-03  6.96449354e-03\n",
      "    6.91872847e-04  1.72747881e-03 -6.73647784e-03 -4.31124261e-03\n",
      "   -2.99812644e-03  3.67997074e-03 -5.20061119e-04 -1.59814896e-03]\n",
      "  [-1.91590248e-03  4.02741320e-03  5.47716813e-03  4.56047535e-04\n",
      "    3.25095584e-03 -8.59794021e-03 -5.64622227e-03 -3.90832685e-03\n",
      "    2.57031852e-03 -6.61897380e-03  1.07745838e-03 -5.54302661e-03\n",
      "    1.74627057e-03  2.53617251e-03 -3.74363316e-03  9.32357041e-04\n",
      "   -3.97581578e-04  1.69916009e-03 -4.85049281e-03  1.93978113e-03\n",
      "   -3.42243770e-03  7.10552791e-04  4.18002135e-04 -7.39000243e-05]]\n",
      "\n",
      " [[ 2.43666698e-03  3.47954244e-03  1.10141562e-04  3.89999896e-03\n",
      "   -2.96596368e-03 -6.07845234e-03  1.86627090e-04 -1.38304231e-03\n",
      "    1.52783154e-03  3.80474812e-04 -2.05500424e-03 -5.88539173e-04\n",
      "   -2.80263415e-03  4.25484031e-03  4.46109660e-03 -5.36049157e-03\n",
      "   -3.69298691e-03 -6.44852174e-03 -6.44720218e-04 -1.97991217e-03\n",
      "    6.64757239e-03 -7.50900770e-04 -2.51113903e-04 -7.32868304e-03]\n",
      "  [ 4.21748217e-03 -3.65078275e-04  7.82052739e-05  8.92664597e-04\n",
      "   -3.79832159e-03 -4.63890936e-03 -5.12484985e-04 -1.23810369e-05\n",
      "   -1.22558337e-03  3.77814984e-04 -1.97321712e-03 -9.93730966e-04\n",
      "   -4.42242250e-03 -8.43097572e-04  8.68635438e-03 -1.03923175e-02\n",
      "   -3.35983885e-03 -5.38254529e-03  1.29142625e-03  4.83559258e-03\n",
      "    6.95069088e-03 -5.01516322e-03  2.57732160e-03 -4.52809967e-03]\n",
      "  [ 1.55402231e-03 -4.55096504e-03 -4.53423447e-04 -1.56605477e-03\n",
      "    1.76153565e-03  1.60635728e-03 -2.37538177e-03 -1.26218551e-03\n",
      "   -4.47158841e-03  5.21411793e-03 -3.30609176e-03  2.24602292e-04\n",
      "   -7.13639287e-03  5.41532354e-04  8.70989449e-03 -1.12469485e-02\n",
      "   -2.45448342e-03  3.65040312e-03 -4.73827496e-03  4.03449824e-03\n",
      "    9.46827978e-03 -2.37691123e-03  7.74712302e-04 -8.26028921e-03]\n",
      "  [-9.15979675e-04 -1.26434835e-02 -3.61224939e-03 -6.95944065e-03\n",
      "    5.45598846e-03  8.07265006e-03  3.81474383e-03 -3.56174470e-03\n",
      "   -3.01088952e-03  8.52980092e-03 -1.27382472e-03  3.32405185e-03\n",
      "   -4.69917571e-03  1.94727618e-03  8.75597261e-03 -8.63289833e-03\n",
      "   -4.33726935e-03 -1.60974334e-03 -2.26784428e-03  1.21928402e-03\n",
      "    5.49898902e-03 -1.05190999e-03  1.98922222e-04 -4.27303649e-03]\n",
      "  [-3.81106441e-03 -9.55551583e-03  4.41668468e-04 -7.31550762e-03\n",
      "    7.16067106e-03  5.05638914e-03  4.00853902e-03 -7.02171912e-03\n",
      "   -4.95733041e-03  5.27721969e-03 -2.17611855e-03  1.64649345e-03\n",
      "   -6.46752026e-03  1.80175505e-03  4.16345056e-03 -6.52234582e-03\n",
      "    2.30473728e-04  2.35313826e-04 -9.46375367e-04 -3.40038585e-03\n",
      "   -9.30925715e-04  1.69004285e-04  1.99730188e-04 -7.80000305e-03]\n",
      "  [ 2.49200524e-03 -8.50101840e-03  2.85871164e-03 -7.21057644e-03\n",
      "    7.03093968e-03  3.82319838e-03  2.77882675e-03 -7.96259474e-03\n",
      "   -2.85504269e-03  1.86193734e-04 -3.05018038e-03  3.76324193e-03\n",
      "   -4.93477983e-03 -2.06902390e-03  6.16305554e-03 -2.76751933e-03\n",
      "   -7.09207379e-04 -3.50344670e-03  9.78456112e-04 -7.71057326e-03\n",
      "    7.41282420e-04  3.33088427e-03 -3.13105527e-03 -7.48298597e-03]\n",
      "  [ 3.39330756e-03 -4.58637485e-03  5.02466038e-03 -8.20348505e-03\n",
      "    8.15432239e-03  4.83670970e-03  3.23042879e-03 -3.87870730e-03\n",
      "   -3.52549576e-03  1.58770999e-03 -5.75074600e-03  5.81337465e-03\n",
      "   -5.00733778e-03 -2.53270194e-03  3.50574637e-03 -1.10317266e-03\n",
      "    2.38270336e-03  7.44598161e-04  1.09365105e-03 -9.71995108e-03\n",
      "    6.37318101e-03  3.34810861e-03  9.71890870e-04 -7.56283989e-03]\n",
      "  [ 6.93057382e-06 -2.97075463e-03  2.44092662e-03 -1.74158462e-03\n",
      "    5.84476395e-03  1.68530899e-03 -3.24566965e-04 -2.77691684e-03\n",
      "   -2.24045850e-03  5.71835553e-04 -2.89828307e-03  1.04470807e-03\n",
      "    2.79707531e-03 -2.42841686e-03 -6.57955767e-04  2.16082833e-03\n",
      "    6.49692316e-04  2.33518193e-03 -8.91193748e-04 -6.37207553e-03\n",
      "    2.55625276e-03  3.18015786e-03  2.16913805e-03  1.48963256e-04]\n",
      "  [ 1.00152940e-03 -8.82217355e-05  4.19375114e-03  2.52214842e-03\n",
      "    4.28971462e-03  1.64736202e-03 -2.80340970e-03  2.76159006e-03\n",
      "    3.78735771e-04 -2.04958278e-03 -2.08896375e-03  1.12263800e-03\n",
      "    1.82583171e-03 -4.04429855e-03  3.21633671e-03  3.81388469e-03\n",
      "   -9.43471736e-04 -2.64738715e-04  1.90961326e-03 -6.34308811e-03\n",
      "    1.05146260e-03  4.22508875e-03 -1.39825616e-03  1.64992246e-03]\n",
      "  [ 1.13192793e-04 -4.07269603e-04  2.56955391e-03 -3.15113552e-03\n",
      "    5.46101714e-03  4.50190296e-03  2.22863350e-03  4.70036222e-03\n",
      "    2.32189472e-04 -2.80183577e-03  4.23866732e-06  3.05675552e-03\n",
      "    3.69632849e-03 -1.79762964e-03  4.10756562e-03  1.46525574e-03\n",
      "   -4.59256582e-03 -2.80557922e-03  1.49190938e-03 -3.20623815e-03\n",
      "   -1.79505107e-04  1.83421152e-03  2.93974212e-04  4.74787503e-03]]\n",
      "\n",
      " [[ 6.83734706e-03 -3.99794400e-04  1.81352161e-03  2.12685624e-03\n",
      "   -3.60272289e-03  1.76677469e-03 -2.87977979e-03  4.29457938e-03\n",
      "    7.49245228e-04  8.80263746e-04  2.90807523e-03 -5.61150722e-04\n",
      "   -4.33520926e-03 -1.09368819e-03  3.73977469e-03  1.73501414e-03\n",
      "    2.49286997e-03 -4.71250433e-03  1.09424873e-03 -2.08093808e-03\n",
      "    4.53014206e-03  5.65575343e-03 -3.39351082e-03 -3.32745817e-03]\n",
      "  [ 6.27455628e-03 -6.56493474e-04 -5.87639748e-04  3.83738521e-03\n",
      "   -3.03057744e-03  2.90536846e-04 -3.35958437e-03  1.01287547e-03\n",
      "    1.44255371e-03  8.02734809e-04  9.08852613e-04 -3.95853975e-04\n",
      "   -1.59544218e-03  4.49710386e-03  5.33042289e-03  1.80741737e-03\n",
      "   -3.05904086e-06 -5.51939942e-04 -5.46405965e-04 -1.49108155e-03\n",
      "    6.75603794e-03  1.24698866e-03 -1.58342312e-03  3.72338429e-04]\n",
      "  [ 6.17287646e-04  4.04077535e-03 -2.98248162e-03  6.15748484e-03\n",
      "   -3.78987379e-03 -2.65360903e-03 -5.78437757e-05  4.42949450e-03\n",
      "    1.37225864e-03  2.75881425e-03  1.16451492e-03 -2.58894241e-03\n",
      "   -3.66974599e-03  5.01547428e-03  5.94996242e-03  2.35343468e-03\n",
      "    1.33928400e-03  1.55774396e-04  2.59474479e-03 -2.79972143e-03\n",
      "    1.04433214e-02  1.58727367e-03 -8.62519897e-04  5.11529041e-04]\n",
      "  [ 2.59268843e-03  6.79988822e-04  7.59343908e-04  4.78510838e-03\n",
      "   -2.93351291e-03 -5.92634315e-04  1.55352626e-03  1.67805178e-03\n",
      "    4.80404263e-03  2.85058771e-03 -2.20828597e-03  2.36290507e-03\n",
      "   -4.77730948e-03  4.72914847e-03  7.43797328e-03 -6.49751164e-04\n",
      "   -2.16404488e-03  2.87002738e-04  2.57050479e-03 -9.03201639e-04\n",
      "    8.20605271e-03  3.20406398e-03 -8.57262313e-03  3.47859401e-04]\n",
      "  [ 1.14147515e-04  4.54612629e-04  5.35074505e-04  2.44882354e-03\n",
      "   -3.01207113e-03 -3.28399963e-03  2.51730345e-03 -8.10452446e-04\n",
      "    2.61735846e-03  4.54019429e-03 -4.08370188e-03  1.91893114e-03\n",
      "   -7.54557186e-05  4.36036615e-03  4.75006737e-03 -1.75988022e-03\n",
      "   -3.36253271e-03  1.29481821e-04  3.86184733e-03 -1.82728283e-03\n",
      "    8.42943229e-03  1.11283280e-03 -2.51418655e-03  3.99540737e-03]\n",
      "  [-3.12309200e-03  3.31272953e-03  2.46167625e-03  5.06224902e-03\n",
      "   -2.22679926e-03 -6.50675269e-03 -1.26230530e-04  3.63916508e-04\n",
      "    2.61788187e-03 -1.40084268e-03 -3.56652471e-03 -4.07333777e-04\n",
      "   -6.02238986e-04 -1.13048672e-03  8.05909187e-03  1.09170424e-03\n",
      "   -3.17831320e-04 -1.87049096e-04  7.19158910e-03  4.49110568e-03\n",
      "    7.17213377e-03 -2.39638332e-03 -3.51814879e-03  8.20740405e-03]\n",
      "  [-6.25513261e-04 -9.10569448e-04 -2.24258355e-03  1.52162323e-03\n",
      "   -2.97167571e-03  1.00779254e-03  4.70322976e-03  3.80084291e-03\n",
      "    3.65104876e-03  3.18470784e-03 -1.73532940e-03  4.91622230e-03\n",
      "   -4.24530078e-03 -4.13480401e-03  1.22485636e-02 -1.55841908e-03\n",
      "   -1.34958897e-03 -3.40583944e-03  7.84327276e-03  8.77292641e-03\n",
      "    1.13827437e-02 -3.02553270e-03 -5.20788692e-03  7.02411076e-03]\n",
      "  [-6.41986821e-03 -1.08597111e-02 -1.08137855e-03 -1.82433554e-03\n",
      "   -1.88171631e-04  7.17274239e-03  6.80613099e-03  2.21064384e-03\n",
      "    5.94809512e-03  2.85210065e-03 -4.38201893e-03  8.28648824e-03\n",
      "   -3.16043408e-03 -2.15636916e-03  8.70051142e-03 -1.91177253e-03\n",
      "   -3.90019850e-04 -1.47252611e-03  3.14609520e-03  7.26996642e-03\n",
      "    8.31675995e-03 -3.72800068e-03 -2.73742829e-03  5.59260696e-03]\n",
      "  [ 1.15534943e-03 -5.77710941e-03 -4.95337590e-04 -3.95124126e-03\n",
      "    1.86361535e-03  9.72273480e-03  7.19585456e-03  4.23015701e-03\n",
      "    1.00527029e-03  7.78422633e-04  1.56091130e-03  5.07158227e-03\n",
      "   -8.84269481e-04 -3.10420035e-03  4.14202549e-03  1.91459653e-03\n",
      "    1.08917500e-03 -5.21956943e-03 -1.46197726e-03  4.06571198e-03\n",
      "    1.12931523e-03 -1.61315443e-03 -2.17445267e-04  1.74327195e-03]\n",
      "  [-1.33385672e-03 -1.01680495e-02 -5.10115176e-03 -2.48728227e-03\n",
      "   -2.87220697e-04  8.97445343e-03  1.01233404e-02  6.63338637e-04\n",
      "    2.55411305e-03  4.59366292e-03  4.10546141e-04  5.05729998e-03\n",
      "    1.27353836e-04  2.48948950e-03  1.45857618e-03 -1.36924069e-03\n",
      "   -1.56305579e-03 -1.05930213e-03 -7.61824311e-04  2.10711919e-03\n",
      "    6.68406766e-03 -1.49865437e-03  3.88268905e-04  1.67534093e-03]]], shape=(4, 10, 24), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import bert.bert_modeling as bert_modeling\n",
    "import copy \n",
    "\n",
    "batch_size = 4\n",
    "seq_len=10\n",
    "feature_size = 12\n",
    "hidden_size=12\n",
    "max_dec_length = 8\n",
    "max_oov = 11\n",
    "vocab_size = 3000\n",
    "float_type=tf.float32\n",
    "\n",
    "bert_config = bert_modeling.BertConfig(vocab_size)\n",
    "\n",
    "bert_config.add_from_dict({\"hidden_size\":hidden_size, \n",
    "                           \"max_seq_length\":seq_len,\n",
    "                           \"use_pointer_gen\":True,\n",
    "                           \"max_oov_size\":max_oov})\n",
    "\n",
    "input_word_ids = np.random.randint(vocab_size, size=(batch_size,seq_len),dtype=np.int32)\n",
    "masks=tf.ones([batch_size,seq_len],tf.float32)\n",
    "\n",
    " \n",
    "#print(oov_ids)\n",
    "answer_ids=np.random.randint(vocab_size, size=(batch_size,max_dec_length))\n",
    "answer_mask=tf.ones([batch_size,max_dec_length],tf.float32)\n",
    "\n",
    "pgnet_model_layer =PGNetSummaryModel(config=bert_config ,\n",
    "                                                  float_type=float_type,\n",
    "                                                 name='pgnet_summary_model')\n",
    "\n",
    "\n",
    "final_dists, attn_dists = pgnet_model_layer(  input_word_ids,\n",
    "                                                masks,\n",
    "                                                answer_ids,\n",
    "                                                answer_mask \n",
    "                                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run BERT on CoQA, adapted from Google's run_Squad.py\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import functools\n",
    "import json\n",
    "import os\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "\n",
    "# pylint: disable=unused-import,g-import-not-at-top,redefined-outer-name,reimported\n",
    "from modeling import model_training_utils\n",
    "from bert import bert_modeling as bert_modeling\n",
    "from pgnet import pgnet_models\n",
    "from bert import optimization\n",
    "from bert import common_flags\n",
    "from bert import input_pipeline\n",
    "from bert import model_saving_utils\n",
    "import coqa_pgnet_lib\n",
    "from bert import tokenization\n",
    "from utils.misc import keras_utils\n",
    "from utils.misc import tpu_lib\n",
    " \n",
    "#FLAGS.remove_flag_values(FLAGS.flag_values_dict()) \n",
    "\n",
    "flags.DEFINE_enum(\n",
    "    'mode', 'train_and_predict',\n",
    "    ['train_and_predict', 'train', 'predict', 'export_only'],\n",
    "    'One of {\"train_and_predict\", \"train\", \"predict\", \"export_only\"}. '\n",
    "    '`train_and_predict`: both train and predict to a json file. '\n",
    "    '`train`: only trains the model. '\n",
    "    '`predict`: predict answers from the coqa json file. '\n",
    "    '`export_only`: will take the latest checkpoint inside '\n",
    "    'model_dir and export a `SavedModel`.')\n",
    "flags.DEFINE_string('train_data_path', '',\n",
    "                    'Training data path with train tfrecords.')\n",
    "flags.DEFINE_string(\n",
    "    'input_meta_data_path', None,\n",
    "    'Path to file that contains meta data about input '\n",
    "    'to be used for training and evaluation.')\n",
    "# Model training specific flags.\n",
    "flags.DEFINE_integer('train_batch_size', 32, 'Total batch size for training.')\n",
    "# Predict processing related.\n",
    "flags.DEFINE_string('predict_file', None,\n",
    "                    'Prediction data path with train tfrecords.')\n",
    "flags.DEFINE_string('vocab_file', None,\n",
    "                    'The vocabulary file that the BERT model was trained on.')\n",
    "flags.DEFINE_bool(\n",
    "    'do_lower_case', True,\n",
    "    'Whether to lower case the input text. Should be True for uncased '\n",
    "    'models and False for cased models.')\n",
    "flags.DEFINE_bool(\n",
    "    'verbose_logging', False,\n",
    "    'If true, all of the warnings related to data processing will be printed. '\n",
    "    'A number of warnings are expected for a normal SQuAD evaluation.')\n",
    "flags.DEFINE_integer('predict_batch_size', 8,\n",
    "                     'Total batch size for prediction.')\n",
    "flags.DEFINE_integer(\n",
    "    'n_best_size', 20,\n",
    "    'The total number of n-best predictions to generate in the '\n",
    "    'nbest_predictions.json output file.')\n",
    "flags.DEFINE_integer(\n",
    "    'max_answer_length', 30,\n",
    "    'The maximum length of an answer that can be generated. This is needed '\n",
    "    'because the start and end predictions are not conditioned on one another.')\n",
    "flags.DEFINE_float('cov_loss_wt', 1.0,\n",
    "                   'Weight of coverage loss (lambda in the paper). '\n",
    "                   'If zero, then no incentive to minimize coverage loss.')\n",
    "flags.DEFINE_boolean('use_pointer_gen', True,\n",
    "                     'If True, use pointer-generator model. If False, use baseline model.')\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    'max_oov_size', 10,\n",
    "    'The maximum number of possible OOV words per input sequence.  ')\n",
    "\n",
    "common_flags.define_common_bert_flags()\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "ERROR:absl:steps_per_loop: 200 is specified to be greater than  steps_per_epoch: 184, we will use steps_per_epoch as steps_per_loop.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n    relative to /Users/wweschen/tf2:\n\n    capstone/pgnet/pgnet_modeling.py:219 call  *\n        decoder_outputs, self._dec_out_state, self.attn_dists, self.p_gens, self.coverage = self.decoder(\n    capstone/pgnet/pgnet_modeling.py:507 __call__  *\n        return super(AttentionDecoder, self).__call__(inputs, **kwargs)\n    env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:822 __call__\n        outputs = self.call(cast_inputs, *args, **kwargs)\n    capstone/pgnet/pgnet_modeling.py:522 call\n        encoder_states = tf.expand_dims(encoder_states, axis=2)  # now is shape (batch_size, attn_len, 1, attn_size)\n    env/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py:180 wrapper\n        return target(*args, **kwargs)\n    env/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:399 expand_dims_v2\n        return gen_array_ops.expand_dims(input, axis, name)\n    env/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py:2202 expand_dims\n        \"ExpandDims\", input=input, dim=axis, name=name)\n    env/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:486 _apply_op_helper\n        (input_name, err))\n\n    ValueError: Tried to convert 'input' to a tensor and failed. Error: Dimension 0 in both shapes must be equal, but are 384 and 1536. Shapes are [384] and [1536].\n    \tFrom merging shape 1 with other shapes. for 'pgnet_summary_model_1/attention_decoder_1/ExpandDims/packed' (op: 'Pack') with input shapes: ?, [384], [1536].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-086779f01a13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    372\u001b[0m          '--strategy_type=mirror']\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-086779f01a13>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-086779f01a13>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m    340\u001b[0m                      FLAGS.strategy_type)\n\u001b[1;32m    341\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_and_predict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0mtrain_coqa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_meta_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_and_predict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0mpredict_coqa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_meta_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-086779f01a13>\u001b[0m in \u001b[0;36mtrain_coqa\u001b[0;34m(strategy, input_meta_data, custom_callbacks, run_eagerly)\u001b[0m\n\u001b[1;32m    227\u001b[0m       \u001b[0minit_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m       \u001b[0mrun_eagerly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m       custom_callbacks=custom_callbacks)\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/capstone/modeling/model_training_utils.py\u001b[0m in \u001b[0;36mrun_customized_training_loop\u001b[0;34m(_sentinel, strategy, model_fn, loss_fn, model_dir, train_input_fn, steps_per_epoch, steps_per_loop, epochs, eval_input_fn, eval_steps, metric_fn, init_checkpoint, custom_callbacks, run_eagerly)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# To correctly place the model weights on accelerators,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;31m# model and optimizer should be created in scope.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m       raise ValueError('User should set optimizer attribute to model '\n",
      "\u001b[0;32m<ipython-input-12-086779f01a13>\u001b[0m in \u001b[0;36m_get_coqa_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mmax_answer_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_oov_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         float_type=tf.float16 if use_float16 else tf.float32)\n\u001b[0m\u001b[1;32m    191\u001b[0m     coqa_model.optimizer = optimization.create_optimizer(\n\u001b[1;32m    192\u001b[0m         FLAGS.learning_rate, steps_per_epoch * epochs, warmup_steps)\n",
      "\u001b[0;32m~/tf2/capstone/pgnet/pgnet_models.py\u001b[0m in \u001b[0;36mcoqa_model\u001b[0;34m(bert_config, max_seq_length, max_answer_length, max_oov_size, float_type, initializer)\u001b[0m\n\u001b[1;32m    130\u001b[0m                                                  \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                                                \u001b[0manswer_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                                                \u001b[0manswer_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                                              )\n\u001b[1;32m    134\u001b[0m   coqa = tf.keras.Model(\n",
      "\u001b[0;32m~/tf2/capstone/pgnet/pgnet_modeling.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_word_ids, input_mask, answer_ids, answer_mask, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m                  **kwargs):\n\u001b[1;32m    193\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_word_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPGNetSummaryModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pgnet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    772\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/env/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n    relative to /Users/wweschen/tf2:\n\n    capstone/pgnet/pgnet_modeling.py:219 call  *\n        decoder_outputs, self._dec_out_state, self.attn_dists, self.p_gens, self.coverage = self.decoder(\n    capstone/pgnet/pgnet_modeling.py:507 __call__  *\n        return super(AttentionDecoder, self).__call__(inputs, **kwargs)\n    env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:822 __call__\n        outputs = self.call(cast_inputs, *args, **kwargs)\n    capstone/pgnet/pgnet_modeling.py:522 call\n        encoder_states = tf.expand_dims(encoder_states, axis=2)  # now is shape (batch_size, attn_len, 1, attn_size)\n    env/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py:180 wrapper\n        return target(*args, **kwargs)\n    env/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:399 expand_dims_v2\n        return gen_array_ops.expand_dims(input, axis, name)\n    env/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py:2202 expand_dims\n        \"ExpandDims\", input=input, dim=axis, name=name)\n    env/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:486 _apply_op_helper\n        (input_name, err))\n\n    ValueError: Tried to convert 'input' to a tensor and failed. Error: Dimension 0 in both shapes must be equal, but are 384 and 1536. Shapes are [384] and [1536].\n    \tFrom merging shape 1 with other shapes. for 'pgnet_summary_model_1/attention_decoder_1/ExpandDims/packed' (op: 'Pack') with input shapes: ?, [384], [1536].\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def coqa_loss_fn( final_dists,\n",
    "                  attn_dists,\n",
    "                  target_words_ids,\n",
    "                  dec_padding_mask,\n",
    "                  loss_factor=1.0):\n",
    "\n",
    "    # Calculate the loss per step\n",
    "    # This is fiddly; we use tf.gather_nd to pick out the probabilities of the gold target words\n",
    "    loss_per_step = [] # will be list length max_dec_steps containing shape (batch_size)\n",
    "    batch_nums = tf.range(0, limit=FLAGS.batch_size) # shape (batch_size)\n",
    "    for dec_step, dist in enumerate(final_dists):\n",
    "        targets = target_words_ids[:,dec_step] # The indices of the target words. shape (batch_size)\n",
    "        indices = tf.stack( (batch_nums, targets), axis=1) # shape (batch_size, 2)\n",
    "        gold_probs = tf.gather_nd(dist, indices) # shape (batch_size). prob of correct words on this step\n",
    "        losses = -tf.log(gold_probs)\n",
    "        loss_per_step.append(losses)\n",
    "\n",
    "        # Apply dec_padding_mask and get loss\n",
    "        _loss = _mask_and_avg(loss_per_step, dec_padding_mask)\n",
    "\n",
    "    #always use coverage for now\n",
    "    _cov_loss = _coverage_loss( attn_dists, dec_padding_mask)\n",
    "    _total_loss = _loss + FLAGS.cov_loss_wt *  _cov_loss\n",
    "\n",
    "    return  _total_loss\n",
    "\n",
    "def _mask_and_avg(values, padding_mask):\n",
    "  \"\"\"Applies mask to values then returns overall average (a scalar)\n",
    "\n",
    "  Args:\n",
    "    values: a list length max_dec_steps containing arrays shape (batch_size).\n",
    "    padding_mask: tensor shape (batch_size, max_dec_steps) containing 1s and 0s.\n",
    "\n",
    "  Returns:\n",
    "    a scalar\n",
    "  \"\"\"\n",
    "\n",
    "  dec_lens = tf.reduce_sum(padding_mask, axis=1) # shape batch_size. float32\n",
    "  values_per_step = [v * padding_mask[:,dec_step] for dec_step,v in enumerate(values)]\n",
    "  values_per_ex = sum(values_per_step)/dec_lens # shape (batch_size); normalized value for each batch member\n",
    "  return tf.reduce_mean(values_per_ex) # overall average\n",
    "\n",
    "\n",
    "def _coverage_loss(attn_dists, padding_mask):\n",
    "  \"\"\"Calculates the coverage loss from the attention distributions.\n",
    "\n",
    "  Args:\n",
    "    attn_dists: The attention distributions for each decoder timestep. A list length max_dec_steps containing shape (batch_size, attn_length)\n",
    "    padding_mask: shape (batch_size, max_dec_steps).\n",
    "\n",
    "  Returns:\n",
    "    coverage_loss: scalar\n",
    "  \"\"\"\n",
    "  coverage = tf.zeros_like(attn_dists[0]) # shape (batch_size, attn_length). Initial coverage is zero.\n",
    "  covlosses = [] # Coverage loss per decoder timestep. Will be list length max_dec_steps containing shape (batch_size).\n",
    "  for a in attn_dists:\n",
    "    covloss = tf.reduce_sum(tf.minimum(a, coverage), [1]) # calculate the coverage loss for this step\n",
    "    covlosses.append(covloss)\n",
    "    coverage += a # update the coverage vector\n",
    "  coverage_loss = _mask_and_avg(covlosses, padding_mask)\n",
    "  return coverage_loss\n",
    "\n",
    "def get_loss_fn(loss_factor=1.0):\n",
    "  \"\"\"Gets a loss function for coqa task.\"\"\"\n",
    "\n",
    "  def _loss_fn(labels, model_outputs):\n",
    "    target_words_ids = labels['answer_ids']\n",
    "    dec_padding_mask = labels['answer_mask']\n",
    "    unique_ids,final_dists, attn_dists = model_outputs\n",
    "    return coqa_loss_fn(final_dists,\n",
    "                        attn_dists,\n",
    "                        target_words_ids,\n",
    "                        dec_padding_mask,\n",
    "                        loss_factor=loss_factor)\n",
    "\n",
    "  return _loss_fn\n",
    "\n",
    "\n",
    "def get_raw_results(predictions):\n",
    "  \"\"\"Converts multi-replica predictions to RawResult.\"\"\"\n",
    "  for unique_ids, start_logits, end_logits in zip(predictions['unique_ids'],\n",
    "                                                  predictions['start_logits'],\n",
    "                                                  predictions['end_logits']):\n",
    "    for values in zip(unique_ids.numpy(), start_logits.numpy(),\n",
    "                      end_logits.numpy()):\n",
    "      yield coqa_pgnet_lib.RawResult(\n",
    "          unique_id=values[0],\n",
    "          start_logits=values[1].tolist(),\n",
    "          end_logits=values[2].tolist())\n",
    "\n",
    "\n",
    "def predict_coqa_customized(strategy, input_meta_data, bert_config,\n",
    "                             predict_tfrecord_path, num_steps):\n",
    "  \"\"\"Make predictions using a Bert-based coqa model.\"\"\"\n",
    "  primary_cpu_task = '/job:worker' if FLAGS.tpu else ''\n",
    "\n",
    "  with tf.device(primary_cpu_task):\n",
    "    predict_dataset = input_pipeline.create_coqa_dataset(\n",
    "        predict_tfrecord_path,\n",
    "        input_meta_data['max_seq_length'],\n",
    "        FLAGS.predict_batch_size,\n",
    "        is_training=False)\n",
    "    predict_iterator = iter(\n",
    "        strategy.experimental_distribute_dataset(predict_dataset))\n",
    "\n",
    "    with strategy.scope():\n",
    "      # Prediction always uses float32, even if training uses mixed precision.\n",
    "      #tf.keras.mixed_precision.experimental.set_policy('float32')\n",
    "      coqa_model, _ = pgnet_models.coqa_model(\n",
    "          bert_config, input_meta_data['max_seq_length'], float_type=tf.float32)\n",
    "\n",
    "    checkpoint_path = tf.train.latest_checkpoint(FLAGS.model_dir)\n",
    "    logging.info('Restoring checkpoints from %s', checkpoint_path)\n",
    "    checkpoint = tf.train.Checkpoint(model=coqa_model)\n",
    "    checkpoint.restore(checkpoint_path).expect_partial()\n",
    "\n",
    "    @tf.function\n",
    "    def predict_step(iterator):\n",
    "      \"\"\"Predicts on distributed devices.\"\"\"\n",
    "\n",
    "      def _replicated_step(inputs):\n",
    "        \"\"\"Replicated prediction calculation.\"\"\"\n",
    "        x, _ = inputs\n",
    "        unique_ids, start_logits, end_logits = coqa_model(x, training=False)\n",
    "        return dict(\n",
    "            unique_ids=unique_ids,\n",
    "            start_logits=start_logits,\n",
    "            end_logits=end_logits)\n",
    "\n",
    "      outputs = strategy.experimental_run_v2(\n",
    "          _replicated_step, args=(next(iterator),))\n",
    "      return tf.nest.map_structure(strategy.experimental_local_results, outputs)\n",
    "\n",
    "    all_results = []\n",
    "    for _ in range(num_steps):\n",
    "      predictions = predict_step(predict_iterator)\n",
    "      for result in get_raw_results(predictions):\n",
    "        all_results.append(result)\n",
    "      if len(all_results) % 100 == 0:\n",
    "        logging.info('Made predictions for %d records.', len(all_results))\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def train_coqa(strategy,\n",
    "                input_meta_data,\n",
    "                custom_callbacks=None,\n",
    "                run_eagerly=False):\n",
    "  \"\"\"Run bert coqa training.\"\"\"\n",
    "  if strategy:\n",
    "    logging.info('Training using customized training loop with distribution'\n",
    "                 ' strategy.')\n",
    "  # Enables XLA in Session Config. Should not be set for TPU.\n",
    "  keras_utils.set_config_v2(FLAGS.enable_xla)\n",
    "\n",
    "  use_float16 = common_flags.use_float16()\n",
    "  if use_float16:\n",
    "    policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "    tf.keras.mixed_precision.experimental.set_policy(policy)\n",
    "\n",
    "  bert_config = bert_modeling.BertConfig.from_json_file(FLAGS.bert_config_file)\n",
    "\n",
    "  # add some extra to bert_config\n",
    "  bert_config.add_from_dict(input_meta_data)\n",
    "\n",
    "  # add use_pointer_gen\n",
    "  bert_config.add_from_dict({\"use_pointer_gen\":FLAGS.use_pointer_gen})\n",
    "  #max_oov_size  let's just add something for now\n",
    "  bert_config.add_from_dict({\"max_oov_size\": FLAGS.max_oov_size})\n",
    "  epochs = FLAGS.num_train_epochs\n",
    "  num_train_examples = input_meta_data['train_data_size']\n",
    "  max_seq_length = input_meta_data['max_seq_length']\n",
    "  max_answer_length = input_meta_data['max_answer_length']\n",
    "\n",
    "  steps_per_epoch = int(num_train_examples / FLAGS.train_batch_size)\n",
    "  warmup_steps = int(epochs * num_train_examples * 0.1 / FLAGS.train_batch_size)\n",
    "  train_input_fn = functools.partial(\n",
    "      input_pipeline.create_coqa_dataset_end2end,\n",
    "      FLAGS.train_data_path,\n",
    "      max_seq_length,\n",
    "      FLAGS.train_batch_size,\n",
    "      is_training=True)\n",
    "\n",
    "  def _get_coqa_model():\n",
    "    \"\"\"Get Squad model and optimizer.\"\"\"\n",
    "    coqa_model, core_model = pgnet_models.coqa_model(\n",
    "        bert_config,\n",
    "        max_seq_length,\n",
    "        max_answer_length,\n",
    "        FLAGS.max_oov_size,\n",
    "        float_type=tf.float16 if use_float16 else tf.float32)\n",
    "    coqa_model.optimizer = optimization.create_optimizer(\n",
    "        FLAGS.learning_rate, steps_per_epoch * epochs, warmup_steps)\n",
    "    if use_float16:\n",
    "      # Wraps optimizer with a LossScaleOptimizer. This is done automatically\n",
    "      # in compile() with the \"mixed_float16\" policy, but since we do not call\n",
    "      # compile(), we must wrap the optimizer manually.\n",
    "      coqa_model.optimizer = (\n",
    "          tf.keras.mixed_precision.experimental.LossScaleOptimizer(\n",
    "              coqa_model.optimizer, loss_scale=common_flags.get_loss_scale()))\n",
    "    if FLAGS.fp16_implementation == 'graph_rewrite':\n",
    "      # Note: when flags_obj.fp16_implementation == \"graph_rewrite\", dtype as\n",
    "      # determined by flags_core.get_tf_dtype(flags_obj) would be 'float32'\n",
    "      # which will ensure tf.compat.v2.keras.mixed_precision and\n",
    "      # tf.train.experimental.enable_mixed_precision_graph_rewrite do not double\n",
    "      # up.\n",
    "      coqa_model.optimizer = tf.train.experimental.enable_mixed_precision_graph_rewrite(\n",
    "          coqa_model.optimizer)\n",
    "    return coqa_model, core_model\n",
    "\n",
    "  # The original BERT model does not scale the loss by\n",
    "  # 1/num_replicas_in_sync. It could be an accident. So, in order to use\n",
    "  # the same hyper parameter, we do the same thing here by keeping each\n",
    "  # replica loss as it is.\n",
    "  loss_fn = get_loss_fn(\n",
    "      loss_factor=1.0 /\n",
    "      strategy.num_replicas_in_sync if FLAGS.scale_loss else 1.0)\n",
    "\n",
    "  model_training_utils.run_customized_training_loop(\n",
    "      strategy=strategy,\n",
    "      model_fn=_get_coqa_model,\n",
    "      loss_fn=loss_fn,\n",
    "      model_dir=FLAGS.model_dir,\n",
    "      steps_per_epoch=steps_per_epoch,\n",
    "      steps_per_loop=FLAGS.steps_per_loop,\n",
    "      epochs=epochs,\n",
    "      train_input_fn=train_input_fn,\n",
    "      init_checkpoint=FLAGS.init_checkpoint,\n",
    "      run_eagerly=run_eagerly,\n",
    "      custom_callbacks=custom_callbacks)\n",
    "\n",
    "\n",
    "def predict_coqa(strategy, input_meta_data):\n",
    "  \"\"\"Makes predictions for a coqa dataset.\"\"\"\n",
    "  bert_config = bert_modeling.BertConfig.from_json_file(FLAGS.bert_config_file)\n",
    "  doc_stride = input_meta_data['doc_stride']\n",
    "  max_seq_length=input_meta_data['max_seq_length']\n",
    "  max_query_length = input_meta_data['max_query_length']\n",
    "  # Whether data should be in Ver 2.0 format.\n",
    "\n",
    "  eval_examples = coqa_pgnet_lib.read_coqa_examples(\n",
    "      input_file=FLAGS.predict_file,\n",
    "      is_training=False )\n",
    "\n",
    "  tokenizer = tokenization.FullTokenizer(\n",
    "      vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)\n",
    "\n",
    "  eval_writer = coqa_pgnet_lib.FeatureWriter(\n",
    "      filename=os.path.join(FLAGS.model_dir, 'eval.tf_record'),\n",
    "      is_training=False)\n",
    "  eval_features = []\n",
    "\n",
    "  def _append_feature(feature, is_padding = False):\n",
    "    if not is_padding:\n",
    "      eval_features.append(feature)\n",
    "    eval_writer.process_feature(feature)\n",
    "\n",
    "  # TPU requires a fixed batch size for all batches, therefore the number\n",
    "  # of examples must be a multiple of the batch size, or else examples\n",
    "  # will get dropped. So we pad with fake examples which are ignored\n",
    "  # later on.\n",
    "  dataset_size = coqa_pgnet_lib.convert_examples_to_features(\n",
    "      examples=eval_examples,\n",
    "      tokenizer=tokenizer,\n",
    "      max_seq_length=max_seq_length,\n",
    "      doc_stride=doc_stride,\n",
    "      max_query_length=max_query_length,\n",
    "      is_training=False,\n",
    "      output_fn=_append_feature  )\n",
    "  eval_writer.close()\n",
    "\n",
    "  logging.info('***** Running predictions *****')\n",
    "  logging.info('  Num orig examples = %d', len(eval_examples))\n",
    "  logging.info('  Num split examples = %d', len(eval_features))\n",
    "  logging.info('  Batch size = %d', FLAGS.predict_batch_size)\n",
    "\n",
    "  num_steps = int(dataset_size / FLAGS.predict_batch_size)\n",
    "  all_results = predict_coqa_customized(strategy, input_meta_data, bert_config,\n",
    "                                         eval_writer.filename, num_steps)\n",
    "\n",
    "  output_prediction_file = os.path.join(FLAGS.model_dir, 'predictions.json')\n",
    "  output_nbest_file = os.path.join(FLAGS.model_dir, 'nbest_predictions.json')\n",
    "  output_null_log_odds_file = os.path.join(FLAGS.model_dir, 'null_odds.json')\n",
    "\n",
    "  coqa_pgnet_lib.write_predictions(\n",
    "      eval_examples,\n",
    "      eval_features,\n",
    "      all_results,\n",
    "      FLAGS.n_best_size,\n",
    "      FLAGS.max_answer_length,\n",
    "      FLAGS.do_lower_case,\n",
    "      output_prediction_file,\n",
    "      output_nbest_file,\n",
    "      output_null_log_odds_file )\n",
    "\n",
    "\n",
    "def export_coqa(model_export_path, input_meta_data):\n",
    "  \"\"\"Exports a trained model as a `SavedModel` for inference.\n",
    "\n",
    "  Args:\n",
    "    model_export_path: a string specifying the path to the SavedModel directory.\n",
    "    input_meta_data: dictionary containing meta data about input and model.\n",
    "\n",
    "  Raises:\n",
    "    Export path is not specified, got an empty string or None.\n",
    "  \"\"\"\n",
    "  if not model_export_path:\n",
    "    raise ValueError('Export path is not specified: %s' % model_export_path)\n",
    "  bert_config = bert_modeling.BertConfig.from_json_file(FLAGS.bert_config_file)\n",
    "\n",
    "  coqa_model, _ = pgnet_models.coqa_model(\n",
    "      bert_config, input_meta_data['max_seq_length'], float_type=tf.float32)\n",
    "  model_saving_utils.export_bert_model(\n",
    "      model_export_path, model=coqa_model, checkpoint_dir=FLAGS.model_dir)\n",
    "\n",
    "\n",
    "def main(_):\n",
    "  # Users should always run this script under TF 2.x\n",
    "  assert tf.version.VERSION.startswith('2.')\n",
    "\n",
    "  #tf.enable_eager_execution()\n",
    "  #tf.compat.v1.enable_eager_execution() \n",
    "  with tf.io.gfile.GFile(FLAGS.input_meta_data_path, 'rb') as reader:\n",
    "    input_meta_data = json.loads(reader.read().decode('utf-8'))\n",
    "\n",
    "\n",
    "  if FLAGS.mode == 'export_only':\n",
    "    export_coqa(FLAGS.model_export_path, input_meta_data)\n",
    "    return\n",
    "\n",
    "  strategy = None\n",
    "  if FLAGS.strategy_type == 'mirror':\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "  elif FLAGS.strategy_type == 'multi_worker_mirror':\n",
    "    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "  elif FLAGS.strategy_type == 'tpu':\n",
    "    cluster_resolver = tpu_lib.tpu_initialize(FLAGS.tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)\n",
    "  else:\n",
    "    raise ValueError('The distribution strategy type is not supported: %s' %\n",
    "                     FLAGS.strategy_type)\n",
    "  if FLAGS.mode in ('train', 'train_and_predict'):\n",
    "    train_coqa(strategy, input_meta_data)\n",
    "  if FLAGS.mode in ('predict', 'train_and_predict'):\n",
    "    predict_coqa(strategy, input_meta_data)\n",
    "\n",
    "  \n",
    "import sys\n",
    "\n",
    "def run(main=None, argv=None):\n",
    "    \n",
    "  flags_passthrough =FLAGS(sys.argv[:1]+argv)\n",
    "  \n",
    "  main = main or sys.modules['__main__'].main\n",
    "  main(None)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "        flags.mark_flag_as_required('bert_config_file')\n",
    "        flags.mark_flag_as_required('model_dir')\n",
    " \n",
    "        args =   ['--input_meta_data_path=/Users/wweschen/tf2/capstone/datasets/CoQA/coqa_pg_meta_data', \n",
    "         '--train_data_path=/Users/wweschen/tf2/capstone/datasets/CoQA/coqa_pg_train.tf_record',\n",
    "         '--predict_file=/Users/wweschen/tf2/capstone/datasets/CoQA/coqa-dev-v1.0.sample.json',\n",
    "         '--vocab_file=/Users/wweschen/tf2/capstone/pretrained/uncased_L-12_H-768_A-12/vocab.txt',\n",
    "         '--bert_config_file=/Users/wweschen/tf2/capstone/pretrained/uncased_L-12_H-768_A-12/bert_config.json',\n",
    "         '--init_checkpoint=/Users/wweschen/tf2/capstone/pretrained/uncased_L-12_H-768_A-12/bert_model.ckpt',\n",
    "         '--train_batch_size=4', '--predict_batch_size=4', '--learning_rate=8e-5', \n",
    "         '--num_train_epochs=2', '--model_dir=/Users/wweschen/tf2/capstone/outputs/coqa/',\n",
    "         '--strategy_type=mirror']\n",
    "    \n",
    "        run(main,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%magic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3002 3002 3001 3004 3003]\n",
      " [3001 3004 3004 3003 3001]\n",
      " [3004 3003 3004 3003 3004]\n",
      " [3004 3000 3000 3001 3004]\n",
      " [3000 3004 3002 3002 3002]]\n",
      "tf.Tensor(\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]], shape=(5, 30), dtype=int32)\n",
      "indices: tf.Tensor(\n",
      "[[[   0  991]\n",
      "  [   0 2577]\n",
      "  [   0  603]\n",
      "  [   0 1900]\n",
      "  [   0  343]\n",
      "  [   0 1173]\n",
      "  [   0  232]\n",
      "  [   0 1571]\n",
      "  [   0 1715]\n",
      "  [   0 1679]\n",
      "  [   0 1429]\n",
      "  [   0 2389]\n",
      "  [   0 1546]\n",
      "  [   0  540]\n",
      "  [   0 1864]\n",
      "  [   0 1541]\n",
      "  [   0  812]\n",
      "  [   0 1256]\n",
      "  [   0  965]\n",
      "  [   0 1988]\n",
      "  [   0 1171]\n",
      "  [   0  241]\n",
      "  [   0  204]\n",
      "  [   0 2577]\n",
      "  [   0 1058]\n",
      "  [   0 2442]\n",
      "  [   0 1463]\n",
      "  [   0   80]\n",
      "  [   0 2389]\n",
      "  [   0 1628]]\n",
      "\n",
      " [[   1 2905]\n",
      "  [   1  845]\n",
      "  [   1 1733]\n",
      "  [   1  575]\n",
      "  [   1 1027]\n",
      "  [   1 1995]\n",
      "  [   1  274]\n",
      "  [   1 2169]\n",
      "  [   1 1130]\n",
      "  [   1 2374]\n",
      "  [   1 2670]\n",
      "  [   1  651]\n",
      "  [   1  134]\n",
      "  [   1 2203]\n",
      "  [   1 1271]\n",
      "  [   1 1255]\n",
      "  [   1 1207]\n",
      "  [   1 2797]\n",
      "  [   1  555]\n",
      "  [   1  265]\n",
      "  [   1 2807]\n",
      "  [   1  340]\n",
      "  [   1  439]\n",
      "  [   1 2363]\n",
      "  [   1 2949]\n",
      "  [   1 1979]\n",
      "  [   1 2479]\n",
      "  [   1  467]\n",
      "  [   1 2368]\n",
      "  [   1 2651]]\n",
      "\n",
      " [[   2  150]\n",
      "  [   2 2352]\n",
      "  [   2 2367]\n",
      "  [   2  441]\n",
      "  [   2  187]\n",
      "  [   2 2702]\n",
      "  [   2 2626]\n",
      "  [   2 1024]\n",
      "  [   2 2375]\n",
      "  [   2 2646]\n",
      "  [   2 2043]\n",
      "  [   2 1905]\n",
      "  [   2 2674]\n",
      "  [   2 1959]\n",
      "  [   2 2477]\n",
      "  [   2  320]\n",
      "  [   2 2890]\n",
      "  [   2 2939]\n",
      "  [   2 2075]\n",
      "  [   2  284]\n",
      "  [   2 2459]\n",
      "  [   2 2356]\n",
      "  [   2  501]\n",
      "  [   2  805]\n",
      "  [   2 1725]\n",
      "  [   2   98]\n",
      "  [   2  735]\n",
      "  [   2 1099]\n",
      "  [   2 2519]\n",
      "  [   2 2416]]\n",
      "\n",
      " [[   3 2118]\n",
      "  [   3 2448]\n",
      "  [   3 1123]\n",
      "  [   3  503]\n",
      "  [   3  192]\n",
      "  [   3 1709]\n",
      "  [   3  446]\n",
      "  [   3 1039]\n",
      "  [   3   13]\n",
      "  [   3 1212]\n",
      "  [   3 2285]\n",
      "  [   3  595]\n",
      "  [   3  718]\n",
      "  [   3 1099]\n",
      "  [   3 1910]\n",
      "  [   3 2863]\n",
      "  [   3 2693]\n",
      "  [   3 2935]\n",
      "  [   3 1260]\n",
      "  [   3  796]\n",
      "  [   3 2847]\n",
      "  [   3 2761]\n",
      "  [   3 1276]\n",
      "  [   3 1738]\n",
      "  [   3 1817]\n",
      "  [   3 1105]\n",
      "  [   3  180]\n",
      "  [   3 1289]\n",
      "  [   3  193]\n",
      "  [   3  597]]\n",
      "\n",
      " [[   4 1205]\n",
      "  [   4  397]\n",
      "  [   4 1942]\n",
      "  [   4 1490]\n",
      "  [   4  606]\n",
      "  [   4  457]\n",
      "  [   4 1200]\n",
      "  [   4 1853]\n",
      "  [   4 2363]\n",
      "  [   4 1809]\n",
      "  [   4 1992]\n",
      "  [   4 2576]\n",
      "  [   4  316]\n",
      "  [   4 2746]\n",
      "  [   4  641]\n",
      "  [   4 1909]\n",
      "  [   4 1727]\n",
      "  [   4 2782]\n",
      "  [   4 2456]\n",
      "  [   4 2744]\n",
      "  [   4 1867]\n",
      "  [   4 1823]\n",
      "  [   4 2392]\n",
      "  [   4 2946]\n",
      "  [   4 1918]\n",
      "  [   4 1173]\n",
      "  [   4 1996]\n",
      "  [   4 2873]\n",
      "  [   4 2051]\n",
      "  [   4 1701]]], shape=(5, 30, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "batch_size=5\n",
    "max_oov_size=5\n",
    "vocab_size=3000\n",
    "seq_len=30\n",
    "extended_vsize = vocab_size + max_oov_size\n",
    "input_word_ids = np.random.randint(vocab_size, size=(batch_size,seq_len))\n",
    "oov_ids = np.random.randint(vocab_size,high=vocab_size+max_oov_size, size=[batch_size,max_oov_size],dtype=np.int64)\n",
    "print(oov_ids)\n",
    "\n",
    "batch_nums = tf.range(0, limit= batch_size)  # shape (batch_size)\n",
    "batch_nums = tf.expand_dims(batch_nums, 1)  # shape (batch_size, 1)\n",
    "attn_len = seq_len  # number of states we attend over\n",
    "batch_nums = tf.tile(batch_nums, [1, attn_len])  # shape (batch_size, attn_len)\n",
    "print (batch_nums)\n",
    "indices = tf.stack((batch_nums,  input_word_ids), axis=2)  # shape (batch_size, enc_t, 2)\n",
    "shape = [ batch_size, extended_vsize]\n",
    "print ('indices:',indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6]]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[1,2,3],[4,5,6]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
